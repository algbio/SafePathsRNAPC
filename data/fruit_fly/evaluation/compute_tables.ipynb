{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run this notebook you first need to run the notebook `evaluation/compute_metrics.ipynb` or obtain the data generated for such notebook in the corresponding folders\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from json import dump, load\n",
    "from pprint import pprint\n",
    "from statistics import median, mean, stdev\n",
    "import networkx as nx\n",
    "\n",
    "## Load gene graphs\n",
    "\n",
    "f = open(f'../gene_graphs/vertices_inv.json', 'r')\n",
    "vertices_inv = load(f)\n",
    "f.close()\n",
    "vertices_inv = {int(k): tuple(v) for k,v in vertices_inv.items()}\n",
    "\n",
    "n = int(open('../gene_graphs/info', 'r').read())\n",
    "\n",
    "components = list()\n",
    "for i in range(n): ## Number of gene_graphs\n",
    "    components.append(dict())\n",
    "    components[i]['graph'] = nx.read_edgelist(f'../gene_graphs/graphs/component_{i+1}.edgelist', delimiter=':', create_using=nx.DiGraph, nodetype=int)\n",
    "    components[i]['len'] = len(components[i]['graph'])\n",
    "    \n",
    "    f = open(f'../gene_graphs/sources/component_{i+1}.json', 'r')\n",
    "    components[i]['sources'] = set(load(f))\n",
    "    f.close()\n",
    "    \n",
    "    f = open(f'../gene_graphs/targets/component_{i+1}.json', 'r')\n",
    "    components[i]['targets'] = set(load(f))\n",
    "    f.close()\n",
    "    \n",
    "    f = open(f'../gene_graphs/vertex_constrains/component_{i+1}.json', 'r')\n",
    "    components[i]['vertex_constrains'] = set(load(f))\n",
    "    f.close()\n",
    "    \n",
    "    f = open(f'../gene_graphs/transcript_paths/component_{i+1}.json', 'r')\n",
    "    components[i]['transcript_paths'] = load(f)\n",
    "    f.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load experiments from json files\n",
    "for i, component in enumerate(components):\n",
    "    if component['len'] > 2 and len(component['transcript_paths']) > 1:\n",
    "        file = open(f'../safe_paths_json/component_{i+1}.json', \"r\")\n",
    "        dd = load(file)\n",
    "        component.update(dd)\n",
    "        file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interval_length(interval):\n",
    "    return interval[1]-interval[0]+1\n",
    "\n",
    "## It computes the base length of a transcript\n",
    "def base_length(contig, vertices_inv):\n",
    "    length = 0\n",
    "    for v in contig:\n",
    "        length += interval_length(vertices_inv[v])\n",
    "    return length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def choose_60_30_10_limits_cdss(components):\n",
    "#     lengths = list()\n",
    "#     for i, component in enumerate(components):\n",
    "#         if component['len'] > 2 and len(component['transcript_paths']) > 1:\n",
    "#             for CDSs in component['cdss_coverage']:\n",
    "#                 for CDS in CDSs:\n",
    "#                     lengths.append(CDS['length'])\n",
    "#     lengths = sorted(lengths)\n",
    "#     return lengths[int(0.6*len(lengths))], lengths[int(0.9*len(lengths))], lengths[-1]\n",
    "\n",
    "# limit_cdss_60, limit_cdss_30, limit_cdss_10 = choose_60_30_10_limits_cdss(components)\n",
    "# limit_cdss_60, limit_cdss_30, limit_cdss_10\n",
    "limit_cdss_60, limit_cdss_30, limit_cdss_10 = 150, 500, 27705"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def choose_60_30_10_limits(components, vertices_inv):\n",
    "#     lengths = list()\n",
    "#     for i, component in enumerate(components):\n",
    "#         if component['len'] > 2 and len(component['transcript_paths']) > 1:\n",
    "#             for transcript in component['transcript_paths']:\n",
    "#                 lengths.append(base_length(transcript['transcript_path'], vertices_inv))\n",
    "#     lengths = sorted(lengths)\n",
    "#     return lengths[int(0.6*len(lengths))], lengths[int(0.9*len(lengths))], lengths[-1]\n",
    "\n",
    "# limit_60, limit_30, limit_10 = choose_60_30_10_limits(components, vertices_inv)\n",
    "# limit_60, limit_30, limit_10\n",
    "limit_60, limit_30, limit_10 = 2000,5000,205012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def choose_60_30_10_limits_size(components, vertices_inv):\n",
    "#     sizes = list()\n",
    "#     for i, component in enumerate(components):\n",
    "#         if component['len'] > 2 and len(component['transcript_paths']) > 1:\n",
    "#             sizes.append(component['len'])\n",
    "#     sizes = sorted(sizes)\n",
    "#     return sizes[int(0.6*len(sizes))], sizes[int(0.9*len(sizes))], sizes[-1]\n",
    "\n",
    "# limit_size_60, limit_size_30, limit_size_10 = choose_60_30_10_limits_size(components, vertices_inv)\n",
    "# limit_size_60, limit_size_30, limit_size_10\n",
    "limit_size_60, limit_size_30, limit_size_10 = 15,50,725"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'large': {'abs_improvements_base': {'mean': 3276.5,\n",
      "                                     'median': 1746.0,\n",
      "                                     'stdev': 5124.650815690628},\n",
      "           'abs_improvements_vertex': {'mean': 6.666666666666667,\n",
      "                                       'median': 6.0,\n",
      "                                       'stdev': 4.381255790164571},\n",
      "           'number_of_unitigs': 30},\n",
      " 'medium': {'abs_improvements_base': {'mean': 2554.1402972027972,\n",
      "                                      'median': 1471.5,\n",
      "                                      'stdev': 4491.002535652361},\n",
      "            'abs_improvements_vertex': {'mean': 6.633304195804196,\n",
      "                                        'median': 4.0,\n",
      "                                        'stdev': 6.6099176263906125},\n",
      "            'number_of_unitigs': 2288},\n",
      " 'small': {'abs_improvements_base': {'mean': 1209.3221382099525,\n",
      "                                     'median': 589,\n",
      "                                     'stdev': 1688.7888762131206},\n",
      "           'abs_improvements_vertex': {'mean': 2.9892737823105326,\n",
      "                                       'median': 2,\n",
      "                                       'stdev': 2.802451871713026},\n",
      "           'number_of_unitigs': 5687},\n",
      " 'total': {'abs_improvements_base': {'mean': 1601.4469706433479,\n",
      "                                     'median': 801,\n",
      "                                     'stdev': 2874.6100999925},\n",
      "           'abs_improvements_vertex': {'mean': 4.044597126795753,\n",
      "                                       'median': 3,\n",
      "                                       'stdev': 4.567871728404067},\n",
      "           'number_of_unitigs': 8005}}\n"
     ]
    }
   ],
   "source": [
    "def compute_abs_improvement_table(over_width, limit_60, limit_30, components, vertices_inv):\n",
    "    unitigs = list()\n",
    "    for i, component in enumerate(components):\n",
    "        if component['len'] > 2 and len(component['transcript_paths']) > 1:\n",
    "            width = component['width']\n",
    "            l = str(width+over_width)\n",
    "            if over_width == -1:\n",
    "                l = str(len(component['transcript_paths']))\n",
    "            if over_width == -2:\n",
    "                l = str(2*component['width'])\n",
    "            if component['experiments'].get(l, None) is None:\n",
    "                l = str(2*width)\n",
    "\n",
    "            safe_paths = component['experiments'][str(l)]['safe_paths']\n",
    "            uni = component['unitigs']\n",
    "            \n",
    "            abs_vertex = component['experiments'][str(l)]['impr_vertex']\n",
    "            abs_base = component['experiments'][str(l)]['impr_base']\n",
    "            \n",
    "            abs_vertex = list(map(lambda r:  r[1] - len(uni[r[0]]), enumerate(abs_vertex)))\n",
    "            abs_base = list(map(lambda r:  r[1] - base_length(uni[r[0]], vertices_inv), enumerate(abs_base)))\n",
    "            \n",
    "                \n",
    "            for j in range(len(abs_base)):\n",
    "                d = dict()\n",
    "                d['component'] = i\n",
    "                d['component_length'] = component['len']\n",
    "                d['abs_improvements_base'] = abs_base[j]\n",
    "                d['abs_improvements_vertex'] = abs_vertex[j]\n",
    "                \n",
    "                unitigs.append(d)\n",
    "\n",
    "    small = list(filter(lambda c: c['component_length'] <= limit_60, unitigs))\n",
    "    medium = list(filter(lambda c: c['component_length'] > limit_60 and c['component_length'] <= limit_30 , unitigs))\n",
    "    large = list(filter(lambda c: c['component_length'] > limit_30, unitigs))\n",
    "    \n",
    "    small_abs_improvements_base = list(map(lambda c: c['abs_improvements_base'] , small))\n",
    "    medium_abs_improvements_base = list(map(lambda c: c['abs_improvements_base'] , medium))\n",
    "    large_abs_improvements_base = list(map(lambda c: c['abs_improvements_base'] , large))\n",
    "    total_abs_improvements_base = list(map(lambda c: c['abs_improvements_base'] , unitigs))\n",
    "    \n",
    "    small_abs_improvements_vertex = list(map(lambda c: c['abs_improvements_vertex'] , small))\n",
    "    medium_abs_improvements_vertex = list(map(lambda c: c['abs_improvements_vertex'] , medium))\n",
    "    large_abs_improvements_vertex = list(map(lambda c: c['abs_improvements_vertex'] , large))\n",
    "    total_abs_improvements_vertex = list(map(lambda c: c['abs_improvements_vertex'] , unitigs))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return { \n",
    "        'small':\n",
    "        {\n",
    "            'abs_improvements_vertex': \n",
    "            {\n",
    "                'median': median(small_abs_improvements_vertex),\n",
    "                'mean': mean(small_abs_improvements_vertex),\n",
    "                'stdev': stdev(small_abs_improvements_vertex)\n",
    "            },\n",
    "            'abs_improvements_base':\n",
    "            {\n",
    "                'median': median(small_abs_improvements_base),\n",
    "                'mean': mean(small_abs_improvements_base),\n",
    "                'stdev': stdev(small_abs_improvements_base)\n",
    "            },\n",
    "            'number_of_unitigs': len(small)            \n",
    "        },\n",
    "        'medium':\n",
    "        {\n",
    "            'abs_improvements_vertex': \n",
    "            {\n",
    "                'median': median(medium_abs_improvements_vertex),\n",
    "                'mean': mean(medium_abs_improvements_vertex),\n",
    "                'stdev': stdev(medium_abs_improvements_vertex)\n",
    "            },\n",
    "            'abs_improvements_base':\n",
    "            {\n",
    "                'median': median(medium_abs_improvements_base),\n",
    "                'mean': mean(medium_abs_improvements_base),\n",
    "                'stdev': stdev(medium_abs_improvements_base)\n",
    "            },\n",
    "            'number_of_unitigs': len(medium)\n",
    "            \n",
    "        },\n",
    "        'large':\n",
    "        {\n",
    "            'abs_improvements_vertex': \n",
    "            {\n",
    "                'median': median(large_abs_improvements_vertex),\n",
    "                'mean': mean(large_abs_improvements_vertex),\n",
    "                'stdev': stdev(large_abs_improvements_vertex)\n",
    "            },\n",
    "            'abs_improvements_base':\n",
    "            {\n",
    "                'median': median(large_abs_improvements_base),\n",
    "                'mean': mean(large_abs_improvements_base),\n",
    "                'stdev': stdev(large_abs_improvements_base)\n",
    "            },\n",
    "            'number_of_unitigs': len(large)\n",
    "            \n",
    "        },\n",
    "        'total':\n",
    "        {\n",
    "            'abs_improvements_vertex': \n",
    "            {\n",
    "                'median': median(total_abs_improvements_vertex),\n",
    "                'mean': mean(total_abs_improvements_vertex),\n",
    "                'stdev': stdev(total_abs_improvements_vertex)\n",
    "            },\n",
    "            'abs_improvements_base':\n",
    "            {\n",
    "                'median': median(total_abs_improvements_base),\n",
    "                'mean': mean(total_abs_improvements_base),\n",
    "                'stdev': stdev(total_abs_improvements_base)\n",
    "            },\n",
    "            'number_of_unitigs': len(unitigs)\n",
    "            \n",
    "        }\n",
    "    }\n",
    "    \n",
    "pprint(compute_abs_improvement_table(0, limit_size_60, limit_size_30, components, vertices_inv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'large': {'number_of_unitigs': 30,\n",
      "           'rel_improvements_base': {'mean': 5.330992845931314,\n",
      "                                     'median': 2.2990650145694653,\n",
      "                                     'stdev': 7.351363201465712},\n",
      "           'rel_improvements_vertex': {'mean': 2.6729589371980675,\n",
      "                                       'median': 2.3333333333333335,\n",
      "                                       'stdev': 1.4621469159451794}},\n",
      " 'medium': {'number_of_unitigs': 2288,\n",
      "            'rel_improvements_base': {'mean': 3.2013096758184707,\n",
      "                                      'median': 1.7467409859179006,\n",
      "                                      'stdev': 4.020454224358351},\n",
      "            'rel_improvements_vertex': {'mean': 2.0730073317782414,\n",
      "                                        'median': 1.6666666666666667,\n",
      "                                        'stdev': 1.2066853105389808}},\n",
      " 'small': {'number_of_unitigs': 5687,\n",
      "           'rel_improvements_base': {'mean': 2.0873666649775844,\n",
      "                                     'median': 1.0683090705487122,\n",
      "                                     'stdev': 2.5831670114572924},\n",
      "           'rel_improvements_vertex': {'mean': 1.4802350283403563,\n",
      "                                       'median': 1.25,\n",
      "                                       'stdev': 0.6609263931294065}},\n",
      " 'total': {'number_of_unitigs': 8005,\n",
      "           'rel_improvements_base': {'mean': 2.4179113738136317,\n",
      "                                     'median': 1.2053811659192826,\n",
      "                                     'stdev': 3.136806626483022},\n",
      "           'rel_improvements_vertex': {'mean': 1.6541319362143865,\n",
      "                                       'median': 1.3333333333333333,\n",
      "                                       'stdev': 0.899803897206865}}}\n"
     ]
    }
   ],
   "source": [
    "def compute_rel_improvement_table(over_width, limit_60, limit_30, components, vertices_inv):\n",
    "    unitigs = list()\n",
    "    for i, component in enumerate(components):\n",
    "        if component['len'] > 2 and len(component['transcript_paths']) > 1:\n",
    "            width = component['width']\n",
    "            l = str(width+over_width)\n",
    "            if over_width == -1:\n",
    "                l = str(len(component['transcript_paths']))\n",
    "            if over_width == -2:\n",
    "                l = str(2*component['width'])\n",
    "            if component['experiments'].get(l, None) is None:\n",
    "                l = str(2*width)\n",
    "\n",
    "            uni = component['unitigs']\n",
    "            safe_paths = component['experiments'][str(l)]['safe_paths']\n",
    "            \n",
    "            rel_vertex = component['experiments'][str(l)]['impr_vertex']\n",
    "            rel_base = component['experiments'][str(l)]['impr_base']\n",
    "            \n",
    "            rel_vertex = list(map(lambda r:  r[1]/len(uni[r[0]]), enumerate(rel_vertex)))\n",
    "            rel_base = list(map(lambda r:  r[1]/base_length(uni[r[0]], vertices_inv), enumerate(rel_base)))\n",
    "            \n",
    "            \n",
    "                \n",
    "            for j in range(len(rel_base)):\n",
    "                d = dict()\n",
    "                d['component'] = i\n",
    "                d['component_length'] = component['len']\n",
    "                d['rel_improvements_base'] = rel_base[j]\n",
    "                d['rel_improvements_vertex'] = rel_vertex[j]\n",
    "                \n",
    "                unitigs.append(d)\n",
    "\n",
    "    small = list(filter(lambda c: c['component_length'] <= limit_60, unitigs))\n",
    "    medium = list(filter(lambda c: c['component_length'] > limit_60 and c['component_length'] <= limit_30 , unitigs))\n",
    "    large = list(filter(lambda c: c['component_length'] > limit_30, unitigs))\n",
    "    \n",
    "    small_rel_improvements_base = list(map(lambda c: c['rel_improvements_base'] , small))\n",
    "    medium_rel_improvements_base = list(map(lambda c: c['rel_improvements_base'] , medium))\n",
    "    large_rel_improvements_base = list(map(lambda c: c['rel_improvements_base'] , large))\n",
    "    total_rel_improvements_base = list(map(lambda c: c['rel_improvements_base'] , unitigs))\n",
    "    \n",
    "    small_rel_improvements_vertex = list(map(lambda c: c['rel_improvements_vertex'] , small))\n",
    "    medium_rel_improvements_vertex = list(map(lambda c: c['rel_improvements_vertex'] , medium))\n",
    "    large_rel_improvements_vertex = list(map(lambda c: c['rel_improvements_vertex'] , large))\n",
    "    total_rel_improvements_vertex = list(map(lambda c: c['rel_improvements_vertex'] , unitigs))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return { \n",
    "        'small':\n",
    "        {\n",
    "            'rel_improvements_vertex': \n",
    "            {\n",
    "                'median': median(small_rel_improvements_vertex),\n",
    "                'mean': mean(small_rel_improvements_vertex),\n",
    "                'stdev': stdev(small_rel_improvements_vertex)\n",
    "            },\n",
    "            'rel_improvements_base':\n",
    "            {\n",
    "                'median': median(small_rel_improvements_base),\n",
    "                'mean': mean(small_rel_improvements_base),\n",
    "                'stdev': stdev(small_rel_improvements_base)\n",
    "            },\n",
    "            'number_of_unitigs': len(small)            \n",
    "        },\n",
    "        'medium':\n",
    "        {\n",
    "            'rel_improvements_vertex': \n",
    "            {\n",
    "                'median': median(medium_rel_improvements_vertex),\n",
    "                'mean': mean(medium_rel_improvements_vertex),\n",
    "                'stdev': stdev(medium_rel_improvements_vertex)\n",
    "            },\n",
    "            'rel_improvements_base':\n",
    "            {\n",
    "                'median': median(medium_rel_improvements_base),\n",
    "                'mean': mean(medium_rel_improvements_base),\n",
    "                'stdev': stdev(medium_rel_improvements_base)\n",
    "            },\n",
    "            'number_of_unitigs': len(medium)\n",
    "            \n",
    "        },\n",
    "        'large':\n",
    "        {\n",
    "            'rel_improvements_vertex': \n",
    "            {\n",
    "                'median': median(large_rel_improvements_vertex),\n",
    "                'mean': mean(large_rel_improvements_vertex),\n",
    "                'stdev': stdev(large_rel_improvements_vertex)\n",
    "            },\n",
    "            'rel_improvements_base':\n",
    "            {\n",
    "                'median': median(large_rel_improvements_base),\n",
    "                'mean': mean(large_rel_improvements_base),\n",
    "                'stdev': stdev(large_rel_improvements_base)\n",
    "            },\n",
    "            'number_of_unitigs': len(large)\n",
    "            \n",
    "        },\n",
    "        'total':\n",
    "        {\n",
    "            'rel_improvements_vertex': \n",
    "            {\n",
    "                'median': median(total_rel_improvements_vertex),\n",
    "                'mean': mean(total_rel_improvements_vertex),\n",
    "                'stdev': stdev(total_rel_improvements_vertex)\n",
    "            },\n",
    "            'rel_improvements_base':\n",
    "            {\n",
    "                'median': median(total_rel_improvements_base),\n",
    "                'mean': mean(total_rel_improvements_base),\n",
    "                'stdev': stdev(total_rel_improvements_base)\n",
    "            },\n",
    "            'number_of_unitigs': len(unitigs)\n",
    "            \n",
    "        }\n",
    "    }\n",
    "    \n",
    "pprint(compute_rel_improvement_table(-1, limit_size_60, limit_size_30, components, vertices_inv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'large': {'base_lengths': {'mean': 4008.8275862068967,\n",
      "                            'median': 2091,\n",
      "                            'stdev': 5633.5535668563925},\n",
      "           'number_of_contigs': 29,\n",
      "           'vertex_lengths': {'mean': 9.275862068965518,\n",
      "                              'median': 7,\n",
      "                              'stdev': 9.414641149841856}},\n",
      " 'medium': {'base_lengths': {'mean': 2271.5820251177392,\n",
      "                             'median': 1652.0,\n",
      "                             'stdev': 2289.504253132241},\n",
      "            'number_of_contigs': 2548,\n",
      "            'vertex_lengths': {'mean': 6.043956043956044,\n",
      "                               'median': 5.0,\n",
      "                               'stdev': 3.948782665566821}},\n",
      " 'small': {'base_lengths': {'mean': 1945.4170318434121,\n",
      "                            'median': 1535.5,\n",
      "                            'stdev': 1724.0689818724766},\n",
      "           'number_of_contigs': 6846,\n",
      "           'vertex_lengths': {'mean': 4.534910896874087,\n",
      "                              'median': 4.0,\n",
      "                              'stdev': 2.3263082763443728}},\n",
      " 'total': {'base_lengths': {'mean': 2039.9630690862782,\n",
      "                            'median': 1570,\n",
      "                            'stdev': 1924.4941873692435},\n",
      "           'number_of_contigs': 9423,\n",
      "           'vertex_lengths': {'mean': 4.957550673883052,\n",
      "                              'median': 4,\n",
      "                              'stdev': 2.9860465900428124}}}\n"
     ]
    }
   ],
   "source": [
    "def compute_contigs_table(over_width, limit_60, limit_30, components, vertices_inv):\n",
    "    contigs = list()\n",
    "    for i, component in enumerate(components):\n",
    "        if component['len'] > 2 and len(component['transcript_paths']) > 1:\n",
    "            width = component['width']\n",
    "            l = str(width+over_width)\n",
    "            if over_width == -1:\n",
    "                l = str(len(component['transcript_paths']))\n",
    "            if over_width == -2:\n",
    "                l = str(2*component['width'])\n",
    "            if component['experiments'].get(l, None) is None:\n",
    "                l = str(2*width)\n",
    "                \n",
    "            if component['experiments'].get(l, None) is not None:\n",
    "                safe_paths_info = component['experiments'][l]\n",
    "                \n",
    "                for safe_path in safe_paths_info['safe_paths']:\n",
    "                    d = dict()\n",
    "                    d['component'] = i\n",
    "                    d['component_length'] = component['len']\n",
    "                    d['vertices'] = len(safe_path)\n",
    "                    d['length'] = base_length(safe_path, vertices_inv)\n",
    "                    \n",
    "                    contigs.append(d)\n",
    "\n",
    "                \n",
    "                    \n",
    "    \n",
    "    \n",
    "   \n",
    "    small = list(filter(lambda c: c['component_length'] <= limit_60, contigs))\n",
    "    medium = list(filter(lambda c: c['component_length'] > limit_60 and c['component_length'] <= limit_30 , contigs))\n",
    "    large = list(filter(lambda c: c['component_length'] > limit_30, contigs))\n",
    "    \n",
    "    small_base_lengths = list(map(lambda c: c['length'] , small))\n",
    "    medium_base_lengths = list(map(lambda c: c['length'] , medium))\n",
    "    large_base_lengths = list(map(lambda c: c['length'] , large))\n",
    "    total_base_lengths = list(map(lambda c: c['length'] , contigs))\n",
    "    \n",
    "    small_vertex_lengths = list(map(lambda c: c['vertices'] , small))\n",
    "    medium_vertex_lengths = list(map(lambda c: c['vertices'] , medium))\n",
    "    large_vertex_lengths = list(map(lambda c: c['vertices'] , large))\n",
    "    total_vertex_lengths = list(map(lambda c: c['vertices'] , contigs))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return { \n",
    "        'small':\n",
    "        {\n",
    "            'vertex_lengths': \n",
    "            {\n",
    "                'median': median(small_vertex_lengths),\n",
    "                'mean': mean(small_vertex_lengths),\n",
    "                'stdev': stdev(small_vertex_lengths)\n",
    "            },\n",
    "            'base_lengths':\n",
    "            {\n",
    "                'median': median(small_base_lengths),\n",
    "                'mean': mean(small_base_lengths),\n",
    "                'stdev': stdev(small_base_lengths)\n",
    "            },\n",
    "            'number_of_contigs': len(small)            \n",
    "        },\n",
    "        'medium':\n",
    "        {\n",
    "            'vertex_lengths': \n",
    "            {\n",
    "                'median': median(medium_vertex_lengths),\n",
    "                'mean': mean(medium_vertex_lengths),\n",
    "                'stdev': stdev(medium_vertex_lengths)\n",
    "            },\n",
    "            'base_lengths':\n",
    "            {\n",
    "                'median': median(medium_base_lengths),\n",
    "                'mean': mean(medium_base_lengths),\n",
    "                'stdev': stdev(medium_base_lengths)\n",
    "            },\n",
    "            'number_of_contigs': len(medium)\n",
    "            \n",
    "        },\n",
    "        'large':\n",
    "        {\n",
    "            'vertex_lengths': \n",
    "            {\n",
    "                'median': median(large_vertex_lengths),\n",
    "                'mean': mean(large_vertex_lengths),\n",
    "                'stdev': stdev(large_vertex_lengths)\n",
    "            },\n",
    "            'base_lengths':\n",
    "            {\n",
    "                'median': median(large_base_lengths),\n",
    "                'mean': mean(large_base_lengths),\n",
    "                'stdev': stdev(large_base_lengths)\n",
    "            },\n",
    "            'number_of_contigs': len(large)\n",
    "            \n",
    "        },\n",
    "        'total':\n",
    "        {\n",
    "            'vertex_lengths': \n",
    "            {\n",
    "                'median': median(total_vertex_lengths),\n",
    "                'mean': mean(total_vertex_lengths),\n",
    "                'stdev': stdev(total_vertex_lengths)\n",
    "            },\n",
    "            'base_lengths':\n",
    "            {\n",
    "                'median': median(total_base_lengths),\n",
    "                'mean': mean(total_base_lengths),\n",
    "                'stdev': stdev(total_base_lengths)\n",
    "            },\n",
    "            'number_of_contigs': len(contigs)\n",
    "            \n",
    "        }\n",
    "    }\n",
    "    \n",
    "pprint(compute_contigs_table(-1, limit_size_60, limit_size_30, components, vertices_inv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'large': {'base_lengths': {'mean': 2124.266666666667,\n",
      "                            'median': 852.5,\n",
      "                            'stdev': 4195.534078314566},\n",
      "           'number_of_contigs': 30,\n",
      "           'vertex_lengths': {'mean': 5.566666666666666,\n",
      "                              'median': 3.0,\n",
      "                              'stdev': 8.041630188708881}},\n",
      " 'medium': {'base_lengths': {'mean': 1469.4873251748252,\n",
      "                             'median': 844.5,\n",
      "                             'stdev': 1864.8254778407177},\n",
      "            'number_of_contigs': 2288,\n",
      "            'vertex_lengths': {'mean': 4.0152972027972025,\n",
      "                               'median': 3.0,\n",
      "                               'stdev': 2.5978418103623735}},\n",
      " 'small': {'base_lengths': {'mean': 1559.2488130824688,\n",
      "                            'median': 1114,\n",
      "                            'stdev': 1588.928607728784},\n",
      "           'number_of_contigs': 5687,\n",
      "           'vertex_lengths': {'mean': 3.748197643748901,\n",
      "                              'median': 3,\n",
      "                              'stdev': 1.643339931930172}},\n",
      " 'total': {'base_lengths': {'mean': 1535.7105559025608,\n",
      "                            'median': 1031,\n",
      "                            'stdev': 1689.3510807430614},\n",
      "           'number_of_contigs': 8005,\n",
      "           'vertex_lengths': {'mean': 3.8313554028732044,\n",
      "                              'median': 3,\n",
      "                              'stdev': 2.0265704355806804}}}\n"
     ]
    }
   ],
   "source": [
    "def compute_contigs_table_unitigs(limit_60, limit_30, components, vertices_inv):\n",
    "    contigs = list()\n",
    "    for i, component in enumerate(components):\n",
    "        if component['len'] > 2 and len(component['transcript_paths']) > 1:\n",
    "            unitigs = component['unitigs']\n",
    "\n",
    "            for unitig in unitigs:\n",
    "                d = dict()\n",
    "                d['component'] = i\n",
    "                d['component_length'] = component['len']\n",
    "                d['vertices'] = len(unitig)\n",
    "                d['length'] = base_length(unitig, vertices_inv)\n",
    "\n",
    "                contigs.append(d)\n",
    "                \n",
    "    \n",
    "    \n",
    "    small = list(filter(lambda c: c['component_length'] <= limit_60, contigs))\n",
    "    medium = list(filter(lambda c: c['component_length'] > limit_60 and c['component_length'] <= limit_30 , contigs))\n",
    "    large = list(filter(lambda c: c['component_length'] > limit_30, contigs))\n",
    "    \n",
    "    small_base_lengths = list(map(lambda c: c['length'] , small))\n",
    "    medium_base_lengths = list(map(lambda c: c['length'] , medium))\n",
    "    large_base_lengths = list(map(lambda c: c['length'] , large))\n",
    "    total_base_lengths = list(map(lambda c: c['length'] , contigs))\n",
    "    \n",
    "    small_vertex_lengths = list(map(lambda c: c['vertices'] , small))\n",
    "    medium_vertex_lengths = list(map(lambda c: c['vertices'] , medium))\n",
    "    large_vertex_lengths = list(map(lambda c: c['vertices'] , large))\n",
    "    total_vertex_lengths = list(map(lambda c: c['vertices'] , contigs))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return { \n",
    "        'small':\n",
    "        {\n",
    "            'vertex_lengths': \n",
    "            {\n",
    "                'median': median(small_vertex_lengths),\n",
    "                'mean': mean(small_vertex_lengths),\n",
    "                'stdev': stdev(small_vertex_lengths)\n",
    "            },\n",
    "            'base_lengths':\n",
    "            {\n",
    "                'median': median(small_base_lengths),\n",
    "                'mean': mean(small_base_lengths),\n",
    "                'stdev': stdev(small_base_lengths)\n",
    "            },\n",
    "            'number_of_contigs': len(small)            \n",
    "        },\n",
    "        'medium':\n",
    "        {\n",
    "            'vertex_lengths': \n",
    "            {\n",
    "                'median': median(medium_vertex_lengths),\n",
    "                'mean': mean(medium_vertex_lengths),\n",
    "                'stdev': stdev(medium_vertex_lengths)\n",
    "            },\n",
    "            'base_lengths':\n",
    "            {\n",
    "                'median': median(medium_base_lengths),\n",
    "                'mean': mean(medium_base_lengths),\n",
    "                'stdev': stdev(medium_base_lengths)\n",
    "            },\n",
    "            'number_of_contigs': len(medium)\n",
    "            \n",
    "        },\n",
    "        'large':\n",
    "        {\n",
    "            'vertex_lengths': \n",
    "            {\n",
    "                'median': median(large_vertex_lengths),\n",
    "                'mean': mean(large_vertex_lengths),\n",
    "                'stdev': stdev(large_vertex_lengths)\n",
    "            },\n",
    "            'base_lengths':\n",
    "            {\n",
    "                'median': median(large_base_lengths),\n",
    "                'mean': mean(large_base_lengths),\n",
    "                'stdev': stdev(large_base_lengths)\n",
    "            },\n",
    "            'number_of_contigs': len(large)\n",
    "            \n",
    "        },\n",
    "        'total':\n",
    "        {\n",
    "            'vertex_lengths': \n",
    "            {\n",
    "                'median': median(total_vertex_lengths),\n",
    "                'mean': mean(total_vertex_lengths),\n",
    "                'stdev': stdev(total_vertex_lengths)\n",
    "            },\n",
    "            'base_lengths':\n",
    "            {\n",
    "                'median': median(total_base_lengths),\n",
    "                'mean': mean(total_base_lengths),\n",
    "                'stdev': stdev(total_base_lengths)\n",
    "            },\n",
    "            'number_of_contigs': len(contigs)\n",
    "            \n",
    "        }\n",
    "    }\n",
    "\n",
    "pprint(compute_contigs_table_unitigs(limit_size_60, limit_size_30, components, vertices_inv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'large': {'e_size_density_bases': {'mean': 0.6158196738202742,\n",
      "                                    'median': 0.5639601355729409,\n",
      "                                    'stdev': 0.25579064322613276},\n",
      "           'e_size_density_vertex': {'mean': 0.5491534623750999,\n",
      "                                     'median': 0.4976915974145891,\n",
      "                                     'stdev': 0.26682321630075806},\n",
      "           'max_prop_cov_bases': {'mean': 0.7309355683252179,\n",
      "                                  'median': 0.7305338078291815,\n",
      "                                  'stdev': 0.2161269274341874},\n",
      "           'max_prop_cov_vertex': {'mean': 0.6682650331139081,\n",
      "                                   'median': 0.6470588235294118,\n",
      "                                   'stdev': 0.2365365934279487}},\n",
      " 'medium': {'e_size_density_bases': {'mean': 0.733483445520376,\n",
      "                                     'median': 0.783389224206539,\n",
      "                                     'stdev': 0.2396273566839232},\n",
      "            'e_size_density_vertex': {'mean': 0.6746542721102519,\n",
      "                                      'median': 0.673469387755102,\n",
      "                                      'stdev': 0.25094608514615235},\n",
      "            'max_prop_cov_bases': {'mean': 0.825234524123176,\n",
      "                                   'median': 0.9084176867315283,\n",
      "                                   'stdev': 0.1962781354623737},\n",
      "            'max_prop_cov_vertex': {'mean': 0.7787861105007498,\n",
      "                                    'median': 0.8181818181818182,\n",
      "                                    'stdev': 0.21210779160052234}},\n",
      " 'small': {'e_size_density_bases': {'mean': 0.8692386469416173,\n",
      "                                    'median': 0.9770582426280296,\n",
      "                                    'stdev': 0.18375106859512647},\n",
      "           'e_size_density_vertex': {'mean': 0.820211010824142,\n",
      "                                     'median': 0.9074074074074073,\n",
      "                                     'stdev': 0.2165281426797437},\n",
      "           'max_prop_cov_bases': {'mean': 0.9203766598521447,\n",
      "                                  'median': 1.0,\n",
      "                                  'stdev': 0.1420402889237526},\n",
      "           'max_prop_cov_vertex': {'mean': 0.8797301961963452,\n",
      "                                   'median': 1.0,\n",
      "                                   'stdev': 0.18159226478403884}}}\n"
     ]
    }
   ],
   "source": [
    "def compute_fixed_l_table(over_width, limit_60, limit_30, components, vertices_inv):\n",
    "    transcripts = list()\n",
    "    for i, component in enumerate(components):\n",
    "        if component['len'] > 2 and len(component['transcript_paths']) > 1:\n",
    "            width = component['width']\n",
    "            l = str(width+over_width)\n",
    "            if over_width == -1:\n",
    "                l = str(len(component['transcript_paths']))\n",
    "            if over_width == -2:\n",
    "                l = str(2*component['width'])\n",
    "            if component['experiments'].get(l, None) is None:\n",
    "                l = str(2*width)\n",
    "                \n",
    "            if component['experiments'].get(l, None) is not None:\n",
    "                safe_paths_info = component['experiments'][l]\n",
    "\n",
    "                for j, transcript in enumerate(component['transcript_paths']):\n",
    "                    transcript = transcript['transcript_path']\n",
    "                    d = dict()\n",
    "                    d['component'] = i\n",
    "                    d['length'] = base_length(transcript, vertices_inv)\n",
    "                    d['transcript'] = transcript\n",
    "                    \n",
    "                    d['e_size_density_vertex'] = safe_paths_info['e_sizes_vertex'][j]/len(transcript)\n",
    "                    d['e_size_density_bases'] = safe_paths_info['e_size_bases'][j]/d['length']\n",
    "                    d['max_prop_cov_bases'] = safe_paths_info['max_cov_bases'][j]/d['length']\n",
    "                    d['max_prop_cov_vertex'] = safe_paths_info['max_cov_vertex'][j]/len(transcript)\n",
    "                    \n",
    "                    transcripts.append(d)\n",
    "    \n",
    "    \n",
    "    \n",
    "    small = list(filter(lambda t: t['length'] <= limit_60, transcripts))\n",
    "    medium = list(filter(lambda t: t['length'] > limit_60 and t['length'] <= limit_30 , transcripts))\n",
    "    large = list(filter(lambda t: t['length'] > limit_30, transcripts))\n",
    "    \n",
    "    \n",
    "    small_e_size_densities_vertex = list(map(lambda t: t['e_size_density_vertex'] , small))\n",
    "    medium_e_size_densities_vertex = list(map(lambda t: t['e_size_density_vertex'] , medium))\n",
    "    large_e_size_densities_vertex = list(map(lambda t: t['e_size_density_vertex'] , large))\n",
    "    \n",
    "    small_e_size_densities_bases = list(map(lambda t: t['e_size_density_bases'] , small))\n",
    "    medium_e_size_densities_bases = list(map(lambda t: t['e_size_density_bases'] , medium))\n",
    "    large_e_size_densities_bases = list(map(lambda t: t['e_size_density_bases'] , large))\n",
    "    \n",
    "    \n",
    "    small_max_prop_cov_vertex = list(map(lambda t: t['max_prop_cov_vertex'] , small))\n",
    "    medium_max_prop_cov_vertex = list(map(lambda t: t['max_prop_cov_vertex'] , medium))\n",
    "    large_max_prop_cov_vertex = list(map(lambda t: t['max_prop_cov_vertex'] , large))\n",
    "    \n",
    "    small_max_prop_cov_bases = list(map(lambda t: t['max_prop_cov_bases'] , small))\n",
    "    medium_max_prop_cov_bases = list(map(lambda t: t['max_prop_cov_bases'] , medium))\n",
    "    large_max_prop_cov_bases = list(map(lambda t: t['max_prop_cov_bases'] , large))\n",
    "    \n",
    "    \n",
    "    \n",
    "    return { \n",
    "        'small':\n",
    "        {\n",
    "            'e_size_density_vertex': \n",
    "            {\n",
    "                'median': median(small_e_size_densities_vertex),\n",
    "                'mean': mean(small_e_size_densities_vertex),\n",
    "                'stdev': stdev(small_e_size_densities_vertex)\n",
    "            },\n",
    "            'e_size_density_bases': \n",
    "            {\n",
    "                'median': median(small_e_size_densities_bases),\n",
    "                'mean': mean(small_e_size_densities_bases),\n",
    "                'stdev': stdev(small_e_size_densities_bases)\n",
    "            },\n",
    "            'max_prop_cov_vertex':\n",
    "            {\n",
    "                'median': median(small_max_prop_cov_vertex),\n",
    "                'mean': mean(small_max_prop_cov_vertex),\n",
    "                'stdev': stdev(small_max_prop_cov_vertex)\n",
    "            },\n",
    "            'max_prop_cov_bases':\n",
    "            {\n",
    "                'median': median(small_max_prop_cov_bases),\n",
    "                'mean': mean(small_max_prop_cov_bases),\n",
    "                'stdev': stdev(small_max_prop_cov_bases)\n",
    "            }\n",
    "            \n",
    "        }\n",
    "        ,\n",
    "        'medium' :\n",
    "        {\n",
    "            'e_size_density_vertex': \n",
    "            {\n",
    "                'median': median(medium_e_size_densities_vertex),\n",
    "                'mean': mean(medium_e_size_densities_vertex),\n",
    "                'stdev': stdev(medium_e_size_densities_vertex)\n",
    "            },\n",
    "            'e_size_density_bases': \n",
    "            {\n",
    "                'median': median(medium_e_size_densities_bases),\n",
    "                'mean': mean(medium_e_size_densities_bases),\n",
    "                'stdev': stdev(medium_e_size_densities_bases)\n",
    "            },\n",
    "            'max_prop_cov_vertex':\n",
    "            {\n",
    "                'median': median(medium_max_prop_cov_vertex),\n",
    "                'mean': mean(medium_max_prop_cov_vertex),\n",
    "                'stdev': stdev(medium_max_prop_cov_vertex)\n",
    "            },\n",
    "            'max_prop_cov_bases':\n",
    "            {\n",
    "                'median': median(medium_max_prop_cov_bases),\n",
    "                'mean': mean(medium_max_prop_cov_bases),\n",
    "                'stdev': stdev(medium_max_prop_cov_bases)\n",
    "            }\n",
    "        },\n",
    "        'large':\n",
    "        {\n",
    "            'e_size_density_vertex': \n",
    "            {\n",
    "                'median': median(large_e_size_densities_vertex),\n",
    "                'mean': mean(large_e_size_densities_vertex),\n",
    "                'stdev': stdev(large_e_size_densities_vertex)\n",
    "            },\n",
    "            'e_size_density_bases': \n",
    "            {\n",
    "                'median': median(large_e_size_densities_bases),\n",
    "                'mean': mean(large_e_size_densities_bases),\n",
    "                'stdev': stdev(large_e_size_densities_bases)\n",
    "            },\n",
    "            'max_prop_cov_vertex':\n",
    "            {\n",
    "                'median': median(large_max_prop_cov_vertex),\n",
    "                'mean': mean(large_max_prop_cov_vertex),\n",
    "                'stdev': stdev(large_max_prop_cov_vertex)\n",
    "            },\n",
    "            'max_prop_cov_bases':\n",
    "            {\n",
    "                'median': median(large_max_prop_cov_bases),\n",
    "                'mean': mean(large_max_prop_cov_bases),\n",
    "                'stdev': stdev(large_max_prop_cov_bases)\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "pprint(compute_fixed_l_table(0, limit_60, limit_30, components, vertices_inv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'large': {'e_size_density_bases': {'mean': 0.46826449854111424,\n",
      "                                    'median': 0.4270592388807871,\n",
      "                                    'stdev': 0.2707898517387217},\n",
      "           'e_size_density_vertex': {'mean': 0.3712801065655022,\n",
      "                                     'median': 0.30092592592592593,\n",
      "                                     'stdev': 0.23371303863907886},\n",
      "           'max_prop_cov_bases': {'mean': 0.6000078237728899,\n",
      "                                  'median': 0.5817028985507247,\n",
      "                                  'stdev': 0.24685051217299278},\n",
      "           'max_prop_cov_vertex': {'mean': 0.4969427524809063,\n",
      "                                   'median': 0.45454545454545453,\n",
      "                                   'stdev': 0.23391352218215306}},\n",
      " 'medium': {'e_size_density_bases': {'mean': 0.5545369465992969,\n",
      "                                     'median': 0.5291852153875484,\n",
      "                                     'stdev': 0.28912947998332356},\n",
      "            'e_size_density_vertex': {'mean': 0.4665010068890766,\n",
      "                                      'median': 0.42148760330578516,\n",
      "                                      'stdev': 0.26335880576677373},\n",
      "            'max_prop_cov_bases': {'mean': 0.6793903428591009,\n",
      "                                   'median': 0.7055181338852835,\n",
      "                                   'stdev': 0.2555581033738048},\n",
      "            'max_prop_cov_vertex': {'mean': 0.5958128108491263,\n",
      "                                    'median': 0.6,\n",
      "                                    'stdev': 0.24452560036962623}},\n",
      " 'small': {'e_size_density_bases': {'mean': 0.6631523860071546,\n",
      "                                    'median': 0.7462868017938111,\n",
      "                                    'stdev': 0.3380457656663787},\n",
      "           'e_size_density_vertex': {'mean': 0.6026217067602802,\n",
      "                                     'median': 0.5625,\n",
      "                                     'stdev': 0.32696526487477623},\n",
      "           'max_prop_cov_bases': {'mean': 0.7495864816136284,\n",
      "                                  'median': 0.8726717023258511,\n",
      "                                  'stdev': 0.30223156824005903},\n",
      "           'max_prop_cov_vertex': {'mean': 0.6959942234271281,\n",
      "                                   'median': 0.75,\n",
      "                                   'stdev': 0.2925127504670988}}}\n"
     ]
    }
   ],
   "source": [
    "def compute_fixed_l_table_unitigs(limit_60, limit_30, components, vertices_inv):\n",
    "    transcripts = list()\n",
    "    for i, component in enumerate(components):\n",
    "        if component['len'] > 2 and len(component['transcript_paths']) > 1:\n",
    "            unitigs = component['unitigs']\n",
    "\n",
    "            for j, transcript in enumerate(component['transcript_paths']):\n",
    "                transcript = transcript['transcript_path']\n",
    "                \n",
    "                d = dict()\n",
    "                d['component'] = i\n",
    "                d['length'] = base_length(transcript, vertices_inv)\n",
    "                d['transcript'] = transcript\n",
    "                \n",
    "                \n",
    "                d['e_size_density_vertex'] =  component['e_sizes_vertex'][j]/len(transcript)\n",
    "                d['e_size_density_bases'] =  component['e_size_bases'][j]/d['length']\n",
    "                d['max_prop_cov_bases'] =  component['max_cov_bases'][j]/d['length']\n",
    "                d['max_prop_cov_vertex'] =  component['max_cov_vertex'][j]/len(transcript)\n",
    "\n",
    "                transcripts.append(d)\n",
    "\n",
    "    \n",
    "    \n",
    "    small = list(filter(lambda t: t['length'] <= limit_60, transcripts))\n",
    "    medium = list(filter(lambda t: t['length'] > limit_60 and t['length'] <= limit_30 , transcripts))\n",
    "    large = list(filter(lambda t: t['length'] > limit_30, transcripts))\n",
    "    \n",
    "    \n",
    "    small_e_size_densities_vertex = list(map(lambda t: t['e_size_density_vertex'] , small))\n",
    "    medium_e_size_densities_vertex = list(map(lambda t: t['e_size_density_vertex'] , medium))\n",
    "    large_e_size_densities_vertex = list(map(lambda t: t['e_size_density_vertex'] , large))\n",
    "    \n",
    "    small_e_size_densities_bases = list(map(lambda t: t['e_size_density_bases'] , small))\n",
    "    medium_e_size_densities_bases = list(map(lambda t: t['e_size_density_bases'] , medium))\n",
    "    large_e_size_densities_bases = list(map(lambda t: t['e_size_density_bases'] , large))\n",
    "    \n",
    "    \n",
    "    small_max_prop_cov_vertex = list(map(lambda t: t['max_prop_cov_vertex'] , small))\n",
    "    medium_max_prop_cov_vertex = list(map(lambda t: t['max_prop_cov_vertex'] , medium))\n",
    "    large_max_prop_cov_vertex = list(map(lambda t: t['max_prop_cov_vertex'] , large))\n",
    "    \n",
    "    small_max_prop_cov_bases = list(map(lambda t: t['max_prop_cov_bases'] , small))\n",
    "    medium_max_prop_cov_bases = list(map(lambda t: t['max_prop_cov_bases'] , medium))\n",
    "    large_max_prop_cov_bases = list(map(lambda t: t['max_prop_cov_bases'] , large))\n",
    "\n",
    "    \n",
    "    \n",
    "    return { \n",
    "        'small':\n",
    "        {\n",
    "            'e_size_density_vertex': \n",
    "            {\n",
    "                'median': median(small_e_size_densities_vertex),\n",
    "                'mean': mean(small_e_size_densities_vertex),\n",
    "                'stdev': stdev(small_e_size_densities_vertex)\n",
    "            },\n",
    "            'e_size_density_bases': \n",
    "            {\n",
    "                'median': median(small_e_size_densities_bases),\n",
    "                'mean': mean(small_e_size_densities_bases),\n",
    "                'stdev': stdev(small_e_size_densities_bases)\n",
    "            },\n",
    "            'max_prop_cov_vertex':\n",
    "            {\n",
    "                'median': median(small_max_prop_cov_vertex),\n",
    "                'mean': mean(small_max_prop_cov_vertex),\n",
    "                'stdev': stdev(small_max_prop_cov_vertex)\n",
    "            },\n",
    "            'max_prop_cov_bases':\n",
    "            {\n",
    "                'median': median(small_max_prop_cov_bases),\n",
    "                'mean': mean(small_max_prop_cov_bases),\n",
    "                'stdev': stdev(small_max_prop_cov_bases)\n",
    "            }\n",
    "            \n",
    "        }\n",
    "        ,\n",
    "        'medium' :\n",
    "        {\n",
    "            'e_size_density_vertex': \n",
    "            {\n",
    "                'median': median(medium_e_size_densities_vertex),\n",
    "                'mean': mean(medium_e_size_densities_vertex),\n",
    "                'stdev': stdev(medium_e_size_densities_vertex)\n",
    "            },\n",
    "            'e_size_density_bases': \n",
    "            {\n",
    "                'median': median(medium_e_size_densities_bases),\n",
    "                'mean': mean(medium_e_size_densities_bases),\n",
    "                'stdev': stdev(medium_e_size_densities_bases)\n",
    "            },\n",
    "            'max_prop_cov_vertex':\n",
    "            {\n",
    "                'median': median(medium_max_prop_cov_vertex),\n",
    "                'mean': mean(medium_max_prop_cov_vertex),\n",
    "                'stdev': stdev(medium_max_prop_cov_vertex)\n",
    "            },\n",
    "            'max_prop_cov_bases':\n",
    "            {\n",
    "                'median': median(medium_max_prop_cov_bases),\n",
    "                'mean': mean(medium_max_prop_cov_bases),\n",
    "                'stdev': stdev(medium_max_prop_cov_bases)\n",
    "            }\n",
    "        },\n",
    "        'large':\n",
    "        {\n",
    "            'e_size_density_vertex': \n",
    "            {\n",
    "                'median': median(large_e_size_densities_vertex),\n",
    "                'mean': mean(large_e_size_densities_vertex),\n",
    "                'stdev': stdev(large_e_size_densities_vertex)\n",
    "            },\n",
    "            'e_size_density_bases': \n",
    "            {\n",
    "                'median': median(large_e_size_densities_bases),\n",
    "                'mean': mean(large_e_size_densities_bases),\n",
    "                'stdev': stdev(large_e_size_densities_bases)\n",
    "            },\n",
    "            'max_prop_cov_vertex':\n",
    "            {\n",
    "                'median': median(large_max_prop_cov_vertex),\n",
    "                'mean': mean(large_max_prop_cov_vertex),\n",
    "                'stdev': stdev(large_max_prop_cov_vertex)\n",
    "            },\n",
    "            'max_prop_cov_bases':\n",
    "            {\n",
    "                'median': median(large_max_prop_cov_bases),\n",
    "                'mean': mean(large_max_prop_cov_bases),\n",
    "                'stdev': stdev(large_max_prop_cov_bases)\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "pprint(compute_fixed_l_table_unitigs(limit_60, limit_30, components, vertices_inv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'large': {'e_size_density_bases': {'mean': 0.5241701987985957,\n",
      "                                    'median': 0.45818507871186426,\n",
      "                                    'stdev': 0.23136599256223805},\n",
      "           'e_size_density_vertex': {'mean': 0.4130478407829345,\n",
      "                                     'median': 0.2648299319727891,\n",
      "                                     'stdev': 0.2643829223254821},\n",
      "           'max_prop_cov_bases': {'mean': 0.6973747416998024,\n",
      "                                  'median': 0.671332221829275,\n",
      "                                  'stdev': 0.19230244942485558},\n",
      "           'max_prop_cov_vertex': {'mean': 0.5618927573137158,\n",
      "                                   'median': 0.4819976771196283,\n",
      "                                   'stdev': 0.23654199774904558},\n",
      "           'precision_bases': {'mean': 1.0, 'median': 1.0, 'stdev': 0.0},\n",
      "           'precision_vertex': {'mean': 1.0, 'median': 1.0, 'stdev': 0.0}},\n",
      " 'medium': {'e_size_density_bases': {'mean': 0.5359138649669625,\n",
      "                                     'median': 0.48507178947924334,\n",
      "                                     'stdev': 0.22232890833288754},\n",
      "            'e_size_density_vertex': {'mean': 0.4708803955567988,\n",
      "                                      'median': 0.4103623649078194,\n",
      "                                      'stdev': 0.22329037057352852},\n",
      "            'max_prop_cov_bases': {'mean': 0.6754860715778424,\n",
      "                                   'median': 0.6552252077023535,\n",
      "                                   'stdev': 0.20407452827729608},\n",
      "            'max_prop_cov_vertex': {'mean': 0.6135079126946857,\n",
      "                                    'median': 0.5833333333333334,\n",
      "                                    'stdev': 0.21310350772202494},\n",
      "            'precision_bases': {'mean': 0.8215443917941007,\n",
      "                                'median': 1.0,\n",
      "                                'stdev': 0.3473525270269538},\n",
      "            'precision_vertex': {'mean': 0.8220556137424827,\n",
      "                                 'median': 1.0,\n",
      "                                 'stdev': 0.3443134487635044}},\n",
      " 'small': {'e_size_density_bases': {'mean': 0.8524257489947439,\n",
      "                                    'median': 0.9429125614406312,\n",
      "                                    'stdev': 0.18493045067342248},\n",
      "           'e_size_density_vertex': {'mean': 0.7995823135087755,\n",
      "                                     'median': 0.8750000000000001,\n",
      "                                     'stdev': 0.2128548579550218},\n",
      "           'max_prop_cov_bases': {'mean': 0.9099208417006774,\n",
      "                                  'median': 1.0,\n",
      "                                  'stdev': 0.144800228565939},\n",
      "           'max_prop_cov_vertex': {'mean': 0.8687611687638073,\n",
      "                                   'median': 1.0,\n",
      "                                   'stdev': 0.17637813001453345},\n",
      "           'precision_bases': {'mean': 0.8499195734129082,\n",
      "                               'median': 1.0,\n",
      "                               'stdev': 0.34969330837501594},\n",
      "           'precision_vertex': {'mean': 0.8495676929767295,\n",
      "                                'median': 1.0,\n",
      "                                'stdev': 0.34931214438262276}}}\n"
     ]
    }
   ],
   "source": [
    "def compute_fixed_rd_table(over_width, limit_60, limit_30, components, vertices_inv):\n",
    "    genes = list()\n",
    "    transcripts = list()\n",
    "    for i, component in enumerate(components):\n",
    "        if component['len'] > 2 and len(component['transcript_paths']) > 1:\n",
    "            width = component['width']\n",
    "            l = str(width+over_width)\n",
    "            if over_width == -1:\n",
    "                l = str(len(component['transcript_paths']))\n",
    "            if over_width == -2:\n",
    "                l = str(2*component['width'])\n",
    "                \n",
    "                \n",
    "            if component['experiments'].get(l, None) is None:\n",
    "                l = str(2*width)\n",
    "                        \n",
    "            if component['experiments'].get(l, None) is not None:\n",
    "                safe_paths_info = component['experiments'][l]\n",
    "\n",
    "                for j, transcript in enumerate(component['transcript_paths']):\n",
    "                    transcript = transcript['transcript_path']\n",
    "                    \n",
    "                    d = dict()\n",
    "                    d['component'] = i\n",
    "                    d['component_length'] = component['len']\n",
    "                    d['length'] = base_length(transcript, vertices_inv)\n",
    "                    d['transcript'] = transcript\n",
    "                    \n",
    "                    \n",
    "                    d['e_size_density_vertex'] = safe_paths_info['e_sizes_vertex'][j]/len(transcript)\n",
    "                    d['e_size_density_bases'] = safe_paths_info['e_size_bases'][j]/d['length']\n",
    "                    d['max_prop_cov_bases'] = safe_paths_info['max_cov_bases'][j]/d['length']\n",
    "                    d['max_prop_cov_vertex'] = safe_paths_info['max_cov_vertex'][j]/len(transcript)\n",
    "                    \n",
    "                    transcripts.append(d)\n",
    "                 \n",
    "                d = dict()\n",
    "                \n",
    "                tp_bases = 0\n",
    "                tp_vertex = 0\n",
    "                for safe_path in safe_paths_info['true_positives']:\n",
    "                    tp_bases += base_length(safe_path, vertices_inv)\n",
    "                    tp_vertex += len(safe_path)\n",
    "                    \n",
    "                p_bases = tp_bases\n",
    "                p_vertex = tp_vertex\n",
    "                for safe_path in safe_paths_info['false_positives']:\n",
    "                    p_bases += base_length(safe_path, vertices_inv)\n",
    "                    p_vertex += len(safe_path)\n",
    "                \n",
    "                d['precision_bases'] = 1.0*tp_bases/p_bases\n",
    "                d['precision_vertex'] = 1.0*tp_vertex/p_vertex\n",
    "                d['component_length'] = components[i]['len']\n",
    "                genes.append(d)\n",
    "    \n",
    "    small = list(filter(lambda t: t['component_length'] <= limit_60, transcripts))\n",
    "    medium = list(filter(lambda t: t['component_length'] > limit_60 and t['component_length'] <= limit_30 , transcripts))\n",
    "    large = list(filter(lambda t: t['component_length'] > limit_30, transcripts))\n",
    "    \n",
    "    small_e_size_densities_vertex = list(map(lambda t: t['e_size_density_vertex'] , small))\n",
    "    medium_e_size_densities_vertex = list(map(lambda t: t['e_size_density_vertex'] , medium))\n",
    "    large_e_size_densities_vertex = list(map(lambda t: t['e_size_density_vertex'] , large))\n",
    "    \n",
    "    small_e_size_densities_bases = list(map(lambda t: t['e_size_density_bases'] , small))\n",
    "    medium_e_size_densities_bases = list(map(lambda t: t['e_size_density_bases'] , medium))\n",
    "    large_e_size_densities_bases = list(map(lambda t: t['e_size_density_bases'] , large))\n",
    "    \n",
    "    \n",
    "    small_max_prop_cov_vertex = list(map(lambda t: t['max_prop_cov_vertex'] , small))\n",
    "    medium_max_prop_cov_vertex = list(map(lambda t: t['max_prop_cov_vertex'] , medium))\n",
    "    large_max_prop_cov_vertex = list(map(lambda t: t['max_prop_cov_vertex'] , large))\n",
    "    \n",
    "    small_max_prop_cov_bases = list(map(lambda t: t['max_prop_cov_bases'] , small))\n",
    "    medium_max_prop_cov_bases = list(map(lambda t: t['max_prop_cov_bases'] , medium))\n",
    "    large_max_prop_cov_bases = list(map(lambda t: t['max_prop_cov_bases'] , large))\n",
    "    \n",
    "    \n",
    "    s = list(filter(lambda t: t['component_length'] <= limit_60, genes))\n",
    "    m = list(filter(lambda t: t['component_length'] > limit_60 and t['component_length'] <= limit_30 , genes))\n",
    "    l = list(filter(lambda t: t['component_length'] > limit_30, genes))\n",
    "    \n",
    "    s_precisions_bases = list(map(lambda t: t['precision_bases'] , s))\n",
    "    m_precisions_bases = list(map(lambda t: t['precision_bases'] , m))\n",
    "    l_precisions_bases = list(map(lambda t: t['precision_bases'] , l))\n",
    "    \n",
    "    s_precisions_vertex = list(map(lambda t: t['precision_vertex'] , s))\n",
    "    m_precisions_vertex = list(map(lambda t: t['precision_vertex'] , m))\n",
    "    l_precisions_vertex = list(map(lambda t: t['precision_vertex'] , l))\n",
    "    \n",
    "    \n",
    "    return { \n",
    "        'small':\n",
    "        {\n",
    "            'e_size_density_vertex': \n",
    "            {\n",
    "                'median': median(small_e_size_densities_vertex),\n",
    "                'mean': mean(small_e_size_densities_vertex),\n",
    "                'stdev': stdev(small_e_size_densities_vertex)\n",
    "            },\n",
    "            'e_size_density_bases': \n",
    "            {\n",
    "                'median': median(small_e_size_densities_bases),\n",
    "                'mean': mean(small_e_size_densities_bases),\n",
    "                'stdev': stdev(small_e_size_densities_bases)\n",
    "            },\n",
    "            'max_prop_cov_vertex':\n",
    "            {\n",
    "                'median': median(small_max_prop_cov_vertex),\n",
    "                'mean': mean(small_max_prop_cov_vertex),\n",
    "                'stdev': stdev(small_max_prop_cov_vertex)\n",
    "            },\n",
    "            'max_prop_cov_bases':\n",
    "            {\n",
    "                'median': median(small_max_prop_cov_bases),\n",
    "                'mean': mean(small_max_prop_cov_bases),\n",
    "                'stdev': stdev(small_max_prop_cov_bases)\n",
    "            },\n",
    "            'precision_bases':\n",
    "            {\n",
    "                'median': median(s_precisions_bases),\n",
    "                'mean': mean(s_precisions_bases),\n",
    "                'stdev': stdev(s_precisions_bases)\n",
    "            },\n",
    "            'precision_vertex':\n",
    "            {\n",
    "                'median': median(s_precisions_vertex),\n",
    "                'mean': mean(s_precisions_vertex),\n",
    "                'stdev': stdev(s_precisions_vertex)\n",
    "            }\n",
    "            \n",
    "        }\n",
    "        ,\n",
    "        'medium' :\n",
    "        {\n",
    "            'e_size_density_vertex': \n",
    "            {\n",
    "                'median': median(medium_e_size_densities_vertex),\n",
    "                'mean': mean(medium_e_size_densities_vertex),\n",
    "                'stdev': stdev(medium_e_size_densities_vertex)\n",
    "            },\n",
    "            'e_size_density_bases': \n",
    "            {\n",
    "                'median': median(medium_e_size_densities_bases),\n",
    "                'mean': mean(medium_e_size_densities_bases),\n",
    "                'stdev': stdev(medium_e_size_densities_bases)\n",
    "            },\n",
    "            'max_prop_cov_vertex':\n",
    "            {\n",
    "                'median': median(medium_max_prop_cov_vertex),\n",
    "                'mean': mean(medium_max_prop_cov_vertex),\n",
    "                'stdev': stdev(medium_max_prop_cov_vertex)\n",
    "            },\n",
    "            'max_prop_cov_bases':\n",
    "            {\n",
    "                'median': median(medium_max_prop_cov_bases),\n",
    "                'mean': mean(medium_max_prop_cov_bases),\n",
    "                'stdev': stdev(medium_max_prop_cov_bases)\n",
    "            },\n",
    "            'precision_bases':\n",
    "            {\n",
    "                'median': median(m_precisions_bases),\n",
    "                'mean': mean(m_precisions_bases),\n",
    "                'stdev': stdev(m_precisions_bases)\n",
    "            },\n",
    "            'precision_vertex':\n",
    "            {\n",
    "                'median': median(m_precisions_vertex),\n",
    "                'mean': mean(m_precisions_vertex),\n",
    "                'stdev': stdev(m_precisions_vertex)\n",
    "            }\n",
    "        },\n",
    "        'large':\n",
    "        {\n",
    "            'e_size_density_vertex': \n",
    "            {\n",
    "                'median': median(large_e_size_densities_vertex),\n",
    "                'mean': mean(large_e_size_densities_vertex),\n",
    "                'stdev': stdev(large_e_size_densities_vertex)\n",
    "            },\n",
    "            'e_size_density_bases': \n",
    "            {\n",
    "                'median': median(large_e_size_densities_bases),\n",
    "                'mean': mean(large_e_size_densities_bases),\n",
    "                'stdev': stdev(large_e_size_densities_bases)\n",
    "            },\n",
    "            'max_prop_cov_vertex':\n",
    "            {\n",
    "                'median': median(large_max_prop_cov_vertex),\n",
    "                'mean': mean(large_max_prop_cov_vertex),\n",
    "                'stdev': stdev(large_max_prop_cov_vertex)\n",
    "            },\n",
    "            'max_prop_cov_bases':\n",
    "            {\n",
    "                'median': median(large_max_prop_cov_bases),\n",
    "                'mean': mean(large_max_prop_cov_bases),\n",
    "                'stdev': stdev(large_max_prop_cov_bases)\n",
    "            },\n",
    "            'precision_bases':\n",
    "            {\n",
    "                'median': median(l_precisions_bases),\n",
    "                'mean': mean(l_precisions_bases),\n",
    "                'stdev': stdev(l_precisions_bases)\n",
    "            },\n",
    "            'precision_vertex':\n",
    "            {\n",
    "                'median': median(l_precisions_vertex),\n",
    "                'mean': mean(l_precisions_vertex),\n",
    "                'stdev': stdev(l_precisions_vertex)\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "pprint(compute_fixed_rd_table(0, limit_size_60, limit_size_30, components, vertices_inv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'large': {'e_size_density_bases': {'mean': 0.41516271019668255,\n",
      "                                    'median': 0.3037045648220238,\n",
      "                                    'stdev': 0.23945066394987435},\n",
      "           'e_size_density_vertex': {'mean': 0.2930053578477853,\n",
      "                                     'median': 0.1591005279764097,\n",
      "                                     'stdev': 0.24916657682939378},\n",
      "           'max_prop_cov_bases': {'mean': 0.5818881577995612,\n",
      "                                  'median': 0.46002517572246937,\n",
      "                                  'stdev': 0.2089103970131025},\n",
      "           'max_prop_cov_vertex': {'mean': 0.42866657035293365,\n",
      "                                   'median': 0.34523809523809523,\n",
      "                                   'stdev': 0.239341325258517},\n",
      "           'precision_bases': {'mean': 1.0, 'median': 1.0, 'stdev': 0.0},\n",
      "           'precision_vertex': {'mean': 1.0, 'median': 1.0, 'stdev': 0.0}},\n",
      " 'medium': {'e_size_density_bases': {'mean': 0.3880402844027247,\n",
      "                                     'median': 0.3506193895132783,\n",
      "                                     'stdev': 0.2249539729863082},\n",
      "            'e_size_density_vertex': {'mean': 0.3066413703953033,\n",
      "                                      'median': 0.25,\n",
      "                                      'stdev': 0.19626770165337587},\n",
      "            'max_prop_cov_bases': {'mean': 0.5401736275350122,\n",
      "                                   'median': 0.51438512856868,\n",
      "                                   'stdev': 0.2188190061428587},\n",
      "            'max_prop_cov_vertex': {'mean': 0.4450019392172136,\n",
      "                                    'median': 0.4,\n",
      "                                    'stdev': 0.20709432339980763},\n",
      "            'precision_bases': {'mean': 1.0, 'median': 1.0, 'stdev': 0.0},\n",
      "            'precision_vertex': {'mean': 1.0, 'median': 1.0, 'stdev': 0.0}},\n",
      " 'small': {'e_size_density_bases': {'mean': 0.654313133739445,\n",
      "                                    'median': 0.7110224973892528,\n",
      "                                    'stdev': 0.31359406932171224},\n",
      "           'e_size_density_vertex': {'mean': 0.5772616575166133,\n",
      "                                     'median': 0.5625,\n",
      "                                     'stdev': 0.29770134067929016},\n",
      "           'max_prop_cov_bases': {'mean': 0.7498024728634091,\n",
      "                                  'median': 0.8469945355191257,\n",
      "                                  'stdev': 0.2778714308952248},\n",
      "           'max_prop_cov_vertex': {'mean': 0.6827388943510315,\n",
      "                                   'median': 0.7142857142857143,\n",
      "                                   'stdev': 0.2663469580724349},\n",
      "           'precision_bases': {'mean': 1.0, 'median': 1.0, 'stdev': 0.0},\n",
      "           'precision_vertex': {'mean': 1.0, 'median': 1.0, 'stdev': 0.0}}}\n"
     ]
    }
   ],
   "source": [
    "def compute_fixed_rd_table_unitigs(limit_60, limit_30, components, vertices_inv):\n",
    "    transcripts = list()\n",
    "    genes = list()\n",
    "    for i, component in enumerate(components):\n",
    "        if component['len'] > 2 and len(component['transcript_paths']) > 1:\n",
    "            unitigs = component['unitigs']\n",
    "\n",
    "            for j, transcript in enumerate(component['transcript_paths']):\n",
    "                transcript = transcript['transcript_path']\n",
    "                \n",
    "                d = dict()\n",
    "                d['component'] = i\n",
    "                d['component_length'] = components[i]['len']\n",
    "                d['length'] = base_length(transcript, vertices_inv)\n",
    "                d['transcript'] = transcript\n",
    "                \n",
    "                \n",
    "                d['e_size_density_vertex'] =  component['e_sizes_vertex'][j]/len(transcript)\n",
    "                d['e_size_density_bases'] =  component['e_size_bases'][j]/d['length']\n",
    "                d['max_prop_cov_bases'] =  component['max_cov_bases'][j]/d['length']\n",
    "                d['max_prop_cov_vertex'] =  component['max_cov_vertex'][j]/len(transcript)\n",
    "\n",
    "                transcripts.append(d)\n",
    "                \n",
    "            d = dict()\n",
    "                \n",
    "            tp_bases = 0\n",
    "            tp_vertex = 0\n",
    "            for safe_path in component['true_positives']:\n",
    "                tp_bases += base_length(safe_path, vertices_inv)\n",
    "                tp_vertex += len(safe_path)\n",
    "\n",
    "            p_bases = tp_bases\n",
    "            p_vertex = tp_vertex\n",
    "            for safe_path in component['false_positives']:\n",
    "                p_bases += base_length(safe_path, vertices_inv)\n",
    "                p_vertex += len(safe_path)\n",
    "\n",
    "            d['precision_bases'] = 1.0 if p_bases == 0 else 1.0*tp_bases/p_bases\n",
    "            d['precision_vertex'] = 1.0 if p_vertex == 0 else 1.0*tp_vertex/p_vertex\n",
    "            d['component_length'] = component['len']\n",
    "            genes.append(d)\n",
    "\n",
    "    \n",
    "    \n",
    "    small = list(filter(lambda t: t['component_length'] <= limit_60, transcripts))\n",
    "    medium = list(filter(lambda t: t['component_length'] > limit_60 and t['component_length'] <= limit_30 , transcripts))\n",
    "    large = list(filter(lambda t: t['component_length'] > limit_30, transcripts))\n",
    "    \n",
    "    small_e_size_densities_vertex = list(map(lambda t: t['e_size_density_vertex'] , small))\n",
    "    medium_e_size_densities_vertex = list(map(lambda t: t['e_size_density_vertex'] , medium))\n",
    "    large_e_size_densities_vertex = list(map(lambda t: t['e_size_density_vertex'] , large))\n",
    "    \n",
    "    small_e_size_densities_bases = list(map(lambda t: t['e_size_density_bases'] , small))\n",
    "    medium_e_size_densities_bases = list(map(lambda t: t['e_size_density_bases'] , medium))\n",
    "    large_e_size_densities_bases = list(map(lambda t: t['e_size_density_bases'] , large))\n",
    "    \n",
    "    \n",
    "    small_max_prop_cov_vertex = list(map(lambda t: t['max_prop_cov_vertex'] , small))\n",
    "    medium_max_prop_cov_vertex = list(map(lambda t: t['max_prop_cov_vertex'] , medium))\n",
    "    large_max_prop_cov_vertex = list(map(lambda t: t['max_prop_cov_vertex'] , large))\n",
    "    \n",
    "    small_max_prop_cov_bases = list(map(lambda t: t['max_prop_cov_bases'] , small))\n",
    "    medium_max_prop_cov_bases = list(map(lambda t: t['max_prop_cov_bases'] , medium))\n",
    "    large_max_prop_cov_bases = list(map(lambda t: t['max_prop_cov_bases'] , large))\n",
    "    \n",
    "    \n",
    "    s = list(filter(lambda t: t['component_length'] <= limit_60, genes))\n",
    "    m = list(filter(lambda t: t['component_length'] > limit_60 and t['component_length'] <= limit_30 , genes))\n",
    "    l = list(filter(lambda t: t['component_length'] > limit_30, genes))\n",
    "    \n",
    "    s_precisions_bases = list(map(lambda t: t['precision_bases'] , s))\n",
    "    m_precisions_bases = list(map(lambda t: t['precision_bases'] , m))\n",
    "    l_precisions_bases = list(map(lambda t: t['precision_bases'] , l))\n",
    "    \n",
    "    s_precisions_vertex = list(map(lambda t: t['precision_vertex'] , s))\n",
    "    m_precisions_vertex = list(map(lambda t: t['precision_vertex'] , m))\n",
    "    l_precisions_vertex = list(map(lambda t: t['precision_vertex'] , l))\n",
    "    \n",
    "    \n",
    "    return { \n",
    "        'small':\n",
    "        {\n",
    "            'e_size_density_vertex': \n",
    "            {\n",
    "                'median': median(small_e_size_densities_vertex),\n",
    "                'mean': mean(small_e_size_densities_vertex),\n",
    "                'stdev': stdev(small_e_size_densities_vertex)\n",
    "            },\n",
    "            'e_size_density_bases': \n",
    "            {\n",
    "                'median': median(small_e_size_densities_bases),\n",
    "                'mean': mean(small_e_size_densities_bases),\n",
    "                'stdev': stdev(small_e_size_densities_bases)\n",
    "            },\n",
    "            'max_prop_cov_vertex':\n",
    "            {\n",
    "                'median': median(small_max_prop_cov_vertex),\n",
    "                'mean': mean(small_max_prop_cov_vertex),\n",
    "                'stdev': stdev(small_max_prop_cov_vertex)\n",
    "            },\n",
    "            'max_prop_cov_bases':\n",
    "            {\n",
    "                'median': median(small_max_prop_cov_bases),\n",
    "                'mean': mean(small_max_prop_cov_bases),\n",
    "                'stdev': stdev(small_max_prop_cov_bases)\n",
    "            },\n",
    "            'precision_bases':\n",
    "            {\n",
    "                'median': median(s_precisions_bases),\n",
    "                'mean': mean(s_precisions_bases),\n",
    "                'stdev': stdev(s_precisions_bases)\n",
    "            },\n",
    "            'precision_vertex':\n",
    "            {\n",
    "                'median': median(s_precisions_vertex),\n",
    "                'mean': mean(s_precisions_vertex),\n",
    "                'stdev': stdev(s_precisions_vertex)\n",
    "            }\n",
    "            \n",
    "        }\n",
    "        ,\n",
    "        'medium' :\n",
    "        {\n",
    "            'e_size_density_vertex': \n",
    "            {\n",
    "                'median': median(medium_e_size_densities_vertex),\n",
    "                'mean': mean(medium_e_size_densities_vertex),\n",
    "                'stdev': stdev(medium_e_size_densities_vertex)\n",
    "            },\n",
    "            'e_size_density_bases': \n",
    "            {\n",
    "                'median': median(medium_e_size_densities_bases),\n",
    "                'mean': mean(medium_e_size_densities_bases),\n",
    "                'stdev': stdev(medium_e_size_densities_bases)\n",
    "            },\n",
    "            'max_prop_cov_vertex':\n",
    "            {\n",
    "                'median': median(medium_max_prop_cov_vertex),\n",
    "                'mean': mean(medium_max_prop_cov_vertex),\n",
    "                'stdev': stdev(medium_max_prop_cov_vertex)\n",
    "            },\n",
    "            'max_prop_cov_bases':\n",
    "            {\n",
    "                'median': median(medium_max_prop_cov_bases),\n",
    "                'mean': mean(medium_max_prop_cov_bases),\n",
    "                'stdev': stdev(medium_max_prop_cov_bases)\n",
    "            },\n",
    "            'precision_bases':\n",
    "            {\n",
    "                'median': median(m_precisions_bases),\n",
    "                'mean': mean(m_precisions_bases),\n",
    "                'stdev': stdev(m_precisions_bases)\n",
    "            },\n",
    "            'precision_vertex':\n",
    "            {\n",
    "                'median': median(m_precisions_vertex),\n",
    "                'mean': mean(m_precisions_vertex),\n",
    "                'stdev': stdev(m_precisions_vertex)\n",
    "            }\n",
    "        },\n",
    "        'large':\n",
    "        {\n",
    "            'e_size_density_vertex': \n",
    "            {\n",
    "                'median': median(large_e_size_densities_vertex),\n",
    "                'mean': mean(large_e_size_densities_vertex),\n",
    "                'stdev': stdev(large_e_size_densities_vertex)\n",
    "            },\n",
    "            'e_size_density_bases': \n",
    "            {\n",
    "                'median': median(large_e_size_densities_bases),\n",
    "                'mean': mean(large_e_size_densities_bases),\n",
    "                'stdev': stdev(large_e_size_densities_bases)\n",
    "            },\n",
    "            'max_prop_cov_vertex':\n",
    "            {\n",
    "                'median': median(large_max_prop_cov_vertex),\n",
    "                'mean': mean(large_max_prop_cov_vertex),\n",
    "                'stdev': stdev(large_max_prop_cov_vertex)\n",
    "            },\n",
    "            'max_prop_cov_bases':\n",
    "            {\n",
    "                'median': median(large_max_prop_cov_bases),\n",
    "                'mean': mean(large_max_prop_cov_bases),\n",
    "                'stdev': stdev(large_max_prop_cov_bases)\n",
    "            },\n",
    "            'precision_bases':\n",
    "            {\n",
    "                'median': median(l_precisions_bases),\n",
    "                'mean': mean(l_precisions_bases),\n",
    "                'stdev': stdev(l_precisions_bases)\n",
    "            },\n",
    "            'precision_vertex':\n",
    "            {\n",
    "                'median': median(l_precisions_vertex),\n",
    "                'mean': mean(l_precisions_vertex),\n",
    "                'stdev': stdev(l_precisions_vertex)\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "pprint(compute_fixed_rd_table_unitigs(limit_size_60, limit_size_30, components, vertices_inv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'all': {'time': 642131},\n",
      " 'large': {'time': 4921},\n",
      " 'medium': {'time': 235311},\n",
      " 'small': {'time': 401899}}\n",
      "{'all': {'time': 787175},\n",
      " 'large': {'time': 13552},\n",
      " 'medium': {'time': 351338},\n",
      " 'small': {'time': 422285}}\n",
      "{'all': {'time': 1339464},\n",
      " 'large': {'time': 17558},\n",
      " 'medium': {'time': 698591},\n",
      " 'small': {'time': 623315}}\n",
      "{'all': {'time': 915354},\n",
      " 'large': {'time': 4831},\n",
      " 'medium': {'time': 359590},\n",
      " 'small': {'time': 550933}}\n"
     ]
    }
   ],
   "source": [
    "def compute_time_table(over_width, limit_60, limit_30, components, vertices_inv, algorithm_experiments='experiments'):\n",
    "    time = list()\n",
    "    for i, component in enumerate(components):\n",
    "        if component['len'] > 2 and len(component['transcript_paths']) > 1:\n",
    "            width = component['width']\n",
    "            l = str(width+over_width)\n",
    "            if over_width == -1:\n",
    "                l = str(len(component['transcript_paths']))\n",
    "            if over_width == -2:\n",
    "                l = str(2*component['width'])\n",
    "            if component[algorithm_experiments].get(l, None) is not None:\n",
    "                safe_paths_info = component[algorithm_experiments][l]\n",
    "\n",
    "                d = dict()\n",
    "                d['time'] = component[algorithm_experiments][l]['time_main']+component[algorithm_experiments][l]['time_filter']\n",
    "                d['component_length'] = component['len']\n",
    "                time.append(d)\n",
    "    \n",
    "    small = list(filter(lambda t: t['component_length'] <= limit_60, time))\n",
    "    medium = list(filter(lambda t: t['component_length'] > limit_60 and t['component_length'] <= limit_30 , time))\n",
    "    large = list(filter(lambda t: t['component_length'] > limit_30, time))\n",
    "    \n",
    "    return { \n",
    "        'small':\n",
    "        {\n",
    "            'time': sum(list(map(lambda x: x['time'] , small)))\n",
    "        }\n",
    "        ,\n",
    "        'medium' :\n",
    "        {\n",
    "            'time': sum(list(map(lambda x: x['time'] , medium)))\n",
    "        },\n",
    "        'large':\n",
    "        {\n",
    "            'time': sum(list(map(lambda x: x['time'] , large)))\n",
    "        },\n",
    "        'all':\n",
    "        {\n",
    "            'time': sum(list(map(lambda x: x['time'] , time)))\n",
    "        }\n",
    "    }\n",
    "\n",
    "pprint(compute_time_table(1, limit_size_60, limit_size_30, components, vertices_inv))\n",
    "pprint(compute_time_table(1, limit_size_60, limit_size_30, components, vertices_inv, 'experiments_two_finger'))\n",
    "pprint(compute_time_table(1, limit_size_60, limit_size_30, components, vertices_inv, 'experiments_unoptimized'))\n",
    "pprint(compute_time_table(1, limit_size_60, limit_size_30, components, vertices_inv, 'experiments_heuristic'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'large': {'max_cov_rel': {'mean': 0.9986652001946815,\n",
      "                           'median': 1.0,\n",
      "                           'stdev': 0.03398940464080226}},\n",
      " 'medium': {'max_cov_rel': {'mean': 0.9985217338396594,\n",
      "                            'median': 1.0,\n",
      "                            'stdev': 0.03807619503599188}},\n",
      " 'small': {'max_cov_rel': {'mean': 0.9972969796685862,\n",
      "                           'median': 1.0,\n",
      "                           'stdev': 0.051921282910762576}}}\n"
     ]
    }
   ],
   "source": [
    "def compute_cdss_coverage_table(over_width, limit_60, limit_30, components, vertices_inv):\n",
    "    cdss = list()\n",
    "    for i, component in enumerate(components):\n",
    "        if component['len'] > 2 and len(component['transcript_paths']) > 1:\n",
    "            width = component['width']\n",
    "            l = str(width+over_width)\n",
    "            if over_width == -1:\n",
    "                l = str(len(component['transcript_paths']))\n",
    "            if over_width == -2:\n",
    "                l = str(2*component['width'])\n",
    "            if component['experiments'].get(l, None) is None:\n",
    "                l = str(2*width)\n",
    "                \n",
    "            if component['experiments'].get(l, None) is not None:\n",
    "                safe_paths_info = component['experiments'][l]\n",
    "\n",
    "                for CDSs in safe_paths_info['cdss_coverage']:\n",
    "                    for CDS in CDSs:\n",
    "                        d = dict()\n",
    "                        d['component'] = i\n",
    "                        d['length'] = CDS['length']\n",
    "                        d['max_cov_rel'] = CDS['max_cov']/d['length']\n",
    "\n",
    "                        cdss.append(d)\n",
    "\n",
    "    \n",
    "    small = list(filter(lambda t: t['length'] <= limit_60, cdss))\n",
    "    medium = list(filter(lambda t: t['length'] > limit_60 and t['length'] <= limit_30 , cdss))\n",
    "    large = list(filter(lambda t: t['length'] > limit_30, cdss))\n",
    "    \n",
    "    \n",
    "    small_max_cov_rel = list(map(lambda t: t['max_cov_rel'] , small))\n",
    "    medium_max_cov_rel = list(map(lambda t: t['max_cov_rel'] , medium))\n",
    "    large_max_cov_rel = list(map(lambda t: t['max_cov_rel'] , large))\n",
    "\n",
    "    \n",
    "    \n",
    "    return { \n",
    "        'small':\n",
    "        {\n",
    "            'max_cov_rel': \n",
    "            {\n",
    "                'median': median(small_max_cov_rel),\n",
    "                'mean': mean(small_max_cov_rel),\n",
    "                'stdev': stdev(small_max_cov_rel)\n",
    "            }\n",
    "        }\n",
    "        ,\n",
    "        'medium' :\n",
    "        {\n",
    "            'max_cov_rel': \n",
    "            {\n",
    "                'median': median(medium_max_cov_rel),\n",
    "                'mean': mean(medium_max_cov_rel),\n",
    "                'stdev': stdev(medium_max_cov_rel)\n",
    "            }\n",
    "        },\n",
    "        'large':\n",
    "        {\n",
    "            'max_cov_rel': \n",
    "            {\n",
    "                'median': median(large_max_cov_rel),\n",
    "                'mean': mean(large_max_cov_rel),\n",
    "                'stdev': stdev(large_max_cov_rel)\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "pprint(compute_cdss_coverage_table(0, limit_cdss_60, limit_cdss_30, components, vertices_inv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'large': {'max_cov_rel': {'mean': 0.9088398513385607,\n",
      "                           'median': 1.0,\n",
      "                           'stdev': 0.2822083670913523}},\n",
      " 'medium': {'max_cov_rel': {'mean': 0.9423626692096354,\n",
      "                            'median': 1.0,\n",
      "                            'stdev': 0.22777643333392011}},\n",
      " 'small': {'max_cov_rel': {'mean': 0.9076126366773409,\n",
      "                           'median': 1.0,\n",
      "                           'stdev': 0.28797644782265364}}}\n"
     ]
    }
   ],
   "source": [
    "def compute_cdss_coverage_table_unitigs(limit_60, limit_30, components, vertices_inv):\n",
    "    cdss = list()\n",
    "    for i, component in enumerate(components):\n",
    "        if component['len'] > 2 and len(component['transcript_paths']) > 1:\n",
    "            for CDSs in component['cdss_coverage']:\n",
    "                for CDS in CDSs:\n",
    "                    d = dict()\n",
    "                    d['component'] = i\n",
    "                    d['length'] = CDS['length']\n",
    "                    d['max_cov_rel'] = CDS['max_cov']/d['length']\n",
    "\n",
    "                    cdss.append(d)\n",
    "\n",
    "    \n",
    "    \n",
    "    small = list(filter(lambda t: t['length'] <= limit_60, cdss))\n",
    "    medium = list(filter(lambda t: t['length'] > limit_60 and t['length'] <= limit_30 , cdss))\n",
    "    large = list(filter(lambda t: t['length'] > limit_30, cdss))\n",
    "    \n",
    "    \n",
    "    small_max_cov_rel = list(map(lambda t: t['max_cov_rel'] , small))\n",
    "    medium_max_cov_rel = list(map(lambda t: t['max_cov_rel'] , medium))\n",
    "    large_max_cov_rel = list(map(lambda t: t['max_cov_rel'] , large))\n",
    "\n",
    "    \n",
    "    \n",
    "    return { \n",
    "        'small':\n",
    "        {\n",
    "            'max_cov_rel': \n",
    "            {\n",
    "                'median': median(small_max_cov_rel),\n",
    "                'mean': mean(small_max_cov_rel),\n",
    "                'stdev': stdev(small_max_cov_rel)\n",
    "            }\n",
    "        }\n",
    "        ,\n",
    "        'medium' :\n",
    "        {\n",
    "            'max_cov_rel': \n",
    "            {\n",
    "                'median': median(medium_max_cov_rel),\n",
    "                'mean': mean(medium_max_cov_rel),\n",
    "                'stdev': stdev(medium_max_cov_rel)\n",
    "            }\n",
    "        },\n",
    "        'large':\n",
    "        {\n",
    "            'max_cov_rel': \n",
    "            {\n",
    "                'median': median(large_max_cov_rel),\n",
    "                'mean': mean(large_max_cov_rel),\n",
    "                'stdev': stdev(large_max_cov_rel)\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "pprint(compute_cdss_coverage_table_unitigs(limit_cdss_60, limit_cdss_30, components, vertices_inv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3648, 3676, 3684, 3688)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## And peak memory\n",
    "max(list(map(lambda x: 0 if x.get('experiments', None) is None else max(list(map(lambda k: x['experiments'][k]['peak_memory'], x['experiments'].keys()))),\n",
    "             components))), max(list(map(lambda x: 0 if x.get('experiments_two_finger', None) is None else max(list(map(lambda k: x['experiments_two_finger'][k]['peak_mem'], x['experiments_two_finger'].keys()))),\n",
    "             components))), max(list(map(lambda x: 0 if x.get('experiments_unoptimized', None) is None else max(list(map(lambda k: x['experiments_unoptimized'][k]['peak_mem'], x['experiments_unoptimized'].keys()))),\n",
    "             components))), max(list(map(lambda x: 0 if x.get('experiments_heuristic', None) is None else max(list(map(lambda k: x['experiments_heuristic'][k]['peak_mem'], x['experiments_heuristic'].keys()))),\n",
    "             components)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LATEX TABLE GENERATORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def trunc(number, decimals):\n",
    "    factor = 10.0 ** decimals\n",
    "    return math.trunc(number * factor) / factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(source, destination):\n",
    "    \"\"\"\n",
    "    run me with nosetests --with-doctest file.py\n",
    "\n",
    "    >>> a = { 'first' : { 'all_rows' : { 'pass' : 'dog', 'number' : '1' } } }\n",
    "    >>> b = { 'first' : { 'all_rows' : { 'fail' : 'cat', 'number' : '5' } } }\n",
    "    >>> merge(b, a) == { 'first' : { 'all_rows' : { 'pass' : 'dog', 'fail' : 'cat', 'number' : '5' } } }\n",
    "    True\n",
    "    \"\"\"\n",
    "    for key, value in source.items():\n",
    "        if isinstance(value, dict):\n",
    "            # get node or create one\n",
    "            node = destination.setdefault(key, {})\n",
    "            merge(value, node)\n",
    "        else:\n",
    "            destination[key] = value\n",
    "\n",
    "    return destination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{center}\n",
      "\\begin{tabular}{|c|cc|cc|cc|}\n",
      "\\hline\n",
      " & \\multicolumn{2}{c|}{small graphs (3-15 vertices)}  & \\multicolumn{2}{c|}{medium graphs (16-50 vertices)} & \\multicolumn{2}{c|}{large graphs (51-725 vertices)}    \\\\\n",
      "$\\ell$  & bases     & vertices      & bases     & vertices     & bases     & vertices     \\\\\\hline\\hline\n",
      "$k$  & \\cellx{2}{0.23\\\\0.24}  & \\cellx{2}{0.23\\\\0.24} & \\cellx{2}{0.23\\\\0.24}  & \\cellx{2}{0.23\\\\0.24}  & \\cellx{2}{0.23\\\\0.24}  & \\cellx{2}{0.23\\\\0.24} \\\\\\hline\n",
      "$k+1$  & \\cellx{2}{0.23\\\\0.24}  & \\cellx{2}{0.23\\\\0.24} & \\cellx{2}{0.23\\\\0.24}  & \\cellx{2}{0.23\\\\0.24}  & \\cellx{2}{0.23\\\\0.24}  & \\cellx{2}{0.23\\\\0.24} \\\\\\hline\n",
      "$t$  & \\cellx{2}{0.23\\\\0.24}  & \\cellx{2}{0.23\\\\0.24} & \\cellx{2}{0.23\\\\0.24}  & \\cellx{2}{0.23\\\\0.24}  & \\cellx{2}{0.23\\\\0.24}  & \\cellx{2}{0.23\\\\0.24} \\\\\\hline\n",
      "$2k$  & \\cellx{2}{0.23\\\\0.24}  & \\cellx{2}{0.23\\\\0.24} & \\cellx{2}{0.23\\\\0.24}  & \\cellx{2}{0.23\\\\0.24}  & \\cellx{2}{0.23\\\\0.24}  & \\cellx{2}{0.23\\\\0.24} \\\\\\hline\n",
      "\\end{tabular} \n",
      "\\end{center}\n"
     ]
    }
   ],
   "source": [
    "def format_number(n) :\n",
    "    if type(n) == int:\n",
    "        return str(n)\n",
    "    return f\"{n:.2f}\"\n",
    "\n",
    "def format_cell(data, key):\n",
    "    \n",
    "    mdata = data[key]\n",
    "    return f\"\"\"\\\\cellx{{2}}{{{format_number(mdata['abs_improvements_base']['mean'])}\\\\\\\\{format_number(mdata['rel_improvements_base']['mean'])}}}  & \\\\cellx{{2}}{{{format_number(mdata['abs_improvements_vertex']['mean'])}\\\\\\\\{format_number(mdata['rel_improvements_vertex']['mean'])}}}\"\"\"\n",
    "\n",
    "def format_row(data, key):\n",
    "    \n",
    "    mdata = data[key]\n",
    "    return f\"\"\"${key}$  & {format_cell(mdata, 'small')} & {format_cell(mdata, 'medium')}  & {format_cell(mdata, 'large')} \\\\\\\\\\\\hline\"\"\"\n",
    "\n",
    "def format_first_paper_table(data):\n",
    "    a = f\"\"\"\\\\begin{{center}}\n",
    "\\\\begin{{tabular}}{{|c|cc|cc|cc|}}\n",
    "\\\\hline\n",
    " & \\\\multicolumn{{2}}{{c|}}{{small graphs (3-{limit_size_60} vertices)}}  & \\\\multicolumn{{2}}{{c|}}{{medium graphs ({limit_size_60+1}-{limit_size_30} vertices)}} & \\\\multicolumn{{2}}{{c|}}{{large graphs ({limit_size_30+1}-{limit_size_10} vertices)}}    \\\\\\\\\n",
    "$\\\\ell$  & bases     & vertices      & bases     & vertices     & bases     & vertices     \\\\\\\\\\\\hline\\\\hline\n",
    "{format_row(data, 'k')}\n",
    "{format_row(data, 'k+1')}\n",
    "{format_row(data, 't')}\n",
    "{format_row(data, '2k')}\n",
    "\\\\end{{tabular}} \n",
    "\\\\end{{center}}\"\"\"\n",
    "    return a\n",
    "\n",
    "\n",
    "d = {\n",
    "    'k': {'small': {'abs_improvements_base': {'mean': 0.23, 'median': 0.22, 'stdev': 0.1}, 'abs_improvements_vertex': {'mean': 0.23, 'median': 0.22, 'stdev': 0.1}},'medium': {'abs_improvements_base': {'mean': 0.23, 'median': 0.22, 'stdev': 0.1}, 'abs_improvements_vertex': {'mean': 0.23, 'median': 0.22, 'stdev': 0.1}},'large': {'abs_improvements_base': {'mean': 0.23, 'median': 0.22, 'stdev': 0.1}, 'abs_improvements_vertex': {'mean': 0.23, 'median': 0.22, 'stdev': 0.1}}},\n",
    "    'k+1': {'small': {'abs_improvements_base': {'mean': 0.23, 'median': 0.22, 'stdev': 0.1}, 'abs_improvements_vertex': {'mean': 0.23, 'median': 0.22, 'stdev': 0.1}},'medium': {'abs_improvements_base': {'mean': 0.23, 'median': 0.22, 'stdev': 0.1}, 'abs_improvements_vertex': {'mean': 0.23, 'median': 0.22, 'stdev': 0.1}},'large': {'abs_improvements_base': {'mean': 0.23, 'median': 0.22, 'stdev': 0.1}, 'abs_improvements_vertex': {'mean': 0.23, 'median': 0.22, 'stdev': 0.1}}},\n",
    "    't': {'small': {'abs_improvements_base': {'mean': 0.23, 'median': 0.22, 'stdev': 0.1}, 'abs_improvements_vertex': {'mean': 0.23, 'median': 0.22, 'stdev': 0.1}},'medium': {'abs_improvements_base': {'mean': 0.23, 'median': 0.22, 'stdev': 0.1}, 'abs_improvements_vertex': {'mean': 0.23, 'median': 0.22, 'stdev': 0.1}},'large': {'abs_improvements_base': {'mean': 0.23, 'median': 0.22, 'stdev': 0.1}, 'abs_improvements_vertex': {'mean': 0.23, 'median': 0.22, 'stdev': 0.1}}},\n",
    "    '2k': {'small': {'abs_improvements_base': {'mean': 0.23, 'median': 0.22, 'stdev': 0.1}, 'abs_improvements_vertex': {'mean': 0.23, 'median': 0.22, 'stdev': 0.1}},'medium': {'abs_improvements_base': {'mean': 0.23, 'median': 0.22, 'stdev': 0.1}, 'abs_improvements_vertex': {'mean': 0.23, 'median': 0.22, 'stdev': 0.1}},'large': {'abs_improvements_base': {'mean': 0.23, 'median': 0.22, 'stdev': 0.1}, 'abs_improvements_vertex': {'mean': 0.23, 'median': 0.22, 'stdev': 0.1}}}\n",
    "}\n",
    "\n",
    "d2 = {\n",
    "    'k': {'small': {'rel_improvements_base': {'mean':  0.24, 'median': 0.22, 'stdev': 0.1}, 'rel_improvements_vertex': {'mean':  0.24, 'median': 0.22, 'stdev': 0.1}},'medium': {'rel_improvements_base': {'mean':  0.24, 'median': 0.22, 'stdev': 0.1}, 'rel_improvements_vertex': {'mean':  0.24, 'median': 0.22, 'stdev': 0.1}},'large': {'rel_improvements_base': {'mean':  0.24, 'median': 0.22, 'stdev': 0.1}, 'rel_improvements_vertex': {'mean':  0.24, 'median': 0.22, 'stdev': 0.1}}},\n",
    "    'k+1': {'small': {'rel_improvements_base': {'mean':  0.24, 'median': 0.22, 'stdev': 0.1}, 'rel_improvements_vertex': {'mean':  0.24, 'median': 0.22, 'stdev': 0.1}},'medium': {'rel_improvements_base': {'mean':  0.24, 'median': 0.22, 'stdev': 0.1}, 'rel_improvements_vertex': {'mean':  0.24, 'median': 0.22, 'stdev': 0.1}},'large': {'rel_improvements_base': {'mean':  0.24, 'median': 0.22, 'stdev': 0.1}, 'rel_improvements_vertex': {'mean':  0.24, 'median': 0.22, 'stdev': 0.1}}},\n",
    "    't': {'small': {'rel_improvements_base': {'mean':  0.24, 'median': 0.22, 'stdev': 0.1}, 'rel_improvements_vertex': {'mean':  0.24, 'median': 0.22, 'stdev': 0.1}},'medium': {'rel_improvements_base': {'mean':  0.24, 'median': 0.22, 'stdev': 0.1}, 'rel_improvements_vertex': {'mean':  0.24, 'median': 0.22, 'stdev': 0.1}},'large': {'rel_improvements_base': {'mean':  0.24, 'median': 0.22, 'stdev': 0.1}, 'rel_improvements_vertex': {'mean':  0.24, 'median': 0.22, 'stdev': 0.1}}},\n",
    "    '2k': {'small': {'rel_improvements_base': {'mean':  0.24, 'median': 0.22, 'stdev': 0.1}, 'rel_improvements_vertex': {'mean':  0.24, 'median': 0.22, 'stdev': 0.1}},'medium': {'rel_improvements_base': {'mean':  0.24, 'median': 0.22, 'stdev': 0.1}, 'rel_improvements_vertex': {'mean':  0.24, 'median': 0.22, 'stdev': 0.1}},'large': {'rel_improvements_base': {'mean':  0.24, 'median': 0.22, 'stdev': 0.1}, 'rel_improvements_vertex': {'mean':  0.24, 'median': 0.22, 'stdev': 0.1}}}\n",
    "}\n",
    "print(format_first_paper_table(merge(d,d2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_impr_dict = dict()\n",
    "\n",
    "abs_impr_dict['k'] = compute_abs_improvement_table(0, limit_size_60, limit_size_30, components, vertices_inv)\n",
    "abs_impr_dict['k+1'] = compute_abs_improvement_table(1, limit_size_60, limit_size_30, components, vertices_inv)\n",
    "abs_impr_dict['t'] = compute_abs_improvement_table(-1, limit_size_60, limit_size_30, components, vertices_inv)\n",
    "abs_impr_dict['2k'] = compute_abs_improvement_table(-2, limit_size_60, limit_size_30, components,vertices_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_impr_dict = dict()\n",
    "\n",
    "rel_impr_dict['k'] = compute_rel_improvement_table(0, limit_size_60, limit_size_30, components, vertices_inv)\n",
    "rel_impr_dict['k+1'] = compute_rel_improvement_table(1, limit_size_60, limit_size_30, components, vertices_inv)\n",
    "rel_impr_dict['t'] = compute_rel_improvement_table(-1, limit_size_60, limit_size_30, components, vertices_inv)\n",
    "rel_impr_dict['2k'] = compute_rel_improvement_table(-2, limit_size_60, limit_size_30, components,vertices_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{center}\n",
      "\\begin{tabular}{|c|cc|cc|cc|}\n",
      "\\hline\n",
      " & \\multicolumn{2}{c|}{small graphs (3-15 vertices)}  & \\multicolumn{2}{c|}{medium graphs (16-50 vertices)} & \\multicolumn{2}{c|}{large graphs (51-725 vertices)}    \\\\\n",
      "$\\ell$  & bases     & vertices      & bases     & vertices     & bases     & vertices     \\\\\\hline\\hline\n",
      "$k$  & \\cellx{2}{1209.32\\\\3.39}  & \\cellx{2}{2.99\\\\1.94} & \\cellx{2}{2554.14\\\\5.48}  & \\cellx{2}{6.63\\\\2.97}  & \\cellx{2}{3276.50\\\\5.56}  & \\cellx{2}{6.67\\\\2.96} \\\\\\hline\n",
      "$k+1$  & \\cellx{2}{662.90\\\\2.09}  & \\cellx{2}{1.59\\\\1.48} & \\cellx{2}{1339.42\\\\3.20}  & \\cellx{2}{3.61\\\\2.07}  & \\cellx{2}{3049.40\\\\5.33}  & \\cellx{2}{5.97\\\\2.67} \\\\\\hline\n",
      "$t$  & \\cellx{2}{662.90\\\\2.09}  & \\cellx{2}{1.59\\\\1.48} & \\cellx{2}{1339.30\\\\3.20}  & \\cellx{2}{3.61\\\\2.07}  & \\cellx{2}{3049.40\\\\5.33}  & \\cellx{2}{5.97\\\\2.67} \\\\\\hline\n",
      "$2k$  & \\cellx{2}{662.90\\\\2.09}  & \\cellx{2}{1.59\\\\1.48} & \\cellx{2}{1339.30\\\\3.20}  & \\cellx{2}{3.61\\\\2.07}  & \\cellx{2}{3049.40\\\\5.33}  & \\cellx{2}{5.97\\\\2.67} \\\\\\hline\n",
      "\\end{tabular} \n",
      "\\end{center}\n"
     ]
    }
   ],
   "source": [
    "impr_dict = merge(abs_impr_dict, rel_impr_dict)\n",
    "print(format_first_paper_table(impr_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{center}\n",
      "\\begin{tabular}{|c|cc|cc|cc|}\n",
      "\\hline\n",
      " & \\multicolumn{2}{c|}{small (1-2000 bases)}    & \\multicolumn{2}{c|}{medium (2001-5000 bases)} & \\multicolumn{2}{c|}{large (5001-205012 bases)}    \\\\\n",
      "$\\ell$  & \\texttt{esr}     & \\texttt{mcr}     & \\texttt{esr}     & \\texttt{mcr}    & \\texttt{esr}     & \\texttt{mcr}    \\\\\\hline\\hline\n",
      "$k$  & \\cell{2}{0.10\\\\0.20} & \\cell{2}{0.10\\\\0.20} & \\cell{2}{0.10\\\\0.20} & \\cell{2}{0.10\\\\0.20} & \\cell{2}{0.10\\\\0.20} & \\cell{2}{0.10\\\\0.20} \\\\\\hline\n",
      "$k+1$  & \\cell{2}{0.30\\\\0.40} & \\cell{2}{0.30\\\\0.40} & \\cell{2}{0.30\\\\0.40} & \\cell{2}{0.30\\\\0.40} & \\cell{2}{0.30\\\\0.40} & \\cell{2}{0.30\\\\0.40} \\\\\\hline\n",
      "$t$  & \\cell{2}{0.50\\\\0.60} & \\cell{2}{0.50\\\\0.60} & \\cell{2}{0.50\\\\0.60} & \\cell{2}{0.50\\\\0.60} & \\cell{2}{0.50\\\\0.60} & \\cell{2}{0.50\\\\0.60} \\\\\\hline\n",
      "$2k$  & \\cell{2}{0.50\\\\0.60} & \\cell{2}{0.50\\\\0.60} & \\cell{2}{0.50\\\\0.60} & \\cell{2}{0.50\\\\0.60} & \\cell{2}{0.50\\\\0.60} & \\cell{2}{0.50\\\\0.60} \\\\\\hline\\hline\n",
      "\\cell{1}{$ST$-\\\\unitigs}\n",
      "   & \\cell{2}{0.70\\\\0.80} & \\cell{2}{0.70\\\\0.80} & \\cell{2}{0.70\\\\0.80} & \\cell{2}{0.70\\\\0.80} & \\cell{2}{0.70\\\\0.80} & \\cell{2}{0.70\\\\0.80} \\\\\\hline\n",
      "\\end{tabular} \n",
      "\\end{center}\n"
     ]
    }
   ],
   "source": [
    "def format_number(n) :\n",
    "    if type(n) == int:\n",
    "        return str(n)\n",
    "    return f\"{trunc(n,2):.2f}\"\n",
    "\n",
    "def format_cell(data, key, variant):\n",
    "    \n",
    "    mdata = data[key]\n",
    "    return f\"\"\"\\\\cell{{2}}{{{format_number(mdata['e_size_density'+variant]['mean'])}\\\\\\\\{format_number(mdata['e_size_density'+variant]['median'])}}} & \\\\cell{{2}}{{{format_number(mdata['max_prop_cov'+variant]['mean'])}\\\\\\\\{format_number(mdata['max_prop_cov'+variant]['median'])}}}\"\"\"\n",
    "\n",
    "def format_row(data, key, variant):\n",
    "    \n",
    "    mdata = data[key]\n",
    "    return f\"\"\"{format_cell(mdata, 'small', variant)} & {format_cell(mdata, 'medium', variant)} & {format_cell(mdata, 'large', variant)} \\\\\\\\\\\\hline\"\"\"\n",
    "    \n",
    "\n",
    "def format_second_paper_table(data, variant=''):\n",
    "    \n",
    "    a = f\"\"\"\\\\begin{{center}}\n",
    "\\\\begin{{tabular}}{{|c|cc|cc|cc|}}\n",
    "\\\\hline\n",
    " & \\\\multicolumn{{2}}{{c|}}{{small (1-{limit_60} bases)}}    & \\\\multicolumn{{2}}{{c|}}{{medium ({limit_60+1}-{limit_30} bases)}} & \\\\multicolumn{{2}}{{c|}}{{large ({limit_30+1}-{limit_10} bases)}}    \\\\\\\\\n",
    "$\\\\ell$  & \\\\texttt{{esr}}     & \\\\texttt{{mcr}}     & \\\\texttt{{esr}}     & \\\\texttt{{mcr}}    & \\\\texttt{{esr}}     & \\\\texttt{{mcr}}    \\\\\\\\\\\\hline\\\\hline\n",
    "$k$  & {format_row(data, 'k', variant)}\n",
    "$k+1$  & {format_row(data, 'k+1', variant)}\n",
    "$t$  & {format_row(data, 't', variant)}\n",
    "$2k$  & {format_row(data, '2k', variant)}\\\\hline\n",
    "\\\\cell{{1}}{{$ST$-\\\\\\\\unitigs}}\n",
    "   & {format_row(data, 'unitigs', variant)}\n",
    "\\\\end{{tabular}} \n",
    "\\\\end{{center}}\"\"\"\n",
    "\n",
    "    return a\n",
    "\n",
    "d = {\n",
    "    'k': {'small': {'e_size_density': {'mean': 0.1, 'median': 0.2, 'stdev': 0.1}, 'max_prop_cov': {'mean': 0.1, 'median': 0.2, 'stdev': 0.1}},'medium': {'e_size_density': {'mean': 0.1, 'median': 0.2, 'stdev': 0.1}, 'max_prop_cov': {'mean': 0.1, 'median': 0.2, 'stdev': 0.1}},'large': {'e_size_density': {'mean': 0.1, 'median': 0.2, 'stdev': 0.1}, 'max_prop_cov': {'mean': 0.1, 'median': 0.2, 'stdev': 0.1}}},\n",
    "    'k+1': {'small': {'e_size_density': {'mean': 0.3, 'median': 0.4, 'stdev': 0.3}, 'max_prop_cov': {'mean': 0.3, 'median': 0.4, 'stdev': 0.3}},'medium': {'e_size_density': {'mean': 0.3, 'median': 0.4, 'stdev': 0.3}, 'max_prop_cov': {'mean': 0.3, 'median': 0.4, 'stdev': 0.3}},'large': {'e_size_density': {'mean': 0.3, 'median': 0.4, 'stdev': 0.3}, 'max_prop_cov': {'mean': 0.3, 'median': 0.4, 'stdev': 0.3}}},\n",
    "    't': {'small': {'e_size_density': {'mean': 0.5, 'median': 0.6, 'stdev': 0.5}, 'max_prop_cov': {'mean': 0.5, 'median': 0.6, 'stdev': 0.5}},'medium': {'e_size_density': {'mean': 0.5, 'median': 0.6, 'stdev': 0.5}, 'max_prop_cov': {'mean': 0.5, 'median': 0.6, 'stdev': 0.5}},'large': {'e_size_density': {'mean': 0.5, 'median': 0.6, 'stdev': 0.5}, 'max_prop_cov': {'mean': 0.5, 'median': 0.6, 'stdev': 0.5}}},\n",
    "    '2k': {'small': {'e_size_density': {'mean': 0.5, 'median': 0.6, 'stdev': 0.5}, 'max_prop_cov': {'mean': 0.5, 'median': 0.6, 'stdev': 0.5}},'medium': {'e_size_density': {'mean': 0.5, 'median': 0.6, 'stdev': 0.5}, 'max_prop_cov': {'mean': 0.5, 'median': 0.6, 'stdev': 0.5}},'large': {'e_size_density': {'mean': 0.5, 'median': 0.6, 'stdev': 0.5}, 'max_prop_cov': {'mean': 0.5, 'median': 0.6, 'stdev': 0.5}}},\n",
    "    'unitigs': {'small': {'e_size_density': {'mean': 0.7, 'median': 0.8, 'stdev': 0.7}, 'max_prop_cov': {'mean': 0.7, 'median': 0.8, 'stdev': 0.7}},'medium': {'e_size_density': {'mean': 0.7, 'median': 0.8, 'stdev': 0.7}, 'max_prop_cov': {'mean': 0.7, 'median': 0.8, 'stdev': 0.7}},'large': {'e_size_density': {'mean': 0.7, 'median': 0.8, 'stdev': 0.7}, 'max_prop_cov': {'mean': 0.7, 'median': 0.8, 'stdev': 0.7}}},\n",
    "}\n",
    "\n",
    "print(format_second_paper_table(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_l_dict = dict()\n",
    "fixed_l_dict['unitigs'] = compute_fixed_l_table_unitigs(limit_60, limit_30, components, vertices_inv)\n",
    "fixed_l_dict['k']  = compute_fixed_l_table(0, limit_60, limit_30, components, vertices_inv)\n",
    "fixed_l_dict['k+1']  = compute_fixed_l_table(1, limit_60, limit_30, components, vertices_inv)\n",
    "fixed_l_dict['t']  = compute_fixed_l_table(-1, limit_60, limit_30, components, vertices_inv)\n",
    "fixed_l_dict['2k']  = compute_fixed_l_table(-2, limit_60, limit_30, components, vertices_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{center}\n",
      "\\begin{tabular}{|c|cc|cc|cc|}\n",
      "\\hline\n",
      " & \\multicolumn{2}{c|}{small (1-2000 bases)}    & \\multicolumn{2}{c|}{medium (2001-5000 bases)} & \\multicolumn{2}{c|}{large (5001-205012 bases)}    \\\\\n",
      "$\\ell$  & \\texttt{esr}     & \\texttt{mcr}     & \\texttt{esr}     & \\texttt{mcr}    & \\texttt{esr}     & \\texttt{mcr}    \\\\\\hline\\hline\n",
      "$k$  & \\cell{2}{0.86\\\\0.97} & \\cell{2}{0.92\\\\1.00} & \\cell{2}{0.73\\\\0.78} & \\cell{2}{0.82\\\\0.90} & \\cell{2}{0.61\\\\0.56} & \\cell{2}{0.73\\\\0.73} \\\\\\hline\n",
      "$k+1$  & \\cell{2}{0.83\\\\0.92} & \\cell{2}{0.90\\\\1.00} & \\cell{2}{0.70\\\\0.73} & \\cell{2}{0.80\\\\0.87} & \\cell{2}{0.58\\\\0.52} & \\cell{2}{0.70\\\\0.70} \\\\\\hline\n",
      "$t$  & \\cell{2}{0.83\\\\0.92} & \\cell{2}{0.90\\\\1.00} & \\cell{2}{0.70\\\\0.73} & \\cell{2}{0.80\\\\0.87} & \\cell{2}{0.58\\\\0.52} & \\cell{2}{0.70\\\\0.70} \\\\\\hline\n",
      "$2k$  & \\cell{2}{0.83\\\\0.92} & \\cell{2}{0.90\\\\1.00} & \\cell{2}{0.70\\\\0.73} & \\cell{2}{0.80\\\\0.87} & \\cell{2}{0.58\\\\0.52} & \\cell{2}{0.70\\\\0.70} \\\\\\hline\\hline\n",
      "\\cell{1}{$ST$-\\\\unitigs}\n",
      "   & \\cell{2}{0.66\\\\0.74} & \\cell{2}{0.74\\\\0.87} & \\cell{2}{0.55\\\\0.52} & \\cell{2}{0.67\\\\0.70} & \\cell{2}{0.46\\\\0.42} & \\cell{2}{0.60\\\\0.58} \\\\\\hline\n",
      "\\end{tabular} \n",
      "\\end{center}\n"
     ]
    }
   ],
   "source": [
    "print(format_second_paper_table(fixed_l_dict, '_bases'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{center}\n",
      "\\begin{tabular}{|c|cc|cc|cc|}\n",
      "\\hline\n",
      " & \\multicolumn{2}{c|}{small (1-2000 bases)}    & \\multicolumn{2}{c|}{medium (2001-5000 bases)} & \\multicolumn{2}{c|}{large (5001-205012 bases)}    \\\\\n",
      "$\\ell$  & \\texttt{esr}     & \\texttt{mcr}     & \\texttt{esr}     & \\texttt{mcr}    & \\texttt{esr}     & \\texttt{mcr}    \\\\\\hline\\hline\n",
      "$k$  & \\cell{2}{0.82\\\\0.90} & \\cell{2}{0.87\\\\1.00} & \\cell{2}{0.67\\\\0.67} & \\cell{2}{0.77\\\\0.81} & \\cell{2}{0.54\\\\0.49} & \\cell{2}{0.66\\\\0.64} \\\\\\hline\n",
      "$k+1$  & \\cell{2}{0.77\\\\0.87} & \\cell{2}{0.85\\\\1.00} & \\cell{2}{0.63\\\\0.62} & \\cell{2}{0.75\\\\0.77} & \\cell{2}{0.50\\\\0.45} & \\cell{2}{0.63\\\\0.60} \\\\\\hline\n",
      "$t$  & \\cell{2}{0.77\\\\0.87} & \\cell{2}{0.85\\\\1.00} & \\cell{2}{0.63\\\\0.62} & \\cell{2}{0.75\\\\0.77} & \\cell{2}{0.50\\\\0.45} & \\cell{2}{0.63\\\\0.60} \\\\\\hline\n",
      "$2k$  & \\cell{2}{0.77\\\\0.87} & \\cell{2}{0.85\\\\1.00} & \\cell{2}{0.63\\\\0.62} & \\cell{2}{0.75\\\\0.77} & \\cell{2}{0.50\\\\0.45} & \\cell{2}{0.63\\\\0.60} \\\\\\hline\\hline\n",
      "\\cell{1}{$ST$-\\\\unitigs}\n",
      "   & \\cell{2}{0.60\\\\0.56} & \\cell{2}{0.69\\\\0.75} & \\cell{2}{0.46\\\\0.42} & \\cell{2}{0.59\\\\0.60} & \\cell{2}{0.37\\\\0.30} & \\cell{2}{0.49\\\\0.45} \\\\\\hline\n",
      "\\end{tabular} \n",
      "\\end{center}\n"
     ]
    }
   ],
   "source": [
    "## This is the fifth table\n",
    "print(format_second_paper_table(fixed_l_dict, '_vertex'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{center}\n",
      "    \\begin{tabular}{|c|ccc|ccc|ccc|}\n",
      "\\hline\n",
      " & \\multicolumn{3}{c|}{small graphs (3-15 vertices)}        & \\multicolumn{3}{c|}{medium graphs (16-50 vertices)}     & \\multicolumn{3}{c|}{large graphs (51-725 vertices)}          \\\\\n",
      "$\\ell$  & \\texttt{prec}   & \\texttt{esr}     & \\texttt{mcr}    & \\texttt{prec}   & \\texttt{esr}     & \\texttt{mcr}    & \\texttt{prec}   & \\texttt{esr}     & \\texttt{mcr}    \\\\\\hline\\hline\n",
      "$k$  & \\cell{1}{0.23\\\\0.22}  & \\cell{1}{0.23\\\\0.22}  & \\cell{1}{0.23\\\\0.22}  & \\cell{1}{0.23\\\\0.22}  & \\cell{1}{0.23\\\\0.22}  & \\cell{1}{0.23\\\\0.22} & \\cell{1}{0.23\\\\0.22}  & \\cell{1}{0.23\\\\0.22}  & \\cell{1}{0.23\\\\0.22}  \\\\\\hline\n",
      "$k+1$  & \\cell{1}{0.34\\\\0.22}  & \\cell{1}{0.23\\\\0.22}  & \\cell{1}{0.23\\\\0.22}  & \\cell{1}{0.23\\\\0.22}  & \\cell{1}{0.23\\\\0.22}  & \\cell{1}{0.23\\\\0.22} & \\cell{1}{0.23\\\\0.22}  & \\cell{1}{0.23\\\\0.22}  & \\cell{1}{0.23\\\\0.22}  \\\\\\hline\n",
      "$t$  & \\cell{1}{0.45\\\\0.22}  & \\cell{1}{0.23\\\\0.22}  & \\cell{1}{0.23\\\\0.22}  & \\cell{1}{0.23\\\\0.22}  & \\cell{1}{0.23\\\\0.22}  & \\cell{1}{0.23\\\\0.22} & \\cell{1}{0.23\\\\0.22}  & \\cell{1}{0.23\\\\0.22}  & \\cell{1}{0.23\\\\0.22}  \\\\\\hline\n",
      "$2k$  & \\cell{1}{0.46\\\\0.22}  & \\cell{1}{0.23\\\\0.22}  & \\cell{1}{0.23\\\\0.22}  & \\cell{1}{0.23\\\\0.22}  & \\cell{1}{0.23\\\\0.22}  & \\cell{1}{0.23\\\\0.22} & \\cell{1}{0.23\\\\0.22}  & \\cell{1}{0.23\\\\0.22}  & \\cell{1}{0.23\\\\0.22}  \\\\\\hline\\hline\n",
      "\\cell{1}{$ST$-\\\\unitigs} \n",
      "  & \\cell{1}{0.56\\\\0.22}  & \\cell{1}{0.23\\\\0.22}  & \\cell{1}{0.23\\\\0.22}  & \\cell{1}{0.23\\\\0.22}  & \\cell{1}{0.23\\\\0.22}  & \\cell{1}{0.23\\\\0.22} & \\cell{1}{0.23\\\\0.22}  & \\cell{1}{0.23\\\\0.22}  & \\cell{1}{0.23\\\\0.22}  \\\\\\hline\n",
      "\\end{tabular} \n",
      "\\end{center}\n"
     ]
    }
   ],
   "source": [
    "def format_number(n) :\n",
    "    if type(n) == int:\n",
    "        return str(n)\n",
    "    return f\"{trunc(n,2):.2f}\"\n",
    "\n",
    "def format_cell(data, key, variant):\n",
    "    \n",
    "    mdata = data[key]\n",
    "    return f\"\"\"\\\\cell{{1}}{{{format_number(mdata['precision'+variant]['mean'])}\\\\\\\\{format_number(mdata['precision'+variant]['median'])}}}  & \\\\cell{{1}}{{{format_number(mdata['e_size_density'+variant]['mean'])}\\\\\\\\{format_number(mdata['e_size_density'+variant]['median'])}}}  & \\\\cell{{1}}{{{format_number(mdata['max_prop_cov'+variant]['mean'])}\\\\\\\\{format_number(mdata['max_prop_cov'+variant]['median'])}}}\"\"\"\n",
    "    \n",
    "def format_row(data, key, variant):\n",
    "    \n",
    "    mdata = data[key]\n",
    "    return f\"\"\"{format_cell(mdata, 'small', variant)}  & {format_cell(mdata, 'medium', variant)} & {format_cell(mdata, 'large', variant)}  \\\\\\\\\\\\hline\"\"\"\n",
    "    \n",
    "\n",
    "def format_third_paper_table(data, variant=''):\n",
    "    \n",
    "    a = f\"\"\"\\\\begin{{center}}\n",
    "    \\\\begin{{tabular}}{{|c|ccc|ccc|ccc|}}\n",
    "\\\\hline\n",
    " & \\\\multicolumn{{3}}{{c|}}{{small graphs (3-{limit_size_60} vertices)}}        & \\\\multicolumn{{3}}{{c|}}{{medium graphs ({limit_size_60+1}-{limit_size_30} vertices)}}     & \\\\multicolumn{{3}}{{c|}}{{large graphs ({limit_size_30+1}-{limit_size_10} vertices)}}          \\\\\\\\\n",
    "$\\\\ell$  & \\\\texttt{{prec}}   & \\\\texttt{{esr}}     & \\\\texttt{{mcr}}    & \\\\texttt{{prec}}   & \\\\texttt{{esr}}     & \\\\texttt{{mcr}}    & \\\\texttt{{prec}}   & \\\\texttt{{esr}}     & \\\\texttt{{mcr}}    \\\\\\\\\\\\hline\\\\hline\n",
    "$k$  & {format_row(data, 'k', variant)}\n",
    "$k+1$  & {format_row(data, 'k+1', variant)}\n",
    "$t$  & {format_row(data, 't', variant)}\n",
    "$2k$  & {format_row(data, '2k', variant)}\\\\hline\n",
    "\\\\cell{{1}}{{$ST$-\\\\\\\\unitigs}} \n",
    "  & {format_row(data, 'unitigs', variant)}\n",
    "\\\\end{{tabular}} \n",
    "\\\\end{{center}}\"\"\"\n",
    "    \n",
    "    return a\n",
    "\n",
    "d = {\n",
    "    'k': {'small': {'precision': {'mean': 0.23, 'median': 0.22, 'stdev': 0.1}, 'e_size_density': {'mean': 0.23, 'median': 0.22, 'stdev': 0.1}, 'max_prop_cov': {'mean': 0.23, 'median': 0.22, 'stdev': 0.1}},'medium': {'precision': {'mean': 0.23, 'median': 0.22, 'stdev': 0.1}, 'e_size_density': {'mean': 0.23, 'median': 0.22, 'stdev': 0.1}, 'max_prop_cov': {'mean': 0.23, 'median': 0.22, 'stdev': 0.1}},'large': {'precision': {'mean': 0.23, 'median': 0.22, 'stdev': 0.1}, 'e_size_density': {'mean': 0.23, 'median': 0.22, 'stdev': 0.1}, 'max_prop_cov': {'mean': 0.23, 'median': 0.22, 'stdev': 0.1}}},\n",
    "    'k+1': {'small': {'precision': {'mean': 0.34, 'median': 0.22, 'stdev': 0.1}, 'e_size_density': {'mean': 0.23, 'median': 0.22, 'stdev': 0.1}, 'max_prop_cov': {'mean': 0.23, 'median': 0.22, 'stdev': 0.1}},'medium': {'precision': {'mean': 0.23, 'median': 0.22, 'stdev': 0.1}, 'e_size_density': {'mean': 0.23, 'median': 0.22, 'stdev': 0.1}, 'max_prop_cov': {'mean': 0.23, 'median': 0.22, 'stdev': 0.1}},'large': {'precision': {'mean': 0.23, 'median': 0.22, 'stdev': 0.1}, 'e_size_density': {'mean': 0.23, 'median': 0.22, 'stdev': 0.1}, 'max_prop_cov': {'mean': 0.23, 'median': 0.22, 'stdev': 0.1}}},\n",
    "    't': {'small': {'precision': {'mean': 0.45, 'median': 0.22, 'stdev': 0.1}, 'e_size_density': {'mean': 0.23, 'median': 0.22, 'stdev': 0.1}, 'max_prop_cov': {'mean': 0.23, 'median': 0.22, 'stdev': 0.1}},'medium': {'precision': {'mean': 0.23, 'median': 0.22, 'stdev': 0.1}, 'e_size_density': {'mean': 0.23, 'median': 0.22, 'stdev': 0.1}, 'max_prop_cov': {'mean': 0.23, 'median': 0.22, 'stdev': 0.1}},'large': {'precision': {'mean': 0.23, 'median': 0.22, 'stdev': 0.1}, 'e_size_density': {'mean': 0.23, 'median': 0.22, 'stdev': 0.1}, 'max_prop_cov': {'mean': 0.23, 'median': 0.22, 'stdev': 0.1}}},\n",
    "    '2k': {'small': {'precision': {'mean': 0.46, 'median': 0.22, 'stdev': 0.1}, 'e_size_density': {'mean': 0.23, 'median': 0.22, 'stdev': 0.1}, 'max_prop_cov': {'mean': 0.23, 'median': 0.22, 'stdev': 0.1}},'medium': {'precision': {'mean': 0.23, 'median': 0.22, 'stdev': 0.1}, 'e_size_density': {'mean': 0.23, 'median': 0.22, 'stdev': 0.1}, 'max_prop_cov': {'mean': 0.23, 'median': 0.22, 'stdev': 0.1}},'large': {'precision': {'mean': 0.23, 'median': 0.22, 'stdev': 0.1}, 'e_size_density': {'mean': 0.23, 'median': 0.22, 'stdev': 0.1}, 'max_prop_cov': {'mean': 0.23, 'median': 0.22, 'stdev': 0.1}}},\n",
    "    'unitigs': {'small': {'precision': {'mean': 0.56, 'median': 0.22, 'stdev': 0.1}, 'e_size_density': {'mean': 0.23, 'median': 0.22, 'stdev': 0.1}, 'max_prop_cov': {'mean': 0.23, 'median': 0.22, 'stdev': 0.1}},'medium': {'precision': {'mean': 0.23, 'median': 0.22, 'stdev': 0.1}, 'e_size_density': {'mean': 0.23, 'median': 0.22, 'stdev': 0.1}, 'max_prop_cov': {'mean': 0.23, 'median': 0.22, 'stdev': 0.1}},'large': {'precision': {'mean': 0.23, 'median': 0.22, 'stdev': 0.1}, 'e_size_density': {'mean': 0.23, 'median': 0.22, 'stdev': 0.1}, 'max_prop_cov': {'mean': 0.23, 'median': 0.22, 'stdev': 0.1}}}\n",
    "}\n",
    "\n",
    "print(format_third_paper_table(d))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_rd_dict = dict()\n",
    "\n",
    "fixed_rd_dict['k'] = compute_fixed_rd_table(0, limit_size_60, limit_size_30, components, vertices_inv)\n",
    "fixed_rd_dict['k+1'] = compute_fixed_rd_table(1, limit_size_60, limit_size_30, components, vertices_inv)\n",
    "fixed_rd_dict['t'] = compute_fixed_rd_table(-1, limit_size_60, limit_size_30, components, vertices_inv)\n",
    "fixed_rd_dict['2k'] = compute_fixed_rd_table(-2, limit_size_60, limit_size_30, components, vertices_inv)\n",
    "fixed_rd_dict['unitigs'] = compute_fixed_rd_table_unitigs(limit_size_60, limit_size_30, components, vertices_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{center}\n",
      "    \\begin{tabular}{|c|ccc|ccc|ccc|}\n",
      "\\hline\n",
      " & \\multicolumn{3}{c|}{small graphs (3-15 vertices)}        & \\multicolumn{3}{c|}{medium graphs (16-50 vertices)}     & \\multicolumn{3}{c|}{large graphs (51-725 vertices)}          \\\\\n",
      "$\\ell$  & \\texttt{prec}   & \\texttt{esr}     & \\texttt{mcr}    & \\texttt{prec}   & \\texttt{esr}     & \\texttt{mcr}    & \\texttt{prec}   & \\texttt{esr}     & \\texttt{mcr}    \\\\\\hline\\hline\n",
      "$k$  & \\cell{1}{0.84\\\\1.00}  & \\cell{1}{0.85\\\\0.94}  & \\cell{1}{0.90\\\\1.00}  & \\cell{1}{0.82\\\\1.00}  & \\cell{1}{0.53\\\\0.48}  & \\cell{1}{0.67\\\\0.65} & \\cell{1}{1.00\\\\1.00}  & \\cell{1}{0.52\\\\0.45}  & \\cell{1}{0.69\\\\0.67}  \\\\\\hline\n",
      "$k+1$  & \\cell{1}{1.00\\\\1.00}  & \\cell{1}{0.81\\\\0.88}  & \\cell{1}{0.89\\\\0.98}  & \\cell{1}{1.00\\\\1.00}  & \\cell{1}{0.51\\\\0.46}  & \\cell{1}{0.65\\\\0.63} & \\cell{1}{1.00\\\\1.00}  & \\cell{1}{0.50\\\\0.37}  & \\cell{1}{0.67\\\\0.58}  \\\\\\hline\n",
      "$t$  & \\cell{1}{1.00\\\\1.00}  & \\cell{1}{0.81\\\\0.88}  & \\cell{1}{0.89\\\\0.98}  & \\cell{1}{1.00\\\\1.00}  & \\cell{1}{0.50\\\\0.46}  & \\cell{1}{0.65\\\\0.63} & \\cell{1}{1.00\\\\1.00}  & \\cell{1}{0.50\\\\0.37}  & \\cell{1}{0.67\\\\0.58}  \\\\\\hline\n",
      "$2k$  & \\cell{1}{1.00\\\\1.00}  & \\cell{1}{0.81\\\\0.88}  & \\cell{1}{0.89\\\\0.98}  & \\cell{1}{1.00\\\\1.00}  & \\cell{1}{0.50\\\\0.46}  & \\cell{1}{0.65\\\\0.63} & \\cell{1}{1.00\\\\1.00}  & \\cell{1}{0.50\\\\0.37}  & \\cell{1}{0.67\\\\0.58}  \\\\\\hline\\hline\n",
      "\\cell{1}{$ST$-\\\\unitigs} \n",
      "  & \\cell{1}{1.00\\\\1.00}  & \\cell{1}{0.65\\\\0.71}  & \\cell{1}{0.74\\\\0.84}  & \\cell{1}{1.00\\\\1.00}  & \\cell{1}{0.38\\\\0.35}  & \\cell{1}{0.54\\\\0.51} & \\cell{1}{1.00\\\\1.00}  & \\cell{1}{0.41\\\\0.30}  & \\cell{1}{0.58\\\\0.46}  \\\\\\hline\n",
      "\\end{tabular} \n",
      "\\end{center}\n"
     ]
    }
   ],
   "source": [
    "print(format_third_paper_table(fixed_rd_dict, '_bases'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{center}\n",
      "    \\begin{tabular}{|c|ccc|ccc|ccc|}\n",
      "\\hline\n",
      " & \\multicolumn{3}{c|}{small graphs (3-15 vertices)}        & \\multicolumn{3}{c|}{medium graphs (16-50 vertices)}     & \\multicolumn{3}{c|}{large graphs (51-725 vertices)}          \\\\\n",
      "$\\ell$  & \\texttt{prec}   & \\texttt{esr}     & \\texttt{mcr}    & \\texttt{prec}   & \\texttt{esr}     & \\texttt{mcr}    & \\texttt{prec}   & \\texttt{esr}     & \\texttt{mcr}    \\\\\\hline\\hline\n",
      "$k$  & \\cell{1}{0.84\\\\1.00}  & \\cell{1}{0.79\\\\0.87}  & \\cell{1}{0.86\\\\1.00}  & \\cell{1}{0.82\\\\1.00}  & \\cell{1}{0.47\\\\0.41}  & \\cell{1}{0.61\\\\0.58} & \\cell{1}{1.00\\\\1.00}  & \\cell{1}{0.41\\\\0.26}  & \\cell{1}{0.56\\\\0.48}  \\\\\\hline\n",
      "$k+1$  & \\cell{1}{1.00\\\\1.00}  & \\cell{1}{0.75\\\\0.79}  & \\cell{1}{0.83\\\\0.90}  & \\cell{1}{1.00\\\\1.00}  & \\cell{1}{0.44\\\\0.39}  & \\cell{1}{0.59\\\\0.56} & \\cell{1}{1.00\\\\1.00}  & \\cell{1}{0.39\\\\0.26}  & \\cell{1}{0.54\\\\0.48}  \\\\\\hline\n",
      "$t$  & \\cell{1}{1.00\\\\1.00}  & \\cell{1}{0.75\\\\0.79}  & \\cell{1}{0.83\\\\0.90}  & \\cell{1}{1.00\\\\1.00}  & \\cell{1}{0.44\\\\0.39}  & \\cell{1}{0.58\\\\0.56} & \\cell{1}{1.00\\\\1.00}  & \\cell{1}{0.39\\\\0.26}  & \\cell{1}{0.54\\\\0.48}  \\\\\\hline\n",
      "$2k$  & \\cell{1}{1.00\\\\1.00}  & \\cell{1}{0.75\\\\0.79}  & \\cell{1}{0.83\\\\0.90}  & \\cell{1}{1.00\\\\1.00}  & \\cell{1}{0.44\\\\0.39}  & \\cell{1}{0.58\\\\0.56} & \\cell{1}{1.00\\\\1.00}  & \\cell{1}{0.39\\\\0.26}  & \\cell{1}{0.54\\\\0.48}  \\\\\\hline\\hline\n",
      "\\cell{1}{$ST$-\\\\unitigs} \n",
      "  & \\cell{1}{1.00\\\\1.00}  & \\cell{1}{0.57\\\\0.56}  & \\cell{1}{0.68\\\\0.71}  & \\cell{1}{1.00\\\\1.00}  & \\cell{1}{0.30\\\\0.25}  & \\cell{1}{0.44\\\\0.40} & \\cell{1}{1.00\\\\1.00}  & \\cell{1}{0.29\\\\0.15}  & \\cell{1}{0.42\\\\0.34}  \\\\\\hline\n",
      "\\end{tabular} \n",
      "\\end{center}\n"
     ]
    }
   ],
   "source": [
    "## This is the sixth table\n",
    "print(format_third_paper_table(fixed_rd_dict, '_vertex'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}\n",
      "\\begin{tabular}{l|l|l|l|l|}\n",
      "\\cline{2-5}\n",
      "                       & \\multicolumn{4}{c|}{$\\ell = k$} \\\\ \\hline\n",
      "\\multicolumn{1}{|l|}{Gene graph sets} & Unoptimized (secs) & Two Finger (secs) & Optimized (secs) & Heuristic (secs) \\\\ \\hline\n",
      "\\multicolumn{1}{|l|}{small, 3-15 vertices} & 0.59  & 0.59 & 0.59 & 0.59\\\\ \\hline\n",
      "\\multicolumn{1}{|l|}{medium, 16-50 vertices} & 0.92 & 0.92 & 0.92 & 0.92\\\\ \\hline\n",
      "\\multicolumn{1}{|l|}{large, 51-725 vertices} & 23.27 & 23.27 & 23.27 & 23.27\\\\ \\hline\n",
      "\\multicolumn{1}{|l|}{all, 3-725 vertices}  & 24.78 & 24.78 & 24.78 & 24.78\\\\ \\hline\n",
      "\\end{tabular}\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "def format_time(time):\n",
    "    return f'{time/1000000:.2f}'\n",
    "\n",
    "def format_fourth_table(data, rl):\n",
    "    a = f\"\"\"\\\\begin{{table}}\n",
    "\\\\begin{{tabular}}{{l|l|l|l|l|}}\n",
    "\\\\cline{{2-5}}\n",
    "                       & \\\\multicolumn{{4}}{{c|}}{{$\\\\ell = {rl}$}} \\\\\\\\ \\\\hline\n",
    "\\\\multicolumn{{1}}{{|l|}}{{Gene graph sets}} & Unoptimized (secs) & Two Finger (secs) & Optimized (secs) & Heuristic (secs) \\\\\\\\ \\\\hline\n",
    "\\\\multicolumn{{1}}{{|l|}}{{small, 3-{limit_size_60} vertices}} & {format_time(data[rl]['unoptimized']['small']['time'])}  & {format_time(data[rl]['two_finger']['small']['time'])} & {format_time(data[rl]['optimized']['small']['time'])} & {format_time(data[rl]['heuristic']['small']['time'])}\\\\\\\\ \\\\hline\n",
    "\\\\multicolumn{{1}}{{|l|}}{{medium, {limit_size_60+1}-{limit_size_30} vertices}} & {format_time(data[rl]['unoptimized']['medium']['time'])} & {format_time(data[rl]['two_finger']['medium']['time'])} & {format_time(data[rl]['optimized']['medium']['time'])} & {format_time(data[rl]['heuristic']['medium']['time'])}\\\\\\\\ \\\\hline\n",
    "\\\\multicolumn{{1}}{{|l|}}{{large, {limit_size_30+1}-{limit_size_10} vertices}} & {format_time(data[rl]['unoptimized']['large']['time'])} & {format_time(data[rl]['two_finger']['large']['time'])} & {format_time(data[rl]['optimized']['large']['time'])} & {format_time(data[rl]['heuristic']['large']['time'])}\\\\\\\\ \\\\hline\n",
    "\\\\multicolumn{{1}}{{|l|}}{{all, 3-{limit_size_10} vertices}}  & {format_time(data[rl]['unoptimized']['all']['time'])} & {format_time(data[rl]['two_finger']['all']['time'])} & {format_time(data[rl]['optimized']['all']['time'])} & {format_time(data[rl]['heuristic']['all']['time'])}\\\\\\\\ \\\\hline\n",
    "\\\\end{{tabular}}\n",
    "\\\\end{{table}}\"\"\"\n",
    "    return a\n",
    "\n",
    "d = {\n",
    "    'k': {\n",
    "            'optimized': {\n",
    "                'all': {'time': 24781434},\n",
    "                 'large': {'time': 23265773},\n",
    "                 'medium': {'time': 922717},\n",
    "                 'small': {'time': 592944}\n",
    "            },\n",
    "            'heuristic': {\n",
    "                'all': {'time': 24781434},\n",
    "                 'large': {'time': 23265773},\n",
    "                 'medium': {'time': 922717},\n",
    "                 'small': {'time': 592944}\n",
    "            },\n",
    "            'unoptimized': {\n",
    "                'all': {'time': 24781434},\n",
    "                 'large': {'time': 23265773},\n",
    "                 'medium': {'time': 922717},\n",
    "                 'small': {'time': 592944}\n",
    "            },\n",
    "            'two_finger': {\n",
    "                'all': {'time': 24781434},\n",
    "                 'large': {'time': 23265773},\n",
    "                 'medium': {'time': 922717},\n",
    "                 'small': {'time': 592944}\n",
    "            }\n",
    "    },\n",
    "    'k+1': {\n",
    "            'optimized': {\n",
    "                'all': {'time': 24781434},\n",
    "                 'large': {'time': 23265773},\n",
    "                 'medium': {'time': 922717},\n",
    "                 'small': {'time': 592944}\n",
    "            },\n",
    "            'heuristic': {\n",
    "                'all': {'time': 24781434},\n",
    "                 'large': {'time': 23265773},\n",
    "                 'medium': {'time': 922717},\n",
    "                 'small': {'time': 592944}\n",
    "            },\n",
    "            'unoptimized': {\n",
    "                'all': {'time': 24781434},\n",
    "                 'large': {'time': 23265773},\n",
    "                 'medium': {'time': 922717},\n",
    "                 'small': {'time': 592944}\n",
    "            },\n",
    "            'two_finger': {\n",
    "                'all': {'time': 24781434},\n",
    "                 'large': {'time': 23265773},\n",
    "                 'medium': {'time': 922717},\n",
    "                 'small': {'time': 592944}\n",
    "            }\n",
    "    }\n",
    "}\n",
    "print(format_fourth_table(d, 'k'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}\n",
      "\\begin{tabular}{l|l|l|l|l|}\n",
      "\\cline{2-5}\n",
      "                       & \\multicolumn{4}{c|}{$\\ell = k$} \\\\ \\hline\n",
      "\\multicolumn{1}{|l|}{Gene graph sets} & Unoptimized (secs) & Two Finger (secs) & Optimized (secs) & Heuristic (secs) \\\\ \\hline\n",
      "\\multicolumn{1}{|l|}{small, 3-15 vertices} & 0.92  & 0.56 & 0.57 & 0.74\\\\ \\hline\n",
      "\\multicolumn{1}{|l|}{medium, 16-50 vertices} & 1.34 & 0.59 & 0.37 & 0.59\\\\ \\hline\n",
      "\\multicolumn{1}{|l|}{large, 51-725 vertices} & 0.04 & 0.03 & 0.02 & 0.02\\\\ \\hline\n",
      "\\multicolumn{1}{|l|}{all, 3-725 vertices}  & 2.31 & 1.18 & 0.97 & 1.34\\\\ \\hline\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\\begin{table}\n",
      "\\begin{tabular}{l|l|l|l|l|}\n",
      "\\cline{2-5}\n",
      "                       & \\multicolumn{4}{c|}{$\\ell = k+1$} \\\\ \\hline\n",
      "\\multicolumn{1}{|l|}{Gene graph sets} & Unoptimized (secs) & Two Finger (secs) & Optimized (secs) & Heuristic (secs) \\\\ \\hline\n",
      "\\multicolumn{1}{|l|}{small, 3-15 vertices} & 0.62  & 0.42 & 0.40 & 0.55\\\\ \\hline\n",
      "\\multicolumn{1}{|l|}{medium, 16-50 vertices} & 0.70 & 0.35 & 0.24 & 0.36\\\\ \\hline\n",
      "\\multicolumn{1}{|l|}{large, 51-725 vertices} & 0.02 & 0.01 & 0.00 & 0.00\\\\ \\hline\n",
      "\\multicolumn{1}{|l|}{all, 3-725 vertices}  & 1.34 & 0.79 & 0.64 & 0.92\\\\ \\hline\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\\begin{table}\n",
      "\\begin{tabular}{l|l|l|l|l|}\n",
      "\\cline{2-5}\n",
      "                       & \\multicolumn{4}{c|}{$\\ell = t$} \\\\ \\hline\n",
      "\\multicolumn{1}{|l|}{Gene graph sets} & Unoptimized (secs) & Two Finger (secs) & Optimized (secs) & Heuristic (secs) \\\\ \\hline\n",
      "\\multicolumn{1}{|l|}{small, 3-15 vertices} & 0.89  & 0.58 & 0.57 & 0.76\\\\ \\hline\n",
      "\\multicolumn{1}{|l|}{medium, 16-50 vertices} & 1.11 & 0.58 & 0.47 & 0.57\\\\ \\hline\n",
      "\\multicolumn{1}{|l|}{large, 51-725 vertices} & 0.04 & 0.02 & 0.01 & 0.01\\\\ \\hline\n",
      "\\multicolumn{1}{|l|}{all, 3-725 vertices}  & 2.05 & 1.19 & 1.06 & 1.35\\\\ \\hline\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\\begin{table}\n",
      "\\begin{tabular}{l|l|l|l|l|}\n",
      "\\cline{2-5}\n",
      "                       & \\multicolumn{4}{c|}{$\\ell = 2k$} \\\\ \\hline\n",
      "\\multicolumn{1}{|l|}{Gene graph sets} & Unoptimized (secs) & Two Finger (secs) & Optimized (secs) & Heuristic (secs) \\\\ \\hline\n",
      "\\multicolumn{1}{|l|}{small, 3-15 vertices} & 0.89  & 0.58 & 0.58 & 0.76\\\\ \\hline\n",
      "\\multicolumn{1}{|l|}{medium, 16-50 vertices} & 1.36 & 0.64 & 0.41 & 0.62\\\\ \\hline\n",
      "\\multicolumn{1}{|l|}{large, 51-725 vertices} & 0.07 & 0.03 & 0.02 & 0.02\\\\ \\hline\n",
      "\\multicolumn{1}{|l|}{all, 3-725 vertices}  & 2.32 & 1.25 & 1.01 & 1.41\\\\ \\hline\n",
      "\\end{tabular}\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "time_dict = dict()\n",
    "time_dict['k'] = dict()\n",
    "time_dict['k+1'] = dict()\n",
    "time_dict['t'] = dict()\n",
    "time_dict['2k'] = dict()\n",
    "\n",
    "time_dict['k']['optimized'] = compute_time_table(0, limit_size_60, limit_size_30, components, vertices_inv)\n",
    "time_dict['k']['two_finger'] = compute_time_table(0, limit_size_60, limit_size_30, components, vertices_inv, 'experiments_two_finger')\n",
    "time_dict['k']['unoptimized'] = compute_time_table(0, limit_size_60, limit_size_30, components, vertices_inv, 'experiments_unoptimized')\n",
    "time_dict['k']['heuristic'] = compute_time_table(0, limit_size_60, limit_size_30, components, vertices_inv, 'experiments_heuristic')\n",
    "\n",
    "\n",
    "time_dict['k+1']['optimized'] = compute_time_table(1, limit_size_60, limit_size_30, components, vertices_inv)\n",
    "time_dict['k+1']['two_finger'] = compute_time_table(1, limit_size_60, limit_size_30, components, vertices_inv, 'experiments_two_finger')\n",
    "time_dict['k+1']['unoptimized'] = compute_time_table(1, limit_size_60, limit_size_30, components, vertices_inv, 'experiments_unoptimized')\n",
    "time_dict['k+1']['heuristic'] = compute_time_table(1, limit_size_60, limit_size_30, components, vertices_inv, 'experiments_heuristic')\n",
    "\n",
    "\n",
    "time_dict['t']['optimized'] = compute_time_table(-1, limit_size_60, limit_size_30, components, vertices_inv)\n",
    "time_dict['t']['two_finger'] = compute_time_table(-1, limit_size_60, limit_size_30, components, vertices_inv, 'experiments_two_finger')\n",
    "time_dict['t']['unoptimized'] = compute_time_table(-1, limit_size_60, limit_size_30, components, vertices_inv, 'experiments_unoptimized')\n",
    "time_dict['t']['heuristic'] = compute_time_table(-1, limit_size_60, limit_size_30, components, vertices_inv, 'experiments_heuristic')\n",
    "\n",
    "\n",
    "time_dict['2k']['optimized'] = compute_time_table(-2, limit_size_60, limit_size_30, components, vertices_inv)\n",
    "time_dict['2k']['two_finger'] = compute_time_table(-2, limit_size_60, limit_size_30, components, vertices_inv, 'experiments_two_finger')\n",
    "time_dict['2k']['unoptimized'] = compute_time_table(-2, limit_size_60, limit_size_30, components, vertices_inv, 'experiments_unoptimized')\n",
    "time_dict['2k']['heuristic'] = compute_time_table(-2, limit_size_60, limit_size_30, components, vertices_inv, 'experiments_heuristic')\n",
    "\n",
    "\n",
    "print(format_fourth_table(time_dict, 'k'))\n",
    "print(format_fourth_table(time_dict, 'k+1'))\n",
    "print(format_fourth_table(time_dict, 't'))\n",
    "print(format_fourth_table(time_dict, '2k'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[t]\n",
      "\\centering\n",
      "\\caption{cdss max relative coverage grouped by cdss size}\n",
      "\\begin{tabular}{|c|c|c|c|}\n",
      "\\hline\n",
      "$\\ell$ & small (1-150 bases)    &  medium (151-500 bases) & large (501-27705 bases)\\\\\\hline\\hline\n",
      "$k$  & \\cell{2}{0.10\\\\0.20} & \\cell{2}{0.10\\\\0.20} & \\cell{2}{0.10\\\\0.20} \\\\\\hline\n",
      "$k+1$  & \\cell{2}{0.10\\\\0.20} & \\cell{2}{0.10\\\\0.20} & \\cell{2}{0.10\\\\0.20} \\\\\\hline\n",
      "$t$  & \\cell{2}{0.10\\\\0.20} & \\cell{2}{0.10\\\\0.20} & \\cell{2}{0.10\\\\0.20} \\\\\\hline\n",
      "$2k$  & \\cell{2}{0.10\\\\0.20} & \\cell{2}{0.10\\\\0.20} & \\cell{2}{0.10\\\\0.20} \\\\\\hline\\hline\n",
      "\\cell{1}{$ST$-\\\\unitigs}\n",
      "   & \\cell{2}{0.10\\\\0.20} & \\cell{2}{0.10\\\\0.20} & \\cell{2}{0.10\\\\0.20} \\\\\\hline\n",
      "\\end{tabular} \n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "def format_number(n) :\n",
    "    if type(n) == int:\n",
    "        return str(n)\n",
    "    return f\"{trunc(n,2):.2f}\"\n",
    "\n",
    "def format_cell(data, key, variant):\n",
    "    \n",
    "    mdata = data[key]\n",
    "    return f\"\"\"\\\\cell{{2}}{{{format_number(mdata['max_cov_rel'+variant]['mean'])}\\\\\\\\{format_number(mdata['max_cov_rel'+variant]['median'])}}}\"\"\"\n",
    "\n",
    "def format_row(data, key, variant):\n",
    "    \n",
    "    mdata = data[key]\n",
    "    return f\"\"\"{format_cell(mdata, 'small', variant)} & {format_cell(mdata, 'medium', variant)} & {format_cell(mdata, 'large', variant)} \\\\\\\\\\\\hline\"\"\"\n",
    "    \n",
    "\n",
    "def format_cdss_paper_table(data, variant=''):\n",
    "    \n",
    "    a = f\"\"\"\\\\begin{{table}}[t]\n",
    "\\centering\n",
    "\\caption{{cdss max relative coverage grouped by cdss size}}\n",
    "\\\\begin{{tabular}}{{|c|c|c|c|}}\n",
    "\\\\hline\n",
    "$\\\\ell$ & small (1-{limit_cdss_60} bases)    &  medium ({limit_cdss_60+1}-{limit_cdss_30} bases) & large ({limit_cdss_30+1}-{limit_cdss_10} bases)\\\\\\\\\\\\hline\\\\hline\n",
    "$k$  & {format_row(data, 'k', variant)}\n",
    "$k+1$  & {format_row(data, 'k+1', variant)}\n",
    "$t$  & {format_row(data, 't', variant)}\n",
    "$2k$  & {format_row(data, '2k', variant)}\\\\hline\n",
    "\\\\cell{{1}}{{$ST$-\\\\\\\\unitigs}}\n",
    "   & {format_row(data, 'unitigs', variant)}\n",
    "\\\\end{{tabular}} \n",
    "\\\\end{{table}}\"\"\"\n",
    "\n",
    "    return a\n",
    "\n",
    "d = {\n",
    "    'k': {'small': {'max_cov_rel': {'mean': 0.1, 'median': 0.2, 'stdev': 0.1}},'medium': {'max_cov_rel': {'mean': 0.1, 'median': 0.2, 'stdev': 0.1}},'large': {'max_cov_rel': {'mean': 0.1, 'median': 0.2, 'stdev': 0.1}}},\n",
    "    'k+1': {'small': {'max_cov_rel': {'mean': 0.1, 'median': 0.2, 'stdev': 0.1}},'medium': {'max_cov_rel': {'mean': 0.1, 'median': 0.2, 'stdev': 0.1}},'large': {'max_cov_rel': {'mean': 0.1, 'median': 0.2, 'stdev': 0.1}}},\n",
    "    't': {'small': {'max_cov_rel': {'mean': 0.1, 'median': 0.2, 'stdev': 0.1}},'medium': {'max_cov_rel': {'mean': 0.1, 'median': 0.2, 'stdev': 0.1}},'large': {'max_cov_rel': {'mean': 0.1, 'median': 0.2, 'stdev': 0.1}}},\n",
    "    '2k': {'small': {'max_cov_rel': {'mean': 0.1, 'median': 0.2, 'stdev': 0.1}},'medium': {'max_cov_rel': {'mean': 0.1, 'median': 0.2, 'stdev': 0.1}},'large': {'max_cov_rel': {'mean': 0.1, 'median': 0.2, 'stdev': 0.1}}},\n",
    "    'unitigs': {'small': {'max_cov_rel': {'mean': 0.1, 'median': 0.2, 'stdev': 0.1}},'medium': {'max_cov_rel': {'mean': 0.1, 'median': 0.2, 'stdev': 0.1}},'large': {'max_cov_rel': {'mean': 0.1, 'median': 0.2, 'stdev': 0.1}}},\n",
    "}\n",
    "\n",
    "print(format_cdss_paper_table(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdss_dict = dict()\n",
    "cdss_dict['unitigs'] = compute_cdss_coverage_table_unitigs(limit_cdss_60, limit_cdss_30, components, vertices_inv)\n",
    "cdss_dict['k']  = compute_cdss_coverage_table(0, limit_cdss_60, limit_cdss_30, components, vertices_inv)\n",
    "cdss_dict['k+1']  = compute_cdss_coverage_table(1, limit_cdss_60, limit_cdss_30, components, vertices_inv)\n",
    "cdss_dict['t']  = compute_cdss_coverage_table(-1, limit_cdss_60, limit_cdss_30, components, vertices_inv)\n",
    "cdss_dict['2k']  = compute_cdss_coverage_table(-2, limit_cdss_60, limit_cdss_30, components, vertices_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[t]\n",
      "\\centering\n",
      "\\caption{cdss max relative coverage grouped by cdss size}\n",
      "\\begin{tabular}{|c|c|c|c|}\n",
      "\\hline\n",
      "$\\ell$ & small (1-150 bases)    &  medium (151-500 bases) & large (501-27705 bases)\\\\\\hline\\hline\n",
      "$k$  & \\cell{2}{0.99\\\\1.00} & \\cell{2}{0.99\\\\1.00} & \\cell{2}{0.99\\\\1.00} \\\\\\hline\n",
      "$k+1$  & \\cell{2}{0.99\\\\1.00} & \\cell{2}{0.99\\\\1.00} & \\cell{2}{0.99\\\\1.00} \\\\\\hline\n",
      "$t$  & \\cell{2}{0.99\\\\1.00} & \\cell{2}{0.99\\\\1.00} & \\cell{2}{0.99\\\\1.00} \\\\\\hline\n",
      "$2k$  & \\cell{2}{0.99\\\\1.00} & \\cell{2}{0.99\\\\1.00} & \\cell{2}{0.99\\\\1.00} \\\\\\hline\\hline\n",
      "\\cell{1}{$ST$-\\\\unitigs}\n",
      "   & \\cell{2}{0.90\\\\1.00} & \\cell{2}{0.94\\\\1.00} & \\cell{2}{0.90\\\\1.00} \\\\\\hline\n",
      "\\end{tabular} \n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "print(format_cdss_paper_table(cdss_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_dict = {\n",
    "    'impr_dict': impr_dict,\n",
    "    'fixed_l_dict': fixed_l_dict,\n",
    "    'fixed_rd_dict': fixed_rd_dict,\n",
    "    'time_dict': time_dict,\n",
    "    'cdss_dict': cdss_dict\n",
    "}\n",
    "\n",
    "f = open('./summary.json', 'w')\n",
    "dump(summary_dict, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
