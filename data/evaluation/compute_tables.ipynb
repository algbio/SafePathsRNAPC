{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run this notebook you first need to run the notebook `evaluation/compute_metrics.ipynb` or obtain the data generated for such notebook in the corresponding folders\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from json import dump, load\n",
    "from pprint import pprint\n",
    "from statistics import median, mean, stdev\n",
    "import networkx as nx\n",
    "\n",
    "## Load gene graphs\n",
    "\n",
    "f = open(f'../gene_graphs/vertices_inv.json', 'r')\n",
    "vertices_inv = load(f)\n",
    "f.close()\n",
    "vertices_inv = {int(k): tuple(v) for k,v in vertices_inv.items()}\n",
    "\n",
    "components = list()\n",
    "for i in range(27121): ## Number of gene_graphs\n",
    "    components.append(dict())\n",
    "    components[i]['graph'] = nx.read_edgelist(f'../gene_graphs/graphs/component_{i+1}.edgelist', delimiter=':', create_using=nx.DiGraph, nodetype=int)\n",
    "    components[i]['len'] = len(components[i]['graph'])\n",
    "    \n",
    "    f = open(f'../gene_graphs/sources/component_{i+1}.json', 'r')\n",
    "    components[i]['sources'] = set(load(f))\n",
    "    f.close()\n",
    "    \n",
    "    f = open(f'../gene_graphs/targets/component_{i+1}.json', 'r')\n",
    "    components[i]['targets'] = set(load(f))\n",
    "    f.close()\n",
    "    \n",
    "    f = open(f'../gene_graphs/vertex_constrains/component_{i+1}.json', 'r')\n",
    "    components[i]['vertex_constrains'] = set(load(f))\n",
    "    f.close()\n",
    "    \n",
    "    f = open(f'../gene_graphs/transcript_paths/component_{i+1}.json', 'r')\n",
    "    components[i]['transcript_paths'] = load(f)\n",
    "    f.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load experiments from json files\n",
    "for i, component in enumerate(components):\n",
    "    if component['len'] > 2:\n",
    "        file = open(f'../safe_paths_json/component_{i+1}.json', \"r\")\n",
    "        dd = load(file)\n",
    "        component.update(dd)\n",
    "        file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interval_length(interval):\n",
    "    return interval[1]-interval[0]+1\n",
    "\n",
    "## It computes the base length of a transcript\n",
    "def base_length(contig, vertices_inv):\n",
    "    length = 0\n",
    "    for v in contig:\n",
    "        length += interval_length(vertices_inv[v])\n",
    "    return length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1356, 3809, 205012)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def choose_60_30_10_limits(components, vertices_inv):\n",
    "    lengths = list()\n",
    "    for i, component in enumerate(components):\n",
    "        if component['len'] > 2:\n",
    "            for transcript in component['transcript_paths']:\n",
    "                lengths.append(base_length(transcript, vertices_inv))\n",
    "    lengths = sorted(lengths)\n",
    "    return lengths[int(0.6*len(lengths))], lengths[int(0.9*len(lengths))], lengths[-1]\n",
    "\n",
    "limit_60, limit_30, limit_10 = choose_60_30_10_limits(components, vertices_inv)\n",
    "limit_60, limit_30, limit_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21, 52, 725)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def choose_60_30_10_limits_size(components, vertices_inv):\n",
    "    sizes = list()\n",
    "    for i, component in enumerate(components):\n",
    "        if component['len'] > 2:\n",
    "            sizes.append(component['len'])\n",
    "    sizes = sorted(sizes)\n",
    "    return sizes[int(0.6*len(sizes))], sizes[int(0.9*len(sizes))], sizes[-1]\n",
    "\n",
    "limit_size_60, limit_size_30, limit_size_10 = choose_60_30_10_limits_size(components, vertices_inv)\n",
    "limit_size_60, limit_size_30, limit_size_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'large': {'abs_improvements_base': {'mean': 620.3321457014713,\n",
      "                                     'median': 214,\n",
      "                                     'stdev': 1253.043242720963},\n",
      "           'abs_improvements_vertex': {'mean': 5.018401307792262,\n",
      "                                       'median': 3,\n",
      "                                       'stdev': 7.826427851424918},\n",
      "           'number_of_unitigs': 23857},\n",
      " 'medium': {'abs_improvements_base': {'mean': 740.421323575017,\n",
      "                                      'median': 225.0,\n",
      "                                      'stdev': 1438.0371968407255},\n",
      "            'abs_improvements_vertex': {'mean': 4.661694473733176,\n",
      "                                        'median': 2.0,\n",
      "                                        'stdev': 6.536794068539553},\n",
      "            'number_of_unitigs': 32246},\n",
      " 'small': {'abs_improvements_base': {'mean': 640.9470082749841,\n",
      "                                     'median': 101.0,\n",
      "                                     'stdev': 1357.9232596592935},\n",
      "           'abs_improvements_vertex': {'mean': 2.475599405898578,\n",
      "                                       'median': 1.0,\n",
      "                                       'stdev': 3.593959411806342},\n",
      "           'number_of_unitigs': 18852},\n",
      " 'total': {'abs_improvements_base': {'mean': 677.1799479687812,\n",
      "                                     'median': 197,\n",
      "                                     'stdev': 1362.4213988042814},\n",
      "           'abs_improvements_vertex': {'mean': 4.225401907811354,\n",
      "                                       'median': 2,\n",
      "                                       'stdev': 6.49447049884983},\n",
      "           'number_of_unitigs': 74955}}\n"
     ]
    }
   ],
   "source": [
    "def compute_abs_improvement_table(over_width, limit_60, limit_30, components, vertices_inv):\n",
    "    unitigs = list()\n",
    "    for i, component in enumerate(components):\n",
    "        if component['len'] > 2:\n",
    "            width = component['width']\n",
    "            l = str(width+over_width)\n",
    "            if over_width == -1:\n",
    "                l = str(len(component['transcript_paths']))\n",
    "            if over_width == -2:\n",
    "                l = str(2*component['width'])\n",
    "            if component['experiments'].get(l, None) is None:\n",
    "                l = str(2*width)\n",
    "\n",
    "            safe_paths = component['experiments'][str(l)]['safe_paths']\n",
    "            uni = component['unitigs']\n",
    "            \n",
    "            abs_vertex = component['experiments'][str(l)]['impr_vertex']\n",
    "            abs_base = component['experiments'][str(l)]['impr_base']\n",
    "            \n",
    "            abs_vertex = list(map(lambda r:  r[1] - len(uni[r[0]]), enumerate(abs_vertex)))\n",
    "            abs_base = list(map(lambda r:  r[1] - base_length(uni[r[0]], vertices_inv), enumerate(abs_base)))\n",
    "            \n",
    "                \n",
    "            for j in range(len(abs_base)):\n",
    "                d = dict()\n",
    "                d['component'] = i\n",
    "                d['component_length'] = component['len']\n",
    "                d['abs_improvements_base'] = abs_base[j]\n",
    "                d['abs_improvements_vertex'] = abs_vertex[j]\n",
    "                \n",
    "                unitigs.append(d)\n",
    "\n",
    "    small = list(filter(lambda c: c['component_length'] <= limit_60, unitigs))\n",
    "    medium = list(filter(lambda c: c['component_length'] > limit_60 and c['component_length'] <= limit_30 , unitigs))\n",
    "    large = list(filter(lambda c: c['component_length'] > limit_30, unitigs))\n",
    "    \n",
    "    small_abs_improvements_base = list(map(lambda c: c['abs_improvements_base'] , small))\n",
    "    medium_abs_improvements_base = list(map(lambda c: c['abs_improvements_base'] , medium))\n",
    "    large_abs_improvements_base = list(map(lambda c: c['abs_improvements_base'] , large))\n",
    "    total_abs_improvements_base = list(map(lambda c: c['abs_improvements_base'] , unitigs))\n",
    "    \n",
    "    small_abs_improvements_vertex = list(map(lambda c: c['abs_improvements_vertex'] , small))\n",
    "    medium_abs_improvements_vertex = list(map(lambda c: c['abs_improvements_vertex'] , medium))\n",
    "    large_abs_improvements_vertex = list(map(lambda c: c['abs_improvements_vertex'] , large))\n",
    "    total_abs_improvements_vertex = list(map(lambda c: c['abs_improvements_vertex'] , unitigs))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return { \n",
    "        'small':\n",
    "        {\n",
    "            'abs_improvements_vertex': \n",
    "            {\n",
    "                'median': median(small_abs_improvements_vertex),\n",
    "                'mean': mean(small_abs_improvements_vertex),\n",
    "                'stdev': stdev(small_abs_improvements_vertex)\n",
    "            },\n",
    "            'abs_improvements_base':\n",
    "            {\n",
    "                'median': median(small_abs_improvements_base),\n",
    "                'mean': mean(small_abs_improvements_base),\n",
    "                'stdev': stdev(small_abs_improvements_base)\n",
    "            },\n",
    "            'number_of_unitigs': len(small)            \n",
    "        },\n",
    "        'medium':\n",
    "        {\n",
    "            'abs_improvements_vertex': \n",
    "            {\n",
    "                'median': median(medium_abs_improvements_vertex),\n",
    "                'mean': mean(medium_abs_improvements_vertex),\n",
    "                'stdev': stdev(medium_abs_improvements_vertex)\n",
    "            },\n",
    "            'abs_improvements_base':\n",
    "            {\n",
    "                'median': median(medium_abs_improvements_base),\n",
    "                'mean': mean(medium_abs_improvements_base),\n",
    "                'stdev': stdev(medium_abs_improvements_base)\n",
    "            },\n",
    "            'number_of_unitigs': len(medium)\n",
    "            \n",
    "        },\n",
    "        'large':\n",
    "        {\n",
    "            'abs_improvements_vertex': \n",
    "            {\n",
    "                'median': median(large_abs_improvements_vertex),\n",
    "                'mean': mean(large_abs_improvements_vertex),\n",
    "                'stdev': stdev(large_abs_improvements_vertex)\n",
    "            },\n",
    "            'abs_improvements_base':\n",
    "            {\n",
    "                'median': median(large_abs_improvements_base),\n",
    "                'mean': mean(large_abs_improvements_base),\n",
    "                'stdev': stdev(large_abs_improvements_base)\n",
    "            },\n",
    "            'number_of_unitigs': len(large)\n",
    "            \n",
    "        },\n",
    "        'total':\n",
    "        {\n",
    "            'abs_improvements_vertex': \n",
    "            {\n",
    "                'median': median(total_abs_improvements_vertex),\n",
    "                'mean': mean(total_abs_improvements_vertex),\n",
    "                'stdev': stdev(total_abs_improvements_vertex)\n",
    "            },\n",
    "            'abs_improvements_base':\n",
    "            {\n",
    "                'median': median(total_abs_improvements_base),\n",
    "                'mean': mean(total_abs_improvements_base),\n",
    "                'stdev': stdev(total_abs_improvements_base)\n",
    "            },\n",
    "            'number_of_unitigs': len(unitigs)\n",
    "            \n",
    "        }\n",
    "    }\n",
    "    \n",
    "pprint(compute_abs_improvement_table(0, limit_size_60, limit_size_30, components, vertices_inv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'large': {'number_of_unitigs': 23857,\n",
      "           'rel_improvements_base': {'mean': 1.9364123011041254,\n",
      "                                     'median': 1.1093117408906883,\n",
      "                                     'stdev': 3.796463199470008},\n",
      "           'rel_improvements_vertex': {'mean': 1.523322717646293,\n",
      "                                       'median': 1.2857142857142858,\n",
      "                                       'stdev': 0.9170090619844139}},\n",
      " 'medium': {'number_of_unitigs': 32246,\n",
      "            'rel_improvements_base': {'mean': 1.817037117189901,\n",
      "                                      'median': 1.056030188605891,\n",
      "                                      'stdev': 4.5078974380953705},\n",
      "            'rel_improvements_vertex': {'mean': 1.4544017553372026,\n",
      "                                        'median': 1.2,\n",
      "                                        'stdev': 0.7585772731196603}},\n",
      " 'small': {'number_of_unitigs': 18852,\n",
      "           'rel_improvements_base': {'mean': 1.4235048754418045,\n",
      "                                     'median': 1.0,\n",
      "                                     'stdev': 1.8468077263401443},\n",
      "           'rel_improvements_vertex': {'mean': 1.208644856657199,\n",
      "                                       'median': 1.0,\n",
      "                                       'stdev': 0.45171054024832014}},\n",
      " 'total': {'number_of_unitigs': 74955,\n",
      "           'rel_improvements_base': {'mean': 1.7560547136305191,\n",
      "                                     'median': 1.0,\n",
      "                                     'stdev': 3.771869826275528},\n",
      "           'rel_improvements_vertex': {'mean': 1.4145276754745189,\n",
      "                                       'median': 1.0,\n",
      "                                       'stdev': 0.7626409508318245}}}\n"
     ]
    }
   ],
   "source": [
    "def compute_rel_improvement_table(over_width, limit_60, limit_30, components, vertices_inv):\n",
    "    unitigs = list()\n",
    "    for i, component in enumerate(components):\n",
    "        if component['len'] > 2:\n",
    "            width = component['width']\n",
    "            l = str(width+over_width)\n",
    "            if over_width == -1:\n",
    "                l = str(len(component['transcript_paths']))\n",
    "            if over_width == -2:\n",
    "                l = str(2*component['width'])\n",
    "            if component['experiments'].get(l, None) is None:\n",
    "                l = str(2*width)\n",
    "\n",
    "            uni = component['unitigs']\n",
    "            safe_paths = component['experiments'][str(l)]['safe_paths']\n",
    "            \n",
    "            rel_vertex = component['experiments'][str(l)]['impr_vertex']\n",
    "            rel_base = component['experiments'][str(l)]['impr_base']\n",
    "            \n",
    "            rel_vertex = list(map(lambda r:  r[1]/len(uni[r[0]]), enumerate(rel_vertex)))\n",
    "            rel_base = list(map(lambda r:  r[1]/base_length(uni[r[0]], vertices_inv), enumerate(rel_base)))\n",
    "            \n",
    "            \n",
    "                \n",
    "            for j in range(len(rel_base)):\n",
    "                d = dict()\n",
    "                d['component'] = i\n",
    "                d['component_length'] = component['len']\n",
    "                d['rel_improvements_base'] = rel_base[j]\n",
    "                d['rel_improvements_vertex'] = rel_vertex[j]\n",
    "                \n",
    "                unitigs.append(d)\n",
    "\n",
    "    small = list(filter(lambda c: c['component_length'] <= limit_60, unitigs))\n",
    "    medium = list(filter(lambda c: c['component_length'] > limit_60 and c['component_length'] <= limit_30 , unitigs))\n",
    "    large = list(filter(lambda c: c['component_length'] > limit_30, unitigs))\n",
    "    \n",
    "    small_rel_improvements_base = list(map(lambda c: c['rel_improvements_base'] , small))\n",
    "    medium_rel_improvements_base = list(map(lambda c: c['rel_improvements_base'] , medium))\n",
    "    large_rel_improvements_base = list(map(lambda c: c['rel_improvements_base'] , large))\n",
    "    total_rel_improvements_base = list(map(lambda c: c['rel_improvements_base'] , unitigs))\n",
    "    \n",
    "    small_rel_improvements_vertex = list(map(lambda c: c['rel_improvements_vertex'] , small))\n",
    "    medium_rel_improvements_vertex = list(map(lambda c: c['rel_improvements_vertex'] , medium))\n",
    "    large_rel_improvements_vertex = list(map(lambda c: c['rel_improvements_vertex'] , large))\n",
    "    total_rel_improvements_vertex = list(map(lambda c: c['rel_improvements_vertex'] , unitigs))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return { \n",
    "        'small':\n",
    "        {\n",
    "            'rel_improvements_vertex': \n",
    "            {\n",
    "                'median': median(small_rel_improvements_vertex),\n",
    "                'mean': mean(small_rel_improvements_vertex),\n",
    "                'stdev': stdev(small_rel_improvements_vertex)\n",
    "            },\n",
    "            'rel_improvements_base':\n",
    "            {\n",
    "                'median': median(small_rel_improvements_base),\n",
    "                'mean': mean(small_rel_improvements_base),\n",
    "                'stdev': stdev(small_rel_improvements_base)\n",
    "            },\n",
    "            'number_of_unitigs': len(small)            \n",
    "        },\n",
    "        'medium':\n",
    "        {\n",
    "            'rel_improvements_vertex': \n",
    "            {\n",
    "                'median': median(medium_rel_improvements_vertex),\n",
    "                'mean': mean(medium_rel_improvements_vertex),\n",
    "                'stdev': stdev(medium_rel_improvements_vertex)\n",
    "            },\n",
    "            'rel_improvements_base':\n",
    "            {\n",
    "                'median': median(medium_rel_improvements_base),\n",
    "                'mean': mean(medium_rel_improvements_base),\n",
    "                'stdev': stdev(medium_rel_improvements_base)\n",
    "            },\n",
    "            'number_of_unitigs': len(medium)\n",
    "            \n",
    "        },\n",
    "        'large':\n",
    "        {\n",
    "            'rel_improvements_vertex': \n",
    "            {\n",
    "                'median': median(large_rel_improvements_vertex),\n",
    "                'mean': mean(large_rel_improvements_vertex),\n",
    "                'stdev': stdev(large_rel_improvements_vertex)\n",
    "            },\n",
    "            'rel_improvements_base':\n",
    "            {\n",
    "                'median': median(large_rel_improvements_base),\n",
    "                'mean': mean(large_rel_improvements_base),\n",
    "                'stdev': stdev(large_rel_improvements_base)\n",
    "            },\n",
    "            'number_of_unitigs': len(large)\n",
    "            \n",
    "        },\n",
    "        'total':\n",
    "        {\n",
    "            'rel_improvements_vertex': \n",
    "            {\n",
    "                'median': median(total_rel_improvements_vertex),\n",
    "                'mean': mean(total_rel_improvements_vertex),\n",
    "                'stdev': stdev(total_rel_improvements_vertex)\n",
    "            },\n",
    "            'rel_improvements_base':\n",
    "            {\n",
    "                'median': median(total_rel_improvements_base),\n",
    "                'mean': mean(total_rel_improvements_base),\n",
    "                'stdev': stdev(total_rel_improvements_base)\n",
    "            },\n",
    "            'number_of_unitigs': len(unitigs)\n",
    "            \n",
    "        }\n",
    "    }\n",
    "    \n",
    "pprint(compute_rel_improvement_table(-1, limit_size_60, limit_size_30, components, vertices_inv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'large': {'base_lengths': {'mean': 671.8732810397453,\n",
      "                            'median': 402,\n",
      "                            'stdev': 938.2866812845797},\n",
      "           'number_of_contigs': 30469,\n",
      "           'vertex_lengths': {'mean': 4.696248646164954,\n",
      "                              'median': 4,\n",
      "                              'stdev': 3.5750445206749824}},\n",
      " 'medium': {'base_lengths': {'mean': 767.3544157800584,\n",
      "                             'median': 449.0,\n",
      "                             'stdev': 1057.421043861511},\n",
      "            'number_of_contigs': 42484,\n",
      "            'vertex_lengths': {'mean': 4.45304114490161,\n",
      "                               'median': 4.0,\n",
      "                               'stdev': 2.7708390549912156}},\n",
      " 'small': {'base_lengths': {'mean': 1018.3653104925054,\n",
      "                            'median': 583.0,\n",
      "                            'stdev': 1484.0827219399116},\n",
      "           'number_of_contigs': 28020,\n",
      "           'vertex_lengths': {'mean': 3.69768022840828,\n",
      "                              'median': 3.0,\n",
      "                              'stdev': 1.8914853629787287}},\n",
      " 'total': {'base_lengths': {'mean': 808.1981123666723,\n",
      "                            'median': 468,\n",
      "                            'stdev': 1168.693492100811},\n",
      "           'number_of_contigs': 100973,\n",
      "           'vertex_lengths': {'mean': 4.316817367018906,\n",
      "                              'median': 4,\n",
      "                              'stdev': 2.8700668505227136}}}\n"
     ]
    }
   ],
   "source": [
    "def compute_contigs_table(over_width, limit_60, limit_30, components, vertices_inv):\n",
    "    contigs = list()\n",
    "    for i, component in enumerate(components):\n",
    "        if component['len'] > 2:\n",
    "            width = component['width']\n",
    "            l = str(width+over_width)\n",
    "            if over_width == -1:\n",
    "                l = str(len(component['transcript_paths']))\n",
    "            if over_width == -2:\n",
    "                l = str(2*component['width'])\n",
    "            if component['experiments'].get(l, None) is None:\n",
    "                l = str(2*width)\n",
    "                \n",
    "            if component['experiments'].get(l, None) is not None:\n",
    "                safe_paths_info = component['experiments'][l]\n",
    "                \n",
    "                for safe_path in safe_paths_info['safe_paths']:\n",
    "                    d = dict()\n",
    "                    d['component'] = i\n",
    "                    d['component_length'] = component['len']\n",
    "                    d['vertices'] = len(safe_path)\n",
    "                    d['length'] = base_length(safe_path, vertices_inv)\n",
    "                    \n",
    "                    contigs.append(d)\n",
    "\n",
    "                \n",
    "                    \n",
    "    \n",
    "    \n",
    "   \n",
    "    small = list(filter(lambda c: c['component_length'] <= limit_60, contigs))\n",
    "    medium = list(filter(lambda c: c['component_length'] > limit_60 and c['component_length'] <= limit_30 , contigs))\n",
    "    large = list(filter(lambda c: c['component_length'] > limit_30, contigs))\n",
    "    \n",
    "    small_base_lengths = list(map(lambda c: c['length'] , small))\n",
    "    medium_base_lengths = list(map(lambda c: c['length'] , medium))\n",
    "    large_base_lengths = list(map(lambda c: c['length'] , large))\n",
    "    total_base_lengths = list(map(lambda c: c['length'] , contigs))\n",
    "    \n",
    "    small_vertex_lengths = list(map(lambda c: c['vertices'] , small))\n",
    "    medium_vertex_lengths = list(map(lambda c: c['vertices'] , medium))\n",
    "    large_vertex_lengths = list(map(lambda c: c['vertices'] , large))\n",
    "    total_vertex_lengths = list(map(lambda c: c['vertices'] , contigs))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return { \n",
    "        'small':\n",
    "        {\n",
    "            'vertex_lengths': \n",
    "            {\n",
    "                'median': median(small_vertex_lengths),\n",
    "                'mean': mean(small_vertex_lengths),\n",
    "                'stdev': stdev(small_vertex_lengths)\n",
    "            },\n",
    "            'base_lengths':\n",
    "            {\n",
    "                'median': median(small_base_lengths),\n",
    "                'mean': mean(small_base_lengths),\n",
    "                'stdev': stdev(small_base_lengths)\n",
    "            },\n",
    "            'number_of_contigs': len(small)            \n",
    "        },\n",
    "        'medium':\n",
    "        {\n",
    "            'vertex_lengths': \n",
    "            {\n",
    "                'median': median(medium_vertex_lengths),\n",
    "                'mean': mean(medium_vertex_lengths),\n",
    "                'stdev': stdev(medium_vertex_lengths)\n",
    "            },\n",
    "            'base_lengths':\n",
    "            {\n",
    "                'median': median(medium_base_lengths),\n",
    "                'mean': mean(medium_base_lengths),\n",
    "                'stdev': stdev(medium_base_lengths)\n",
    "            },\n",
    "            'number_of_contigs': len(medium)\n",
    "            \n",
    "        },\n",
    "        'large':\n",
    "        {\n",
    "            'vertex_lengths': \n",
    "            {\n",
    "                'median': median(large_vertex_lengths),\n",
    "                'mean': mean(large_vertex_lengths),\n",
    "                'stdev': stdev(large_vertex_lengths)\n",
    "            },\n",
    "            'base_lengths':\n",
    "            {\n",
    "                'median': median(large_base_lengths),\n",
    "                'mean': mean(large_base_lengths),\n",
    "                'stdev': stdev(large_base_lengths)\n",
    "            },\n",
    "            'number_of_contigs': len(large)\n",
    "            \n",
    "        },\n",
    "        'total':\n",
    "        {\n",
    "            'vertex_lengths': \n",
    "            {\n",
    "                'median': median(total_vertex_lengths),\n",
    "                'mean': mean(total_vertex_lengths),\n",
    "                'stdev': stdev(total_vertex_lengths)\n",
    "            },\n",
    "            'base_lengths':\n",
    "            {\n",
    "                'median': median(total_base_lengths),\n",
    "                'mean': mean(total_base_lengths),\n",
    "                'stdev': stdev(total_base_lengths)\n",
    "            },\n",
    "            'number_of_contigs': len(contigs)\n",
    "            \n",
    "        }\n",
    "    }\n",
    "    \n",
    "pprint(compute_contigs_table(-1, limit_size_60, limit_size_30, components, vertices_inv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'large': {'base_lengths': {'mean': 578.9776585488536,\n",
      "                            'median': 318,\n",
      "                            'stdev': 927.4126735518306},\n",
      "           'number_of_contigs': 23857,\n",
      "           'vertex_lengths': {'mean': 4.342415224043258,\n",
      "                              'median': 3,\n",
      "                              'stdev': 3.1077091058801223}},\n",
      " 'medium': {'base_lengths': {'mean': 696.6927370836693,\n",
      "                             'median': 363.0,\n",
      "                             'stdev': 1068.2320941184112},\n",
      "            'number_of_contigs': 32246,\n",
      "            'vertex_lengths': {'mean': 4.148297463251256,\n",
      "                               'median': 3.0,\n",
      "                               'stdev': 2.2844871929068025}},\n",
      " 'small': {'base_lengths': {'mean': 1004.8013473371526,\n",
      "                            'median': 549.5,\n",
      "                            'stdev': 1317.6242438288753},\n",
      "           'number_of_contigs': 18852,\n",
      "           'vertex_lengths': {'mean': 3.752227880330999,\n",
      "                              'median': 3.0,\n",
      "                              'stdev': 1.6151314960596064}},\n",
      " 'total': {'base_lengths': {'mean': 736.7185511306784,\n",
      "                            'median': 384,\n",
      "                            'stdev': 1108.1413674431353},\n",
      "           'number_of_contigs': 74955,\n",
      "           'vertex_lengths': {'mean': 4.110466279767861,\n",
      "                              'median': 3,\n",
      "                              'stdev': 2.454607894823446}}}\n"
     ]
    }
   ],
   "source": [
    "def compute_contigs_table_unitigs(limit_60, limit_30, components, vertices_inv):\n",
    "    contigs = list()\n",
    "    for i, component in enumerate(components):\n",
    "        if component['len'] > 2:\n",
    "            unitigs = component['unitigs']\n",
    "\n",
    "            for unitig in unitigs:\n",
    "                d = dict()\n",
    "                d['component'] = i\n",
    "                d['component_length'] = component['len']\n",
    "                d['vertices'] = len(unitig)\n",
    "                d['length'] = base_length(unitig, vertices_inv)\n",
    "\n",
    "                contigs.append(d)\n",
    "                \n",
    "    \n",
    "    \n",
    "    small = list(filter(lambda c: c['component_length'] <= limit_60, contigs))\n",
    "    medium = list(filter(lambda c: c['component_length'] > limit_60 and c['component_length'] <= limit_30 , contigs))\n",
    "    large = list(filter(lambda c: c['component_length'] > limit_30, contigs))\n",
    "    \n",
    "    small_base_lengths = list(map(lambda c: c['length'] , small))\n",
    "    medium_base_lengths = list(map(lambda c: c['length'] , medium))\n",
    "    large_base_lengths = list(map(lambda c: c['length'] , large))\n",
    "    total_base_lengths = list(map(lambda c: c['length'] , contigs))\n",
    "    \n",
    "    small_vertex_lengths = list(map(lambda c: c['vertices'] , small))\n",
    "    medium_vertex_lengths = list(map(lambda c: c['vertices'] , medium))\n",
    "    large_vertex_lengths = list(map(lambda c: c['vertices'] , large))\n",
    "    total_vertex_lengths = list(map(lambda c: c['vertices'] , contigs))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return { \n",
    "        'small':\n",
    "        {\n",
    "            'vertex_lengths': \n",
    "            {\n",
    "                'median': median(small_vertex_lengths),\n",
    "                'mean': mean(small_vertex_lengths),\n",
    "                'stdev': stdev(small_vertex_lengths)\n",
    "            },\n",
    "            'base_lengths':\n",
    "            {\n",
    "                'median': median(small_base_lengths),\n",
    "                'mean': mean(small_base_lengths),\n",
    "                'stdev': stdev(small_base_lengths)\n",
    "            },\n",
    "            'number_of_contigs': len(small)            \n",
    "        },\n",
    "        'medium':\n",
    "        {\n",
    "            'vertex_lengths': \n",
    "            {\n",
    "                'median': median(medium_vertex_lengths),\n",
    "                'mean': mean(medium_vertex_lengths),\n",
    "                'stdev': stdev(medium_vertex_lengths)\n",
    "            },\n",
    "            'base_lengths':\n",
    "            {\n",
    "                'median': median(medium_base_lengths),\n",
    "                'mean': mean(medium_base_lengths),\n",
    "                'stdev': stdev(medium_base_lengths)\n",
    "            },\n",
    "            'number_of_contigs': len(medium)\n",
    "            \n",
    "        },\n",
    "        'large':\n",
    "        {\n",
    "            'vertex_lengths': \n",
    "            {\n",
    "                'median': median(large_vertex_lengths),\n",
    "                'mean': mean(large_vertex_lengths),\n",
    "                'stdev': stdev(large_vertex_lengths)\n",
    "            },\n",
    "            'base_lengths':\n",
    "            {\n",
    "                'median': median(large_base_lengths),\n",
    "                'mean': mean(large_base_lengths),\n",
    "                'stdev': stdev(large_base_lengths)\n",
    "            },\n",
    "            'number_of_contigs': len(large)\n",
    "            \n",
    "        },\n",
    "        'total':\n",
    "        {\n",
    "            'vertex_lengths': \n",
    "            {\n",
    "                'median': median(total_vertex_lengths),\n",
    "                'mean': mean(total_vertex_lengths),\n",
    "                'stdev': stdev(total_vertex_lengths)\n",
    "            },\n",
    "            'base_lengths':\n",
    "            {\n",
    "                'median': median(total_base_lengths),\n",
    "                'mean': mean(total_base_lengths),\n",
    "                'stdev': stdev(total_base_lengths)\n",
    "            },\n",
    "            'number_of_contigs': len(contigs)\n",
    "            \n",
    "        }\n",
    "    }\n",
    "\n",
    "pprint(compute_contigs_table_unitigs(limit_size_60, limit_size_30, components, vertices_inv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'large': {'e_size_density_bases': {'mean': 0.48843401085056903,\n",
      "                                    'median': 0.4490438294731364,\n",
      "                                    'stdev': 0.2540928807513626},\n",
      "           'e_size_density_vertex': {'mean': 0.3498919297198766,\n",
      "                                     'median': 0.28656462585034015,\n",
      "                                     'stdev': 0.22075548509770684},\n",
      "           'max_prop_cov_bases': {'mean': 0.6253037065305191,\n",
      "                                  'median': 0.618051013734467,\n",
      "                                  'stdev': 0.23441831569455798},\n",
      "           'max_prop_cov_vertex': {'mean': 0.4794598252949863,\n",
      "                                   'median': 0.43333333333333335,\n",
      "                                   'stdev': 0.22080904137393437}},\n",
      " 'medium': {'e_size_density_bases': {'mean': 0.47818762396115516,\n",
      "                                     'median': 0.43225340871739565,\n",
      "                                     'stdev': 0.24583830816911673},\n",
      "            'e_size_density_vertex': {'mean': 0.3937952627060286,\n",
      "                                      'median': 0.3347107438016529,\n",
      "                                      'stdev': 0.2239520496950568},\n",
      "            'max_prop_cov_bases': {'mean': 0.6173044914289967,\n",
      "                                   'median': 0.6033666491320357,\n",
      "                                   'stdev': 0.2301173843154604},\n",
      "            'max_prop_cov_vertex': {'mean': 0.5205082445957195,\n",
      "                                    'median': 0.4827586206896552,\n",
      "                                    'stdev': 0.21740107560558672}},\n",
      " 'small': {'e_size_density_bases': {'mean': 0.551639959534532,\n",
      "                                    'median': 0.5102011705555642,\n",
      "                                    'stdev': 0.23370489660961075},\n",
      "           'e_size_density_vertex': {'mean': 0.5141257058472156,\n",
      "                                     'median': 0.46502057613168735,\n",
      "                                     'stdev': 0.22501923331103335},\n",
      "           'max_prop_cov_bases': {'mean': 0.684628316599058,\n",
      "                                  'median': 0.6711409395973155,\n",
      "                                  'stdev': 0.2222551090037906},\n",
      "           'max_prop_cov_vertex': {'mean': 0.6402946692343462,\n",
      "                                   'median': 0.6,\n",
      "                                   'stdev': 0.21768324165555245}}}\n"
     ]
    }
   ],
   "source": [
    "def compute_fixed_l_table(over_width, limit_60, limit_30, components, vertices_inv):\n",
    "    transcripts = list()\n",
    "    for i, component in enumerate(components):\n",
    "        if component['len'] > 2:\n",
    "            width = component['width']\n",
    "            l = str(width+over_width)\n",
    "            if over_width == -1:\n",
    "                l = str(len(component['transcript_paths']))\n",
    "            if over_width == -2:\n",
    "                l = str(2*component['width'])\n",
    "            if component['experiments'].get(l, None) is None:\n",
    "                l = str(2*width)\n",
    "                \n",
    "            if component['experiments'].get(l, None) is not None:\n",
    "                safe_paths_info = component['experiments'][l]\n",
    "\n",
    "                for j, transcript in enumerate(component['transcript_paths']):\n",
    "                    d = dict()\n",
    "                    d['component'] = i\n",
    "                    d['length'] = base_length(transcript, vertices_inv)\n",
    "                    d['transcript'] = transcript\n",
    "                    \n",
    "                    d['e_size_density_vertex'] = safe_paths_info['e_sizes_vertex'][j]/len(transcript)\n",
    "                    d['e_size_density_bases'] = safe_paths_info['e_size_bases'][j]/d['length']\n",
    "                    d['max_prop_cov_bases'] = safe_paths_info['max_cov_bases'][j]/d['length']\n",
    "                    d['max_prop_cov_vertex'] = safe_paths_info['max_cov_vertex'][j]/len(transcript)\n",
    "                    \n",
    "                    transcripts.append(d)\n",
    "    \n",
    "    \n",
    "    \n",
    "    small = list(filter(lambda t: t['length'] <= limit_60, transcripts))\n",
    "    medium = list(filter(lambda t: t['length'] > limit_60 and t['length'] <= limit_30 , transcripts))\n",
    "    large = list(filter(lambda t: t['length'] > limit_30, transcripts))\n",
    "    \n",
    "    \n",
    "    small_e_size_densities_vertex = list(map(lambda t: t['e_size_density_vertex'] , small))\n",
    "    medium_e_size_densities_vertex = list(map(lambda t: t['e_size_density_vertex'] , medium))\n",
    "    large_e_size_densities_vertex = list(map(lambda t: t['e_size_density_vertex'] , large))\n",
    "    \n",
    "    small_e_size_densities_bases = list(map(lambda t: t['e_size_density_bases'] , small))\n",
    "    medium_e_size_densities_bases = list(map(lambda t: t['e_size_density_bases'] , medium))\n",
    "    large_e_size_densities_bases = list(map(lambda t: t['e_size_density_bases'] , large))\n",
    "    \n",
    "    \n",
    "    small_max_prop_cov_vertex = list(map(lambda t: t['max_prop_cov_vertex'] , small))\n",
    "    medium_max_prop_cov_vertex = list(map(lambda t: t['max_prop_cov_vertex'] , medium))\n",
    "    large_max_prop_cov_vertex = list(map(lambda t: t['max_prop_cov_vertex'] , large))\n",
    "    \n",
    "    small_max_prop_cov_bases = list(map(lambda t: t['max_prop_cov_bases'] , small))\n",
    "    medium_max_prop_cov_bases = list(map(lambda t: t['max_prop_cov_bases'] , medium))\n",
    "    large_max_prop_cov_bases = list(map(lambda t: t['max_prop_cov_bases'] , large))\n",
    "    \n",
    "    \n",
    "    \n",
    "    return { \n",
    "        'small':\n",
    "        {\n",
    "            'e_size_density_vertex': \n",
    "            {\n",
    "                'median': median(small_e_size_densities_vertex),\n",
    "                'mean': mean(small_e_size_densities_vertex),\n",
    "                'stdev': stdev(small_e_size_densities_vertex)\n",
    "            },\n",
    "            'e_size_density_bases': \n",
    "            {\n",
    "                'median': median(small_e_size_densities_bases),\n",
    "                'mean': mean(small_e_size_densities_bases),\n",
    "                'stdev': stdev(small_e_size_densities_bases)\n",
    "            },\n",
    "            'max_prop_cov_vertex':\n",
    "            {\n",
    "                'median': median(small_max_prop_cov_vertex),\n",
    "                'mean': mean(small_max_prop_cov_vertex),\n",
    "                'stdev': stdev(small_max_prop_cov_vertex)\n",
    "            },\n",
    "            'max_prop_cov_bases':\n",
    "            {\n",
    "                'median': median(small_max_prop_cov_bases),\n",
    "                'mean': mean(small_max_prop_cov_bases),\n",
    "                'stdev': stdev(small_max_prop_cov_bases)\n",
    "            }\n",
    "            \n",
    "        }\n",
    "        ,\n",
    "        'medium' :\n",
    "        {\n",
    "            'e_size_density_vertex': \n",
    "            {\n",
    "                'median': median(medium_e_size_densities_vertex),\n",
    "                'mean': mean(medium_e_size_densities_vertex),\n",
    "                'stdev': stdev(medium_e_size_densities_vertex)\n",
    "            },\n",
    "            'e_size_density_bases': \n",
    "            {\n",
    "                'median': median(medium_e_size_densities_bases),\n",
    "                'mean': mean(medium_e_size_densities_bases),\n",
    "                'stdev': stdev(medium_e_size_densities_bases)\n",
    "            },\n",
    "            'max_prop_cov_vertex':\n",
    "            {\n",
    "                'median': median(medium_max_prop_cov_vertex),\n",
    "                'mean': mean(medium_max_prop_cov_vertex),\n",
    "                'stdev': stdev(medium_max_prop_cov_vertex)\n",
    "            },\n",
    "            'max_prop_cov_bases':\n",
    "            {\n",
    "                'median': median(medium_max_prop_cov_bases),\n",
    "                'mean': mean(medium_max_prop_cov_bases),\n",
    "                'stdev': stdev(medium_max_prop_cov_bases)\n",
    "            }\n",
    "        },\n",
    "        'large':\n",
    "        {\n",
    "            'e_size_density_vertex': \n",
    "            {\n",
    "                'median': median(large_e_size_densities_vertex),\n",
    "                'mean': mean(large_e_size_densities_vertex),\n",
    "                'stdev': stdev(large_e_size_densities_vertex)\n",
    "            },\n",
    "            'e_size_density_bases': \n",
    "            {\n",
    "                'median': median(large_e_size_densities_bases),\n",
    "                'mean': mean(large_e_size_densities_bases),\n",
    "                'stdev': stdev(large_e_size_densities_bases)\n",
    "            },\n",
    "            'max_prop_cov_vertex':\n",
    "            {\n",
    "                'median': median(large_max_prop_cov_vertex),\n",
    "                'mean': mean(large_max_prop_cov_vertex),\n",
    "                'stdev': stdev(large_max_prop_cov_vertex)\n",
    "            },\n",
    "            'max_prop_cov_bases':\n",
    "            {\n",
    "                'median': median(large_max_prop_cov_bases),\n",
    "                'mean': mean(large_max_prop_cov_bases),\n",
    "                'stdev': stdev(large_max_prop_cov_bases)\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "pprint(compute_fixed_l_table(0, limit_60, limit_30, components, vertices_inv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'large': {'e_size_density_bases': {'mean': 0.3806891567877237,\n",
      "                                    'median': 0.3207514617051683,\n",
      "                                    'stdev': 0.2530305596698371},\n",
      "           'e_size_density_vertex': {'mean': 0.24943402182486896,\n",
      "                                     'median': 0.19576333089846604,\n",
      "                                     'stdev': 0.18057871669076303},\n",
      "           'max_prop_cov_bases': {'mean': 0.5254454879086077,\n",
      "                                  'median': 0.5024841915085817,\n",
      "                                  'stdev': 0.24772857607787951},\n",
      "           'max_prop_cov_vertex': {'mean': 0.36799846511734646,\n",
      "                                   'median': 0.32,\n",
      "                                   'stdev': 0.19494554032134626}},\n",
      " 'medium': {'e_size_density_bases': {'mean': 0.3490242925939059,\n",
      "                                     'median': 0.2864200598143168,\n",
      "                                     'stdev': 0.24326912322761918},\n",
      "            'e_size_density_vertex': {'mean': 0.2851013768616557,\n",
      "                                      'median': 0.23456790123456792,\n",
      "                                      'stdev': 0.1898042739745112},\n",
      "            'max_prop_cov_bases': {'mean': 0.4937733383766842,\n",
      "                                   'median': 0.45852402745995424,\n",
      "                                   'stdev': 0.24198983457499917},\n",
      "            'max_prop_cov_vertex': {'mean': 0.4116911037613131,\n",
      "                                    'median': 0.37209302325581395,\n",
      "                                    'stdev': 0.20005929811730774}},\n",
      " 'small': {'e_size_density_bases': {'mean': 0.36414108501025677,\n",
      "                                    'median': 0.3149403969313568,\n",
      "                                    'stdev': 0.24352570805800156},\n",
      "           'e_size_density_vertex': {'mean': 0.3586065860868394,\n",
      "                                     'median': 0.3133506944444444,\n",
      "                                     'stdev': 0.2063033950024459},\n",
      "           'max_prop_cov_bases': {'mean': 0.5147723624512895,\n",
      "                                  'median': 0.4871205139682456,\n",
      "                                  'stdev': 0.23441924088347868},\n",
      "           'max_prop_cov_vertex': {'mean': 0.5068562296006605,\n",
      "                                   'median': 0.5,\n",
      "                                   'stdev': 0.20690211123084093}}}\n"
     ]
    }
   ],
   "source": [
    "def compute_fixed_l_table_unitigs(limit_60, limit_30, components, vertices_inv):\n",
    "    transcripts = list()\n",
    "    for i, component in enumerate(components):\n",
    "        if component['len'] > 2:\n",
    "            unitigs = component['unitigs']\n",
    "\n",
    "            for j, transcript in enumerate(component['transcript_paths']):\n",
    "                d = dict()\n",
    "                d['component'] = i\n",
    "                d['length'] = base_length(transcript, vertices_inv)\n",
    "                d['transcript'] = transcript\n",
    "                \n",
    "                \n",
    "                d['e_size_density_vertex'] =  component['e_sizes_vertex'][j]/len(transcript)\n",
    "                d['e_size_density_bases'] =  component['e_size_bases'][j]/d['length']\n",
    "                d['max_prop_cov_bases'] =  component['max_cov_bases'][j]/d['length']\n",
    "                d['max_prop_cov_vertex'] =  component['max_cov_vertex'][j]/len(transcript)\n",
    "\n",
    "                transcripts.append(d)\n",
    "\n",
    "    \n",
    "    \n",
    "    small = list(filter(lambda t: t['length'] <= limit_60, transcripts))\n",
    "    medium = list(filter(lambda t: t['length'] > limit_60 and t['length'] <= limit_30 , transcripts))\n",
    "    large = list(filter(lambda t: t['length'] > limit_30, transcripts))\n",
    "    \n",
    "    \n",
    "    small_e_size_densities_vertex = list(map(lambda t: t['e_size_density_vertex'] , small))\n",
    "    medium_e_size_densities_vertex = list(map(lambda t: t['e_size_density_vertex'] , medium))\n",
    "    large_e_size_densities_vertex = list(map(lambda t: t['e_size_density_vertex'] , large))\n",
    "    \n",
    "    small_e_size_densities_bases = list(map(lambda t: t['e_size_density_bases'] , small))\n",
    "    medium_e_size_densities_bases = list(map(lambda t: t['e_size_density_bases'] , medium))\n",
    "    large_e_size_densities_bases = list(map(lambda t: t['e_size_density_bases'] , large))\n",
    "    \n",
    "    \n",
    "    small_max_prop_cov_vertex = list(map(lambda t: t['max_prop_cov_vertex'] , small))\n",
    "    medium_max_prop_cov_vertex = list(map(lambda t: t['max_prop_cov_vertex'] , medium))\n",
    "    large_max_prop_cov_vertex = list(map(lambda t: t['max_prop_cov_vertex'] , large))\n",
    "    \n",
    "    small_max_prop_cov_bases = list(map(lambda t: t['max_prop_cov_bases'] , small))\n",
    "    medium_max_prop_cov_bases = list(map(lambda t: t['max_prop_cov_bases'] , medium))\n",
    "    large_max_prop_cov_bases = list(map(lambda t: t['max_prop_cov_bases'] , large))\n",
    "\n",
    "    \n",
    "    \n",
    "    return { \n",
    "        'small':\n",
    "        {\n",
    "            'e_size_density_vertex': \n",
    "            {\n",
    "                'median': median(small_e_size_densities_vertex),\n",
    "                'mean': mean(small_e_size_densities_vertex),\n",
    "                'stdev': stdev(small_e_size_densities_vertex)\n",
    "            },\n",
    "            'e_size_density_bases': \n",
    "            {\n",
    "                'median': median(small_e_size_densities_bases),\n",
    "                'mean': mean(small_e_size_densities_bases),\n",
    "                'stdev': stdev(small_e_size_densities_bases)\n",
    "            },\n",
    "            'max_prop_cov_vertex':\n",
    "            {\n",
    "                'median': median(small_max_prop_cov_vertex),\n",
    "                'mean': mean(small_max_prop_cov_vertex),\n",
    "                'stdev': stdev(small_max_prop_cov_vertex)\n",
    "            },\n",
    "            'max_prop_cov_bases':\n",
    "            {\n",
    "                'median': median(small_max_prop_cov_bases),\n",
    "                'mean': mean(small_max_prop_cov_bases),\n",
    "                'stdev': stdev(small_max_prop_cov_bases)\n",
    "            }\n",
    "            \n",
    "        }\n",
    "        ,\n",
    "        'medium' :\n",
    "        {\n",
    "            'e_size_density_vertex': \n",
    "            {\n",
    "                'median': median(medium_e_size_densities_vertex),\n",
    "                'mean': mean(medium_e_size_densities_vertex),\n",
    "                'stdev': stdev(medium_e_size_densities_vertex)\n",
    "            },\n",
    "            'e_size_density_bases': \n",
    "            {\n",
    "                'median': median(medium_e_size_densities_bases),\n",
    "                'mean': mean(medium_e_size_densities_bases),\n",
    "                'stdev': stdev(medium_e_size_densities_bases)\n",
    "            },\n",
    "            'max_prop_cov_vertex':\n",
    "            {\n",
    "                'median': median(medium_max_prop_cov_vertex),\n",
    "                'mean': mean(medium_max_prop_cov_vertex),\n",
    "                'stdev': stdev(medium_max_prop_cov_vertex)\n",
    "            },\n",
    "            'max_prop_cov_bases':\n",
    "            {\n",
    "                'median': median(medium_max_prop_cov_bases),\n",
    "                'mean': mean(medium_max_prop_cov_bases),\n",
    "                'stdev': stdev(medium_max_prop_cov_bases)\n",
    "            }\n",
    "        },\n",
    "        'large':\n",
    "        {\n",
    "            'e_size_density_vertex': \n",
    "            {\n",
    "                'median': median(large_e_size_densities_vertex),\n",
    "                'mean': mean(large_e_size_densities_vertex),\n",
    "                'stdev': stdev(large_e_size_densities_vertex)\n",
    "            },\n",
    "            'e_size_density_bases': \n",
    "            {\n",
    "                'median': median(large_e_size_densities_bases),\n",
    "                'mean': mean(large_e_size_densities_bases),\n",
    "                'stdev': stdev(large_e_size_densities_bases)\n",
    "            },\n",
    "            'max_prop_cov_vertex':\n",
    "            {\n",
    "                'median': median(large_max_prop_cov_vertex),\n",
    "                'mean': mean(large_max_prop_cov_vertex),\n",
    "                'stdev': stdev(large_max_prop_cov_vertex)\n",
    "            },\n",
    "            'max_prop_cov_bases':\n",
    "            {\n",
    "                'median': median(large_max_prop_cov_bases),\n",
    "                'mean': mean(large_max_prop_cov_bases),\n",
    "                'stdev': stdev(large_max_prop_cov_bases)\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "pprint(compute_fixed_l_table_unitigs(limit_60, limit_30, components, vertices_inv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'large': {'e_size_density_bases': {'mean': 0.41714149761872815,\n",
      "                                    'median': 0.36897707834567395,\n",
      "                                    'stdev': 0.21855757729032965},\n",
      "           'e_size_density_vertex': {'mean': 0.3728023373605343,\n",
      "                                     'median': 0.32653061224489793,\n",
      "                                     'stdev': 0.2046219563447882},\n",
      "           'max_prop_cov_bases': {'mean': 0.5629802809411107,\n",
      "                                  'median': 0.532770637138839,\n",
      "                                  'stdev': 0.2231472345191591},\n",
      "           'max_prop_cov_vertex': {'mean': 0.508781466766869,\n",
      "                                   'median': 0.47619047619047616,\n",
      "                                   'stdev': 0.21553322358998842},\n",
      "           'precision': {'mean': 0.847837431112713,\n",
      "                         'median': 0.8995228234446745,\n",
      "                         'stdev': 0.16750627150093056}},\n",
      " 'medium': {'e_size_density_bases': {'mean': 0.5005563405622311,\n",
      "                                     'median': 0.4640926082176735,\n",
      "                                     'stdev': 0.20757099202364784},\n",
      "            'e_size_density_vertex': {'mean': 0.43335694131826297,\n",
      "                                      'median': 0.38595041322314055,\n",
      "                                      'stdev': 0.19803457200479604},\n",
      "            'max_prop_cov_bases': {'mean': 0.6449677980797355,\n",
      "                                   'median': 0.6271104993524952,\n",
      "                                   'stdev': 0.2048787008234465},\n",
      "            'max_prop_cov_vertex': {'mean': 0.5678939612525647,\n",
      "                                    'median': 0.5294117647058824,\n",
      "                                    'stdev': 0.20446310621751235},\n",
      "            'precision': {'mean': 0.8183208373025126,\n",
      "                          'median': 0.9214834270790463,\n",
      "                          'stdev': 0.2569399092879682}},\n",
      " 'small': {'e_size_density_bases': {'mean': 0.7164486380810893,\n",
      "                                    'median': 0.7205730290788416,\n",
      "                                    'stdev': 0.2160561489811331},\n",
      "           'e_size_density_vertex': {'mean': 0.639340340062406,\n",
      "                                     'median': 0.5925925925925926,\n",
      "                                     'stdev': 0.23529135394801048},\n",
      "           'max_prop_cov_bases': {'mean': 0.8202653521604336,\n",
      "                                  'median': 0.8684223954089021,\n",
      "                                  'stdev': 0.1821563141500483},\n",
      "           'max_prop_cov_vertex': {'mean': 0.7388412236509273,\n",
      "                                   'median': 0.7333333333333333,\n",
      "                                   'stdev': 0.2094732133685394},\n",
      "           'precision': {'mean': 0.8411739276221606,\n",
      "                         'median': 1.0,\n",
      "                         'stdev': 0.3332851558457581}}}\n"
     ]
    }
   ],
   "source": [
    "def compute_fixed_rd_table(over_width, limit_60, limit_30, components, vertices_inv):\n",
    "    genes = list()\n",
    "    transcripts = list()\n",
    "    for i, component in enumerate(components):\n",
    "        if component['len'] > 2:\n",
    "            width = component['width']\n",
    "            l = str(width+over_width)\n",
    "            if over_width == -1:\n",
    "                l = str(len(component['transcript_paths']))\n",
    "            if over_width == -2:\n",
    "                l = str(2*component['width'])\n",
    "                \n",
    "                \n",
    "            if component['experiments'].get(l, None) is None:\n",
    "                l = str(2*width)\n",
    "                        \n",
    "            if component['experiments'].get(l, None) is not None:\n",
    "                safe_paths_info = component['experiments'][l]\n",
    "\n",
    "                for j, transcript in enumerate(component['transcript_paths']):\n",
    "                    d = dict()\n",
    "                    d['component'] = i\n",
    "                    d['component_length'] = component['len']\n",
    "                    d['length'] = base_length(transcript, vertices_inv)\n",
    "                    d['transcript'] = transcript\n",
    "                    \n",
    "                    \n",
    "                    d['e_size_density_vertex'] = safe_paths_info['e_sizes_vertex'][j]/len(transcript)\n",
    "                    d['e_size_density_bases'] = safe_paths_info['e_size_bases'][j]/d['length']\n",
    "                    d['max_prop_cov_bases'] = safe_paths_info['max_cov_bases'][j]/d['length']\n",
    "                    d['max_prop_cov_vertex'] = safe_paths_info['max_cov_vertex'][j]/len(transcript)\n",
    "                    \n",
    "                    transcripts.append(d)\n",
    "                 \n",
    "                d = dict()\n",
    "                \n",
    "                tp = 0\n",
    "                for safe_path in safe_paths_info['true_positives']:\n",
    "                    tp += base_length(safe_path, vertices_inv)\n",
    "                    \n",
    "                p = tp\n",
    "                for safe_path in safe_paths_info['false_positives']:\n",
    "                    p += base_length(safe_path, vertices_inv)\n",
    "                \n",
    "                d['precision'] = tp/p\n",
    "                d['component_length'] = components[i]['len']\n",
    "                genes.append(d)\n",
    "    \n",
    "    small = list(filter(lambda t: t['component_length'] <= limit_60, transcripts))\n",
    "    medium = list(filter(lambda t: t['component_length'] > limit_60 and t['component_length'] <= limit_30 , transcripts))\n",
    "    large = list(filter(lambda t: t['component_length'] > limit_30, transcripts))\n",
    "    \n",
    "    small_e_size_densities_vertex = list(map(lambda t: t['e_size_density_vertex'] , small))\n",
    "    medium_e_size_densities_vertex = list(map(lambda t: t['e_size_density_vertex'] , medium))\n",
    "    large_e_size_densities_vertex = list(map(lambda t: t['e_size_density_vertex'] , large))\n",
    "    \n",
    "    small_e_size_densities_bases = list(map(lambda t: t['e_size_density_bases'] , small))\n",
    "    medium_e_size_densities_bases = list(map(lambda t: t['e_size_density_bases'] , medium))\n",
    "    large_e_size_densities_bases = list(map(lambda t: t['e_size_density_bases'] , large))\n",
    "    \n",
    "    \n",
    "    small_max_prop_cov_vertex = list(map(lambda t: t['max_prop_cov_vertex'] , small))\n",
    "    medium_max_prop_cov_vertex = list(map(lambda t: t['max_prop_cov_vertex'] , medium))\n",
    "    large_max_prop_cov_vertex = list(map(lambda t: t['max_prop_cov_vertex'] , large))\n",
    "    \n",
    "    small_max_prop_cov_bases = list(map(lambda t: t['max_prop_cov_bases'] , small))\n",
    "    medium_max_prop_cov_bases = list(map(lambda t: t['max_prop_cov_bases'] , medium))\n",
    "    large_max_prop_cov_bases = list(map(lambda t: t['max_prop_cov_bases'] , large))\n",
    "    \n",
    "    \n",
    "    s = list(filter(lambda t: t['component_length'] <= limit_60, genes))\n",
    "    m = list(filter(lambda t: t['component_length'] > limit_60 and t['component_length'] <= limit_30 , genes))\n",
    "    l = list(filter(lambda t: t['component_length'] > limit_30, genes))\n",
    "    \n",
    "    s_precisions = list(map(lambda t: t['precision'] , s))\n",
    "    m_precisions = list(map(lambda t: t['precision'] , m))\n",
    "    l_precisions = list(map(lambda t: t['precision'] , l))\n",
    "    \n",
    "    \n",
    "    return { \n",
    "        'small':\n",
    "        {\n",
    "            'e_size_density_vertex': \n",
    "            {\n",
    "                'median': median(small_e_size_densities_vertex),\n",
    "                'mean': mean(small_e_size_densities_vertex),\n",
    "                'stdev': stdev(small_e_size_densities_vertex)\n",
    "            },\n",
    "            'e_size_density_bases': \n",
    "            {\n",
    "                'median': median(small_e_size_densities_bases),\n",
    "                'mean': mean(small_e_size_densities_bases),\n",
    "                'stdev': stdev(small_e_size_densities_bases)\n",
    "            },\n",
    "            'max_prop_cov_vertex':\n",
    "            {\n",
    "                'median': median(small_max_prop_cov_vertex),\n",
    "                'mean': mean(small_max_prop_cov_vertex),\n",
    "                'stdev': stdev(small_max_prop_cov_vertex)\n",
    "            },\n",
    "            'max_prop_cov_bases':\n",
    "            {\n",
    "                'median': median(small_max_prop_cov_bases),\n",
    "                'mean': mean(small_max_prop_cov_bases),\n",
    "                'stdev': stdev(small_max_prop_cov_bases)\n",
    "            },\n",
    "            'precision':\n",
    "            {\n",
    "                'median': median(s_precisions),\n",
    "                'mean': mean(s_precisions),\n",
    "                'stdev': stdev(s_precisions)\n",
    "            }\n",
    "            \n",
    "        }\n",
    "        ,\n",
    "        'medium' :\n",
    "        {\n",
    "            'e_size_density_vertex': \n",
    "            {\n",
    "                'median': median(medium_e_size_densities_vertex),\n",
    "                'mean': mean(medium_e_size_densities_vertex),\n",
    "                'stdev': stdev(medium_e_size_densities_vertex)\n",
    "            },\n",
    "            'e_size_density_bases': \n",
    "            {\n",
    "                'median': median(medium_e_size_densities_bases),\n",
    "                'mean': mean(medium_e_size_densities_bases),\n",
    "                'stdev': stdev(medium_e_size_densities_bases)\n",
    "            },\n",
    "            'max_prop_cov_vertex':\n",
    "            {\n",
    "                'median': median(medium_max_prop_cov_vertex),\n",
    "                'mean': mean(medium_max_prop_cov_vertex),\n",
    "                'stdev': stdev(medium_max_prop_cov_vertex)\n",
    "            },\n",
    "            'max_prop_cov_bases':\n",
    "            {\n",
    "                'median': median(medium_max_prop_cov_bases),\n",
    "                'mean': mean(medium_max_prop_cov_bases),\n",
    "                'stdev': stdev(medium_max_prop_cov_bases)\n",
    "            },\n",
    "            'precision':\n",
    "            {\n",
    "                'median': median(m_precisions),\n",
    "                'mean': mean(m_precisions),\n",
    "                'stdev': stdev(m_precisions)\n",
    "            }\n",
    "        },\n",
    "        'large':\n",
    "        {\n",
    "            'e_size_density_vertex': \n",
    "            {\n",
    "                'median': median(large_e_size_densities_vertex),\n",
    "                'mean': mean(large_e_size_densities_vertex),\n",
    "                'stdev': stdev(large_e_size_densities_vertex)\n",
    "            },\n",
    "            'e_size_density_bases': \n",
    "            {\n",
    "                'median': median(large_e_size_densities_bases),\n",
    "                'mean': mean(large_e_size_densities_bases),\n",
    "                'stdev': stdev(large_e_size_densities_bases)\n",
    "            },\n",
    "            'max_prop_cov_vertex':\n",
    "            {\n",
    "                'median': median(large_max_prop_cov_vertex),\n",
    "                'mean': mean(large_max_prop_cov_vertex),\n",
    "                'stdev': stdev(large_max_prop_cov_vertex)\n",
    "            },\n",
    "            'max_prop_cov_bases':\n",
    "            {\n",
    "                'median': median(large_max_prop_cov_bases),\n",
    "                'mean': mean(large_max_prop_cov_bases),\n",
    "                'stdev': stdev(large_max_prop_cov_bases)\n",
    "            },\n",
    "            'precision':\n",
    "            {\n",
    "                'median': median(l_precisions),\n",
    "                'mean': mean(l_precisions),\n",
    "                'stdev': stdev(l_precisions)\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "pprint(compute_fixed_rd_table(0, limit_size_60, limit_size_30, components, vertices_inv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'large': {'e_size_density_bases': {'mean': 0.2767474744422535,\n",
      "                                    'median': 0.23109977910954016,\n",
      "                                    'stdev': 0.18777367625935018},\n",
      "           'e_size_density_vertex': {'mean': 0.2614866277899087,\n",
      "                                     'median': 0.22453703703703706,\n",
      "                                     'stdev': 0.15769141207401716},\n",
      "           'max_prop_cov_bases': {'mean': 0.42886139787405575,\n",
      "                                  'median': 0.39526625377361424,\n",
      "                                  'stdev': 0.20256202030795475},\n",
      "           'max_prop_cov_vertex': {'mean': 0.4025184280266759,\n",
      "                                   'median': 0.375,\n",
      "                                   'stdev': 0.1853223535658438},\n",
      "           'precision': {'mean': 1.0, 'median': 1.0, 'stdev': 0.0}},\n",
      " 'medium': {'e_size_density_bases': {'mean': 0.33815263847544497,\n",
      "                                     'median': 0.30365279022051384,\n",
      "                                     'stdev': 0.19958481924669513},\n",
      "            'e_size_density_vertex': {'mean': 0.29928547761858215,\n",
      "                                      'median': 0.2654320987654321,\n",
      "                                      'stdev': 0.15303817515002163},\n",
      "            'max_prop_cov_bases': {'mean': 0.49599387473003087,\n",
      "                                   'median': 0.4737470167064439,\n",
      "                                   'stdev': 0.205885843072728},\n",
      "            'max_prop_cov_vertex': {'mean': 0.44292561402044156,\n",
      "                                    'median': 0.4166666666666667,\n",
      "                                    'stdev': 0.17693931629581675},\n",
      "            'precision': {'mean': 1.0, 'median': 1.0, 'stdev': 0.0}},\n",
      " 'small': {'e_size_density_bases': {'mean': 0.5237752137262572,\n",
      "                                    'median': 0.5044829201065468,\n",
      "                                    'stdev': 0.30419753638913805},\n",
      "           'e_size_density_vertex': {'mean': 0.4643977544055662,\n",
      "                                     'median': 0.4,\n",
      "                                     'stdev': 0.2644805056507866},\n",
      "           'max_prop_cov_bases': {'mean': 0.6498429850270945,\n",
      "                                  'median': 0.6731168703807715,\n",
      "                                  'stdev': 0.27435869031064947},\n",
      "           'max_prop_cov_vertex': {'mean': 0.591474556157989,\n",
      "                                   'median': 0.5714285714285714,\n",
      "                                   'stdev': 0.24292205933797859},\n",
      "           'precision': {'mean': 1.0, 'median': 1.0, 'stdev': 0.0}}}\n"
     ]
    }
   ],
   "source": [
    "def compute_fixed_rd_table_unitigs(limit_60, limit_30, components, vertices_inv):\n",
    "    transcripts = list()\n",
    "    genes = list()\n",
    "    for i, component in enumerate(components):\n",
    "        if component['len'] > 2:\n",
    "            unitigs = component['unitigs']\n",
    "\n",
    "            for j, transcript in enumerate(component['transcript_paths']):\n",
    "                d = dict()\n",
    "                d['component'] = i\n",
    "                d['component_length'] = components[i]['len']\n",
    "                d['length'] = base_length(transcript, vertices_inv)\n",
    "                d['transcript'] = transcript\n",
    "                \n",
    "                \n",
    "                d['e_size_density_vertex'] =  component['e_sizes_vertex'][j]/len(transcript)\n",
    "                d['e_size_density_bases'] =  component['e_size_bases'][j]/d['length']\n",
    "                d['max_prop_cov_bases'] =  component['max_cov_bases'][j]/d['length']\n",
    "                d['max_prop_cov_vertex'] =  component['max_cov_vertex'][j]/len(transcript)\n",
    "\n",
    "                transcripts.append(d)\n",
    "                \n",
    "            d = dict()\n",
    "                \n",
    "            tp = 0\n",
    "            for safe_path in component['true_positives']:\n",
    "                tp += base_length(safe_path, vertices_inv)\n",
    "\n",
    "            p = tp\n",
    "            for safe_path in component['false_positives']:\n",
    "                p += base_length(safe_path, vertices_inv)\n",
    "                \n",
    "\n",
    "            d['precision'] = 1 if p==0 else tp/p\n",
    "            d['component_length'] = component['len']\n",
    "            genes.append(d)\n",
    "\n",
    "    \n",
    "    \n",
    "    small = list(filter(lambda t: t['component_length'] <= limit_60, transcripts))\n",
    "    medium = list(filter(lambda t: t['component_length'] > limit_60 and t['component_length'] <= limit_30 , transcripts))\n",
    "    large = list(filter(lambda t: t['component_length'] > limit_30, transcripts))\n",
    "    \n",
    "    small_e_size_densities_vertex = list(map(lambda t: t['e_size_density_vertex'] , small))\n",
    "    medium_e_size_densities_vertex = list(map(lambda t: t['e_size_density_vertex'] , medium))\n",
    "    large_e_size_densities_vertex = list(map(lambda t: t['e_size_density_vertex'] , large))\n",
    "    \n",
    "    small_e_size_densities_bases = list(map(lambda t: t['e_size_density_bases'] , small))\n",
    "    medium_e_size_densities_bases = list(map(lambda t: t['e_size_density_bases'] , medium))\n",
    "    large_e_size_densities_bases = list(map(lambda t: t['e_size_density_bases'] , large))\n",
    "    \n",
    "    \n",
    "    small_max_prop_cov_vertex = list(map(lambda t: t['max_prop_cov_vertex'] , small))\n",
    "    medium_max_prop_cov_vertex = list(map(lambda t: t['max_prop_cov_vertex'] , medium))\n",
    "    large_max_prop_cov_vertex = list(map(lambda t: t['max_prop_cov_vertex'] , large))\n",
    "    \n",
    "    small_max_prop_cov_bases = list(map(lambda t: t['max_prop_cov_bases'] , small))\n",
    "    medium_max_prop_cov_bases = list(map(lambda t: t['max_prop_cov_bases'] , medium))\n",
    "    large_max_prop_cov_bases = list(map(lambda t: t['max_prop_cov_bases'] , large))\n",
    "    \n",
    "    \n",
    "    s = list(filter(lambda t: t['component_length'] <= limit_60, genes))\n",
    "    m = list(filter(lambda t: t['component_length'] > limit_60 and t['component_length'] <= limit_30 , genes))\n",
    "    l = list(filter(lambda t: t['component_length'] > limit_30, genes))\n",
    "    \n",
    "    s_precisions = list(map(lambda t: t['precision'] , s))\n",
    "    m_precisions = list(map(lambda t: t['precision'] , m))\n",
    "    l_precisions = list(map(lambda t: t['precision'] , l))\n",
    "    \n",
    "    \n",
    "    return { \n",
    "        'small':\n",
    "        {\n",
    "            'e_size_density_vertex': \n",
    "            {\n",
    "                'median': median(small_e_size_densities_vertex),\n",
    "                'mean': mean(small_e_size_densities_vertex),\n",
    "                'stdev': stdev(small_e_size_densities_vertex)\n",
    "            },\n",
    "            'e_size_density_bases': \n",
    "            {\n",
    "                'median': median(small_e_size_densities_bases),\n",
    "                'mean': mean(small_e_size_densities_bases),\n",
    "                'stdev': stdev(small_e_size_densities_bases)\n",
    "            },\n",
    "            'max_prop_cov_vertex':\n",
    "            {\n",
    "                'median': median(small_max_prop_cov_vertex),\n",
    "                'mean': mean(small_max_prop_cov_vertex),\n",
    "                'stdev': stdev(small_max_prop_cov_vertex)\n",
    "            },\n",
    "            'max_prop_cov_bases':\n",
    "            {\n",
    "                'median': median(small_max_prop_cov_bases),\n",
    "                'mean': mean(small_max_prop_cov_bases),\n",
    "                'stdev': stdev(small_max_prop_cov_bases)\n",
    "            },\n",
    "            'precision':\n",
    "            {\n",
    "                'median': median(s_precisions),\n",
    "                'mean': mean(s_precisions),\n",
    "                'stdev': stdev(s_precisions)\n",
    "            }\n",
    "            \n",
    "        }\n",
    "        ,\n",
    "        'medium' :\n",
    "        {\n",
    "            'e_size_density_vertex': \n",
    "            {\n",
    "                'median': median(medium_e_size_densities_vertex),\n",
    "                'mean': mean(medium_e_size_densities_vertex),\n",
    "                'stdev': stdev(medium_e_size_densities_vertex)\n",
    "            },\n",
    "            'e_size_density_bases': \n",
    "            {\n",
    "                'median': median(medium_e_size_densities_bases),\n",
    "                'mean': mean(medium_e_size_densities_bases),\n",
    "                'stdev': stdev(medium_e_size_densities_bases)\n",
    "            },\n",
    "            'max_prop_cov_vertex':\n",
    "            {\n",
    "                'median': median(medium_max_prop_cov_vertex),\n",
    "                'mean': mean(medium_max_prop_cov_vertex),\n",
    "                'stdev': stdev(medium_max_prop_cov_vertex)\n",
    "            },\n",
    "            'max_prop_cov_bases':\n",
    "            {\n",
    "                'median': median(medium_max_prop_cov_bases),\n",
    "                'mean': mean(medium_max_prop_cov_bases),\n",
    "                'stdev': stdev(medium_max_prop_cov_bases)\n",
    "            },\n",
    "            'precision':\n",
    "            {\n",
    "                'median': median(m_precisions),\n",
    "                'mean': mean(m_precisions),\n",
    "                'stdev': stdev(m_precisions)\n",
    "            }\n",
    "        },\n",
    "        'large':\n",
    "        {\n",
    "            'e_size_density_vertex': \n",
    "            {\n",
    "                'median': median(large_e_size_densities_vertex),\n",
    "                'mean': mean(large_e_size_densities_vertex),\n",
    "                'stdev': stdev(large_e_size_densities_vertex)\n",
    "            },\n",
    "            'e_size_density_bases': \n",
    "            {\n",
    "                'median': median(large_e_size_densities_bases),\n",
    "                'mean': mean(large_e_size_densities_bases),\n",
    "                'stdev': stdev(large_e_size_densities_bases)\n",
    "            },\n",
    "            'max_prop_cov_vertex':\n",
    "            {\n",
    "                'median': median(large_max_prop_cov_vertex),\n",
    "                'mean': mean(large_max_prop_cov_vertex),\n",
    "                'stdev': stdev(large_max_prop_cov_vertex)\n",
    "            },\n",
    "            'max_prop_cov_bases':\n",
    "            {\n",
    "                'median': median(large_max_prop_cov_bases),\n",
    "                'mean': mean(large_max_prop_cov_bases),\n",
    "                'stdev': stdev(large_max_prop_cov_bases)\n",
    "            },\n",
    "            'precision':\n",
    "            {\n",
    "                'median': median(l_precisions),\n",
    "                'mean': mean(l_precisions),\n",
    "                'stdev': stdev(l_precisions)\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "pprint(compute_fixed_rd_table_unitigs(limit_size_60, limit_size_30, components, vertices_inv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161\n",
      "{'all': {'time': 0},\n",
      " 'large': {'time': 0},\n",
      " 'medium': {'time': 0},\n",
      " 'small': {'time': 0}}\n",
      "{'all': {'time': 0},\n",
      " 'large': {'time': 0},\n",
      " 'medium': {'time': 0},\n",
      " 'small': {'time': 0}}\n"
     ]
    }
   ],
   "source": [
    "def compute_time_table(over_width, limit_60, limit_30, components, vertices_inv, algorithm_experiments='experiments'):\n",
    "    time = list()\n",
    "    for i, component in enumerate(components):\n",
    "        if component['len'] > 2:\n",
    "            width = component['width']\n",
    "            l = str(width+over_width)\n",
    "            if over_width == -1:\n",
    "                l = str(len(component['transcript_paths']))\n",
    "            if over_width == -2:\n",
    "                l = str(2*component['width'])\n",
    "            if component[algorithm_experiments].get(l, None) is not None:\n",
    "                safe_paths_info = component[algorithm_experiments][l]\n",
    "\n",
    "                d = dict()\n",
    "                d['time'] = component[algorithm_experiments][l]['time_main']+component[algorithm_experiments][l]['time_filter']\n",
    "                print(d['time'])\n",
    "                break\n",
    "                d['component_length'] = component['len']\n",
    "                time.append(d)\n",
    "    \n",
    "    small = list(filter(lambda t: t['component_length'] <= limit_60, time))\n",
    "    medium = list(filter(lambda t: t['component_length'] > limit_60 and t['component_length'] <= limit_30 , time))\n",
    "    large = list(filter(lambda t: t['component_length'] > limit_30, time))\n",
    "    \n",
    "    return { \n",
    "        'small':\n",
    "        {\n",
    "            'time': sum(list(map(lambda x: x['time'] , small)))\n",
    "        }\n",
    "        ,\n",
    "        'medium' :\n",
    "        {\n",
    "            'time': sum(list(map(lambda x: x['time'] , medium)))\n",
    "        },\n",
    "        'large':\n",
    "        {\n",
    "            'time': sum(list(map(lambda x: x['time'] , large)))\n",
    "        },\n",
    "        'all':\n",
    "        {\n",
    "            'time': sum(list(map(lambda x: x['time'] , time)))\n",
    "        }\n",
    "    }\n",
    "\n",
    "pprint(compute_time_table(0, limit_size_60, limit_size_30, components, vertices_inv))\n",
    "pprint(compute_time_table(0, limit_size_60, limit_size_30, components, vertices_inv, 'experiments_naive'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5260, 4892)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## And peak memory\n",
    "max(list(map(lambda x: 0 if x.get('experiments', None) is None else max(list(map(lambda k: x['experiments'][k]['peak_memory'], x['experiments'].keys()))),\n",
    "             components))), max(list(map(lambda x: 0 if x.get('experiments_naive', None) is None else max(list(map(lambda k: x['experiments_naive'][k]['peak_mem'], x['experiments_naive'].keys()))),\n",
    "             components)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
